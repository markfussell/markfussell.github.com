<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Grails | Polyglot]]></title>
  <link href="http://markfussell.emenar.com/blog/categories/grails/atom.xml" rel="self"/>
  <link href="http://markfussell.emenar.com/"/>
  <updated>2015-10-22T12:17:51-07:00</updated>
  <id>http://markfussell.emenar.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-9]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-9/"/>
    <updated>2015-10-21T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-9</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.  The fifth added some major aspects to the stack: Semi-Structured Data, Templates,
and Dual or Isomorphic scripting. The sixth discussed UI frameworks in a bit more detail and ended with an Angular vs.
Ember as a core choice.  The seventh went into logging, analytics, and monitoring of the running applications and nodes.
The eighth was an overview of Federation Components like caches, queues, payment services, and the like.</p>

<h2>Workers!</h2>

<p>Among the more interesting federation / deployment component are workers.  Workers are interesting because
they can do almost anything imaginable and they do it very efficiently.  How efficiently?  Well, the perfect
worker is at 100% when doing a task and <em>dead</em> when they have no tasks to do.  That is pretty darn efficient
because it approaches 100% and is only not 100% when we choose to not accept the 'spin up' latency of getting
 a new worker.  As the amount of work increases, our pool of workers increase, and the spin-up-latency decreases
 on a per-chore basis.  That is <em>very cool</em>: as scale goes up, efficiency <em>increases</em>.  There are a lot of places that
 is not true for computers, so it is nice when it is.</p>

<h3>Work?  Chore?</h3>

<p>So we want to have a worker model where we can add a 'chore' (a unit of work, using a term not otherwise used in
IT and CS... job, task, etc. are now ambivalent) to a queue of work-to-be-done, and have
 something do that chore.  There are a lot of ways to do this:</p>

<p> <!--more--></p>

<ol>
<li>Use BeanStalk</li>
<li>Use Kafka with a bunch of consumers</li>
<li>Use a database and launch a worker if none is available</li>
<li>Use Quartz and coordinate amongst the application servers which one is going to do the work</li>
<li>Use GitHub and launch one or more workers as needed</li>
</ol>


<p>And that is just a minor collection of simple solutions.  The first two are probably 'the best' in terms of having
a very clean model.  But they require additional infrastructure and I am trying to keep that at a minimum.  The
second is using a database as a WorkQueue.  Well, it turns out that this is actually commonly done and almost
always <em>regretted</em>.  Most databases are horrible with the characteristics of Chores and their lifecycle.  So it does
work, but not well.</p>

<p>The fourth is quite functional but not scalable.  You don't want your application servers doing <em>a lot</em> of work.
A little housekeeping is fine.  But the whole point of the Worker model is to enable as many or as few workers who each
<em>always</em> do <em>a lot</em> of work.  And then go away if no longer needed.  That isn't the lifecycle and duty of application
servers.</p>

<p>So if you haven't guessed by now, I am going to describe the fifth approach.  Use an annexed Git repository to describe
chores, their media (if any), and to provide the results (if any).  It turns out to be blazingly fast, scalable,
and flexible.  A little weird but sometimes weird really works.</p>

<h3>Chores, Parents, and Workers</h3>

<p>A lot of time, the real world can seriously inspire the computer world.  The Worker model I am about to describe
matches a 'high-speed', 'high-efficiency', parenting model.  I would guess any parent can see the similarities
and even the Nirvana of this Worker model.  It has a few major components:</p>

<ul>
<li>The World creates some Chores in a to-do list</li>
<li>The World doesn't want to do the Chores, because it has other things to do</li>
<li>So The World creates two or more adults (for redundancy) so they can do the Chores

<ul>
<li>And then The World gives responsibility to the adults to do the Chores</li>
</ul>
</li>
<li>The adults don't want to actually do the Chores themselves, so they produce Workers to do the Chores</li>
<li>The Workers are so awesome that they automatically <em>all</em> try to do the Chores, as quickly as possible

<ul>
<li>The adults (Parents) have worked out a system to prevent two Workers from doing the same Chore</li>
</ul>
</li>
<li>If the Chores are not getting done fast enough, the Parents produce more Workers</li>
<li>If there is no more work to do, the Workers go to sleep

<ul>
<li>Waking periodically to see if there is more work</li>
<li>Or if the Chores are not getting done fast enough, the Parents wake one or more Workers</li>
</ul>
</li>
</ul>


<p>With this model:</p>

<ul>
<li>The World is the Application Server or something similar</li>
<li>The Parents are special Nodes (or processes on Application Server nodes) that can see the 'to-do' list</li>
<li>The Workers are special Nodes that are created as the 'to-do' list backlog gets larger</li>
</ul>


<p>You need at least two Parents at all time to make sure the To-Do list is being watched.  You don't need any
Workers until the To-Do list is sufficiently long or latent.</p>

<p>We will put the 'To-Do' chores into a specially structured, annexed, Git repository.  Because of the annexing,
resources are automatically 'deduped' and having each 'chore' be self-contained is both possible and space
efficient.  Imagine all the 'jar's needed for a java build.  Given most of these are stable between builds,
they cost nothing at all to include in a 'chore'.  Where people run fragile artifact servers (fragile because
(a) they exist as something that could fail and (b) they are rarely run redundantly) that have to handle
heavy load, the Annex puts all that load on S3... which is designed from the ground-up for loads well beyond our workers.</p>

<h4>Chore Structure</h4>

<p>The core of a Chore has to include:</p>

<ul>
<li>The identity of the chore

<ul>
<li>And an ability to 'take it on'</li>
</ul>
</li>
<li>What the instructions are for the chore</li>
<li>What resources you need for the chore</li>
<li>Where the results of the chore are supposed to go</li>
</ul>


<p>To make the throughput easier to see, we will organize chores by time.  So basically a queue.  We can have 'priority' within the
metadata of the chore if we want things to jump the queue.  And we can have different chore types (or IT needs) to
make sure a worker can really handle the chore. Using the 'cron_1m' model of things working on the minute, we will
put things into buckets every minute.  But workers have to look for any not-done chore and pick it up if they can.</p>

<p>An advantage of the one-minute cron is we automatically can have a nice 30-second jitter.  That plus some kind of randomization
makes it very unlikely that workers will acquire the same chore at the same time.  But if they do, one will win due
to 'git push' timing.</p>

<h5>Identity</h5>

<p>Chores are identified by their 'producer' and a timestamp.  A 'producer' is a node plus a process id, and the timestamp can
have any precision necessary for the process to know it can't collide with itself.  Two of the banes of any identity system
is making sure identity is unique and not having a bottleneck for identity generation.  The identity proposed solves these
two main issues.  A third requirement (sometimes) is keeping identity short / consistent.  A hash of the 'phrase' is
possible if necessary, but collisions could be an issue if the phrase is too short.</p>

<h5>Instructions</h5>

<p>So we have something like "chore_ip-1-2-3-4_ps-349467_20151022-110109-123456" as a chore.  This is simply a directory with
a 'chore.json' within it where that 'chore.json' looks something like this:</p>

<p><code>json
{
  "chore_id" : "ip-1-2-3-4_ps-349467_20151022-110109-123456",
  "chore_tss" : "20151022110109",
  "producer_id" : "ip-1-2-3-4_ps-349467",
  "runner" : "bash",
  "command" : "ps -aux",
  "result" : "output.txt",
  "error" : "error.txt"
}
</code></p>

<p>Another file is in the directory initially called 'do_it.txt' which can be empty.</p>

<h5>Take on the 'chore'</h5>

<p>To take this 'chore' on, a worker adds a 'worker.json' file to the directory:</p>

<p><code>json
{
  "chore_id" :  "ip-1-2-3-4_ps-349467_20151022-110109-123456",
  "work_id" :  "ip-4-5-6-7_ps-1000_20151022-110209-123456",
  "worker_id" : "ip-4-5-6-7_ps-1000",
  "work_start_tss" : "20151022110209",
  "state" : "working",
  "work_finish_tss" : ""
}
</code></p>

<p>and renames the 'do_it.txt' to 'doing_it.txt'</p>

<p>When these changes commit and push successfully, this worker now owns the chore.  The worker can update the 'worker.json'
through the work if desired, or put files into the directory or elsewhere.  When the chore is complete, the worker
should change worker.json to a finished state, and rename the 'doing_it.txt' to 'done.txt'.  With this,
the three states are:</p>

<ul>
<li>do_it.txt</li>
<li>doing_it.txt</li>
<li>done.txt</li>
</ul>


<p>And everyone can quickly tell what the state of a chore is without worrying about the details.  Or dive into the json
and results to figure out those details.</p>

<p>A worker should alway be able to acquire:</p>

<ul>
<li>The root of the work repository – Say "${GIT_ROOT}"</li>
<li>The root of the chore itself – Say "${CHORE_ROOT}"</li>
</ul>


<p>Where the "GIT_ROOT" can have shared scripts in its 'chore/bin' or 'bin' directories, and the chore can have
individual scripts in it CHORE_ROOT/bin directory.</p>

<p><img src="http://markfussell.emenar.com/images/addstack-9/addstack-9_chore1.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-8]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-8/"/>
    <updated>2015-10-20T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-8</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.  The fifth added some major aspects to the stack: Semi-Structured Data, Templates,
and Dual or Isomorphic scripting. The sixth discussed UI frameworks in a bit more detail and ended with an Angular vs.
Ember as a core choice.  The seventh went into logging, analytics, and monitoring of the running applications and nodes.</p>

<h2>Federation Application Infrastructure</h2>

<p>The application stack we have so far:</p>

<ul>
<li> UI (both client and server)</li>
<li> Application Server (Grails, Java, potentially scripting engine)</li>
<li> Database (Maria or similar)</li>
</ul>


<p>Is very capable.  Using it combined with the ADD ingredients:</p>

<ul>
<li> GitHub – With resource, presence, application, and configuration information repositories</li>
<li> EC2 Instances – Running continuously or based on load, and running their 'part' plus any dynamic configuration</li>
<li> S3 – For resources</li>
<li> HipChat – To let everyone know</li>
</ul>


<p>Makes for a very functional application.  The nodes and their applications can talk to each other based on presence.
The nodes and their application can keep certain data in-memory (cached).  The nodes can
 launch other nodes to handle load or do certain tasks.  An Application Server is a very generic thing and
 can do pretty much anything.</p>

<h3>Standard Federation Components</h3>

<p>Doing pretty much anything and everything turns out to be very confusing.  For people.  Big monoliths of capabilities
are basically beyond comprehension.  And the bigger the monolith, the harder it falls.  The more likely it falls.
And even if you have redundant monoliths, the system becomes very painful to maintain and to learn.</p>

<!--more-->


<p>So instead of having the one super-capable application server, we can start breaking out some of the responsibilities
of the application server into other system components, and then decide whether we need them or not.  If we need
them, we will be using a very main-stream approach that is redundant, scalable, and easily managed.  It needs to 'fit'
with our application, but it doesn't have to be similar to the application (e.g. works with Java, written in Erlang,
runs on Linux).</p>

<p>The list of standard system components isn't that long, but it is <em>longer than you need</em>.  If you are using all of these,
you are likely over-engineering your solution.  Try to start weaning yourself off some of this technology.</p>

<p>A partial list of federation components</p>

<ul>
<li>Cache – For rapidly retrieving information that changes slowly or needs to be shared broadly</li>
<li>Queue – For getting information from producers (requests) to consumers (workers)</li>
<li>Distributed State – For precise and consistent decision-making among several different entities</li>
<li>Semistructured Database – For persistently storing data in a faster or more flexible format than the main database</li>
<li>SSO (Single Sign-on) – To enable users to get access to various resources without the resources having to authenticate</li>
<li>"Chat" – Real-time presence and data communication enabling 'chat' and various other capabilities</li>
<li>Map-Reduce – Taking large amounts of data and processing it to get answers to questions.  Can be real-time or not</li>
<li>Forum – Supporting forum capabilities for customers to talk with each other</li>
<li>Customer Support – Supporting customer-facing capabilities, including defect and product request tracking</li>
<li>SMS / Email / Contact – Ability to send out emails, SMS, surveys, and other customer contact</li>
<li>Web Site – A separate web site from the main application</li>
<li>Web Content Creator – An ability to enable users to create content within your site (vs. doing it via templating)</li>
<li>Payment Processing – Handling the record of credit cards and payment processing</li>
<li>Freetext Search – The ability to search documents and similar free text</li>
<li>Workers – Special nodes that do work and either go idle or disappear when no work is needed</li>
</ul>


<p>There are some more (e.g. the BI pipeline), but that is a pretty good list.  Especially the 'Workers' is a category basically as broad as
'Application'.</p>

<p>Working through the list, here are some examples:</p>

<ul>
<li>Cache – Redis <a href="http://redis.io">http://redis.io</a></li>
<li>Queue – Kafka <a href="http://kafka.apache.org">http://kafka.apache.org</a></li>
<li>Distributed State - Presence in Git (for minutes), ZooKeeper (for sub-second) <a href="http://zookeeper.apache.org">http://zookeeper.apache.org</a> and Curator <a href="http://curator.apache.org/curator-recipes/index.html">http://curator.apache.org/curator-recipes/index.html</a></li>
<li>Semistructured Database – Riak  <a href="http://basho.com/products/">http://basho.com/products/</a></li>
<li>SSO – Shibboleth <a href="http://shibboleth.net">http://shibboleth.net</a></li>
<li>Chat – Ejabberd <a href="https://www.ejabberd.im">https://www.ejabberd.im</a></li>
<li>Map-Reduce – Spark <a href="https://spark.apache.org">https://spark.apache.org</a>,  Hadoop <a href="https://hadoop.apache.org">https://hadoop.apache.org</a></li>
<li>Forum –  phpBB <a href="https://www.phpbb.com">https://www.phpbb.com</a></li>
<li>Customer Support – Parature <a href="http://www.parature.com">http://www.parature.com</a></li>
<li>SMS / Email / Contact – SendGrid <a href="https://sendgrid.com">https://sendgrid.com</a> , Silverpop <a href="http://www-03.ibm.com/software/products/en/silverpop-engage">http://www-03.ibm.com/software/products/en/silverpop-engage</a> , SurveyMonkey <a href="https://www.surveymonkey.com">https://www.surveymonkey.com</a> , etc.</li>
<li>Web Site –  Expression Engine <a href="https://ellislab.com/expressionengine">https://ellislab.com/expressionengine</a> , Squarespace <a href="http://www.squarespace.com">http://www.squarespace.com</a></li>
<li>Web Content Creator – How about the original 'wiki' <a href="http://wiki.org">http://wiki.org</a> or a more modern one like Foswiki <a href="http://foswiki.org">http://foswiki.org</a></li>
<li>Payment Processing – PayPal <a href="http://paypal.com">http://paypal.com</a> or even Facebook <a href="http://facebook.com">http://facebook.com</a> and Google <a href="http://google.com">http://google.com</a></li>
<li>Freetext Search – Solr <a href="http://lucene.apache.org/solr/">http://lucene.apache.org/solr/</a></li>
<li>Workers – All kinds of workers and frameworks for doing it, including AWS beanstalks <a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-tiers.html">http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-tiers.html</a></li>
</ul>


<p>Sadly, Rumble did use almost all of the above (and more) in some way or another, but that is seriously off-the-chart
and incredibly expensive.  Yes, it is powerful.  No, your users do not care to pay you for that much power.</p>

<p>A company like Wikipedia/Wikimedia looks more like this:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-8/addstack8_wikimedia1.png" /></p>

<h2>Conclusion</h2>

<p>It is good to understand what kinds of system components are out there and be aware that you don't have to
reinvent / recode them when you need them.  Each of the above are good products.  They do what they should
to fill a particular need.  And almost all of them are
fault-tolerant and scalable, so they can join the rest of the <em>very tolerant</em> ADD stack.
Or they are a service and you get what you pay for.  If you really need
one of them, certainly bring it aboard.  It is better than creating a monolith.
But if you can do without it, your application and you IT will be easier to understand and maintain.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-7]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-7/"/>
    <updated>2015-10-19T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-7</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.  The fifth added some major aspects to the stack: Semi-Structured Data, Templates,
and Dual or Isomorphic scripting. The sixth discussed UI frameworks in a bit more detail and ended with an Angular vs.
Ember as a core choice.</p>

<h2>Logging, Analytics, and Monitoring</h2>

<p>Returning to a bit more of an 'IT' issue, how do we handle logging, monitoring, and analytics on our collection of
machines?  There are a number of choices:</p>

<ol>
<li>Run our own infrastructure</li>
<li>Go with an inexpensive provider</li>
<li>Go with a more capable provider</li>
<li>Don't</li>
</ol>


<p>Of the above, I believe #3 is usually worth it until your scale gets to the point of needing #1.  Downgrading
from #3 to #2 is fine <em>after</em> you have learned the capabilities you are giving up.</p>

<!--more-->


<h3>Logging: SumoLogic</h3>

<p>The longest standing, very successful, and SaaS capable company is Splunk (<a href="http://splunk.com/">http://splunk.com/</a>) .  But their prices are crazy.  Have no
idea how they can charge that much.  So instead I will demo SumoLogic (<a href="http://SumoLogic.com/">http://SumoLogic.com/</a>) as the '3B' tier.</p>

<p>Installing SumoLogic is incredibly easy:</p>

<p><code>bash
wget "https://collectors.us2.sumologic.com/rest/download/linux/64" -O SumoCollector.sh &amp;&amp; chmod +x SumoCollector.sh &amp;&amp; ./SumoCollector.sh -q -VskipDefaultSources=true -Vsumo.token_and_url={token}
</code></p>

<p>And the collector is on the machine.  If you tell it what you want to aggregate, it starts collecting and indexing files in those paths.  In our case, the nodes
all have files in '/root/log' which it would be nice to have aggregated.</p>

<p>The results are visible here:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-7/addstack7_sumo1.png" /></p>

<p><img src="http://markfussell.emenar.com/images/addstack-7/addstack7_sumo2.png" /></p>

<p><img src="http://markfussell.emenar.com/images/addstack-7/addstack7_sumo3.png" /></p>

<h4>Logging Alternative: Graylog</h4>

<p>For Rumble, we had a Graylog (<a href="http://graylog.com/">http://graylog.com/</a>) cluster that dealt with a tremendous amount of data (half a
terabyte a day if memory serves, due to over-enthusiastic logging) and was relatively stable under that load.
Elasticsearch had issues if a node failed (just due to the stress of moving data to another backup), but this
is under pretty extreme load levels.  So if you wanted to roll your own, the Graylog path would be a very
inexpensive and powerful path.</p>

<h3>Analytics and Monitoring: NewRelic</h3>

<p>NewRelic (<a href="http://newrelic.com/">http://newrelic.com/</a>) started out as a Ruby-oriented monitoring service, and basically came about because Ruby/Rails developers
(a) wanted a lot of information about why their apps were running slowly, (b) had very little knowledge about
operations and other ways of monitoring things, and (c) Ruby itself has little support for monitoring.  NewRelic
came along and provided the metrics (as you would expect for Java and similar mature languages) <em>outside</em> the
Ruby environment.  Initially this could be viewed as a crutch for Ruby where Java didn't need it, but ultimately
by putting the metrics outside the application everyone's life was simpler.</p>

<p>To install NewRelic, you need to get the agent onto the machine.  In our case we are going to leverage the annex:</p>

<p>```bash</p>

<h1>====================================================</h1>

<h1>=== Install NewRelic</h1>

<h1>====================================================</h1>

<h1>===================================</h1>

<h1>=== Server</h1>

<h1>===================================</h1>

<p>rpm -Uvh http://download.newrelic.com/pub/newrelic/el5/i386/newrelic-repo-5-3.noarch.rpm
yes | yum -y install newrelic-sysmond
nrsysmond-config --set license_key=key</p>

<p>/etc/init.d/newrelic-sysmond start</p>

<h1>===================================</h1>

<h1>=== Java</h1>

<h1>===================================</h1>

<p>export APP_VERSION=3.21.0
export APP_FULL_VERSION=newrelic-java-${APP_VERSION}</p>

<p>mkdir -p .temp
cp it/resource/${APP_FULL_VERSION}.zip .temp/</p>

<p>./bin/inflatePaths.sh .temp/${APP_FULL_VERSION}.zip</p>

<p>mkdir -p /opt
cp -fr .temp/newrelic /opt/</p>

<p>cp -fr ${RESOURCE}/newrelic.yml /opt/newrelic/newrelic.yml</p>

<p>```</p>

<p>The first section puts on the system-monitoring agent for newrelic.
The second section has two parts.  The first part puts the general NewRelic agent onto the machine, and the second part
enables us to override (overlay) the default configuration with our own.  The most important part is to replace the
license, but there are many things that can be configured within the NewRelic agent.</p>

<p>Finally, we need to launch with the agent configuration into the java / 'gradew' launcher:</p>

<p>```bash</p>

<h1>Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.</h1>

<p>DEFAULT_JVM_OPTS="-javaagent:/opt/newrelic/newrelic.jar"
```</p>

<p>After doing this and waiting for the metrics to hit the NewRelic servers, we get some nice visuals:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-7/addstack7_newrelic2.png" />
<img src="http://markfussell.emenar.com/images/addstack-7/addstack7_newrelic4.png" />
<img src="http://markfussell.emenar.com/images/addstack-7/addstack7_newrelic5.png" />
<img src="http://markfussell.emenar.com/images/addstack-7/addstack7_newrelic6.png" />
<img src="http://markfussell.emenar.com/images/addstack-7/addstack7_newrelic7.png" />
<img src="http://markfussell.emenar.com/images/addstack-7/addstack7_newrelic7.png" /></p>

<h3>Operational Monitoring: Nagios and Icinga</h3>

<p>The above monitoring is not 'alert' oriented.  It lets you drill into the details of what is happening
in operations both currently and somewhat into the past.  To be a bit more alert oriented, you need
to go down a different path.  The most mature open source path is the Nagios / Icinga double path (<a href="http://nagios.org/">http://nagios.org/</a>,
 <a href="http://icinga.org/">http://icinga.org/</a>).</p>

<p>An important aspect of monitoring is to have <em>multiple</em> monitors on your network.  And, in general, for the monitors
to be outside the data center.  Agents within the data center can relay information out, but if your monitors fail
inside the data center, you are (unknowingly) blind.</p>

<p>So for Nagios, we can demonstrate monitoring from the developers (or operations dashboard) machine vs.
within the data center.  Because of the presence being visible from anywhere, monitoring configuration can happen
anywhere that you can pull out a git repository.</p>

<p>Examples of Nagios views are:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-7/addstack7_nagios1.png" /></p>

<p><img src="http://markfussell.emenar.com/images/addstack-7/addstack7_nagios2.png" /></p>

<p>Where the lists of hosts to monitor and what to monitor comes from text configuration files.</p>

<p><code>
define host {
   host_name   {host_name}
   use         {node_type}
   alias       {node_id}
   address     {node_public_address}
   register    {registration_order}
}
</code></p>

<p>And these files can trivially be generated from the presence information, and updated if
anything changes.  An important aspect is to make sure to turn off the monitoring system
when a node is going down <em>intentionally</em>.  So the 'node_state' status and 'node_app_state'
status are critical to have come through the presence information for monitoring to
not be 'noisy'.  A noisy monitor is a monitor that will quickly be forever ignored.</p>

<p>Although Nagios and Icinga have dashboards, everything should go into HipChat so everyone
can see the history and stability/instability of the system.  You can even publish the status
  publicly so your users will know there is a production problem. If you enable public chat
  in either HipChat or elsewhere, the users can both see the status and ask for predictions
  of when issues are resolved.  A much higher-touch relationship with users can make them
  longer users (this retention aspect was very true of Winster where the CEO was <em>online</em>
  and could be chatted with a good portion of the evening.  Kind of like walking the floors
  of the casino or Tim Cook being in the University Apple Store.).</p>

<h2>Conclusion</h2>

<p>Although it is more operational than "application stack", the ability to monitor and analyze your
application's performance and behavior is critical to any production deployment of it.  So you
should think about it early and not as an afterthought.  All logging should go into the logging pipeline
(no System.println or equivalent) and be searchable through that pipeline at one or more aggregators.
Start out with a metrics system like NewRelic to get a bunch  of valuable things for free
and you can later add in new application-specific metrics.
And get the basics of operational monitoring up early and you will know if the application and the
IT is reliable long before it gets into the production data center.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-6]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-6/"/>
    <updated>2015-10-17T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-6</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.  The fifth added some major aspects to the stack: Semi-Structured Data, Templates,
and Dual or Isomorphic scripting.</p>

<h2>Which UI framework?</h2>

<p>The <a href="/blog/addstack-4/">fourth article</a> discussed UI alternatives, but it was mostly about 'architectural' alternatives
 and did not recommend a particular framework to use.  I believe that is the correct order: <em>how you use</em> the framework
 is usually more important than the framework itself.  People can correctly and improperly use all kinds of different technology.
Use a hammer correctly and you might have a slight penalty (rubber vs. metal), but
use it wrong (your thumb is targetable) and you can be seriously hurt.</p>

<p>There are a number of popular frameworks:</p>

<ul>
<li>Angular</li>
<li>Ember</li>
<li>Backbone</li>
<li>Sencha</li>
<li>etc.</li>
</ul>


<p>And deciding between them may seem like it should be done as "which has the best features?" but unless
one of them has a killer feature  that you care about
(Sencha can run the same code with both a desktop and mobile UI), and is worth its penalties (Sencha
is proprietary and very 'different') then 'best features' is basically meaningless.  A better question is "Which
one do I understand the best?" and "Which one can other people on the team learn and share-code the best?".</p>

<!--more-->


<p>Taking out 'Sencha' from the above and you get a few different viewpoints on the web:</p>

<ul>
<li><a href="http://blog.yodersolutions.com/why-i-recommend-emberjs-over-angularjs/">http://blog.yodersolutions.com/why-i-recommend-emberjs-over-angularjs/</a></li>
<li><a href="https://www.airpair.com/js/javascript-framework-comparison">https://www.airpair.com/js/javascript-framework-comparison</a></li>
<li><a href="https://www.quora.com/Is-Angular-js-or-Ember-js-the-better-choice-for-JavaScript-frameworks">https://www.quora.com/Is-Angular-js-or-Ember-js-the-better-choice-for-JavaScript-frameworks</a></li>
</ul>


<p>And dropping Backbone, the distinction is really:</p>

<ul>
<li>Angular – Powerful, dry, and scale-limited framework</li>
<li>Ember – Less dry, more opinionated, and more scalable</li>
</ul>


<p>With Angular you have the ability to shoot yourself more and get confused more.  With Ember you will likely
have to be more explicit, but the convention and the explicitness should make the code more readable and
maintainable.</p>

<p>Angular is so similar to Flex that it is very intuitive to me (even directives), but I have seen it used
in ways I think the Angular team would be shocked by.  Sencha is confusing but is so mature, documented,
and powerfully-fragile (do something wrong and you get a terribly visible break) that you can't really use it wrong.
Ember appears to have the advantages of Rails and Grails... as the framework innately 'works' you can't
really deviate very much.  Also, Ember causes certain ripples (handlebars vs. dust) so you need to
decide early whether you want complete alignment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-5]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-5/"/>
    <updated>2015-10-16T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-5</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.</p>

<p>This article is about some fairly advanced capabilities, but capabilities that many projects find useful,
and so should be considered within the context of the overall context.  They are:</p>

<ul>
<li> Data Flexibility and Templating</li>
<li> Server Side Scripting</li>
</ul>


<h2>Data Flexibility and Template Systems</h2>

<p>One of the more interesting capability of an application is when users can control the content and presentation
of information.  Content is relatively easy given pure structured information is trivial to store in most
any database.  As the content becomes more unstructured you need to shift models and store it in a 'meta'
structure like JSON.  As the content becomes bigger, you need the flexibility of very large objects (BLOBs and CLOBs)
stored either in the database or potentially within content repositories like S3.  Using the Annex model
discussed earlier, you can simply store a hash in the database and the actual content on S3, and then
<em>the client</em> can pull down the information without taxing your server network at all.</p>

<p>Having flexible data is not very useful unless you can present it.  If the data is in JSON, you need to
be able to take JSON and render it into text, HTML, or something the programming language can work with.
There are a number of template systems out there:</p>

<ul>
<li> Mustache</li>
<li> Jade</li>
<li> Dust</li>
</ul>


<!--more-->


<p>Deciding amongst them depends on who is going to be writing the template and 'where' it is
going to execute.  But I recommend (a) making it language agnostic, (b) making it output agnostic,
and (c) making writing HTML templates a lot like writing HTML (and not something weird even if "more
powerful").  I have seen a lot of developers argue that you should write HTML in some YAML like language.
That is like saying you should write Java in some LISP-like language.  It makes no sense to change
syntax that dramatically even if every language is computationally equivalent.  HTML is verbose
because people like that lack of ambiguity (The original SGML was much more ambiguous and powerful).
There are plenty of auto-complete tools out there that help with HTML.  And everyone can follow
'fragments' of HTML better because the fragment has so much redundant information.</p>

<p>Among the above, it seems that Dust <a href="http://dustjs.com/">http://dustjs.com/</a> is a well supported successor to Mustache / Handlebars.
Besides having LinkedIn support, it appears the company <a href="http://cloudcms.com/">http://cloudcms.com/</a> is using it as well.  There is
a comparison of frameworks at <a href="https://engineering.linkedin.com/frontend/client-side-templating-throwdown-mustache-handlebars-dustjs-and-more">Templating Throwdown</a></p>

<p>By combining an ability to retrieve arbitrary information with arbitrary templates, we can enable
a user to generate any page they want... either for themselves or for other people.</p>

<h3>Scary!</h3>

<p>OK, the above should seem both epic and <em>scary</em>.  A user can generate arbitrary HTML pages
including JavaScript?  Doesn't that mean they could do <em>anything</em> including hijack another user?  Get
their password?  Stuff like that?</p>

<p>If you do it wrong... yes... yes they can.  Fortunately we have Facebook, MySpace and other companies that
show how to do it wrong and then fix the problem.  The general solution is:</p>

<ul>
<li>Users never authenticate with 'The Page'.  They only authenticate with you.</li>
<li>You give the page a valid one-time token for that third party to contact you on behalf of a user</li>
<li>You make sure to verify the token before doing anything for the user, and only allow the page / third party to do things you (or the user) approve</li>
</ul>


<p>This model makes sure the third party is not doing anything dangerous to your site...
or at least not successfully doing anything.</p>

<h2>Server-Side Scripting</h2>

<p>Along with the data flexibility combined with templating described above, there is an even scarier and more powerful
option to enable within-server scripting.  This ability to have code be mutable at run-time enables some easy upgrades
and 'forks' (customers doing their own thing) in exchange for much less surety that the code is running, some performance
trades, a more complex system model (flowing back and forth between JavaScript and Java), and potential for security
holes.  I have seen a number of systems have scripting and the most successful variations have been:</p>

<ul>
<li>Limited scripting to support customizing very controlled situations (e.g. Templating, Workflow, etc.)</li>
<li>Hog-wild scripting that enables customers to 'fork' the code base, where that code base is being run on un-shared servers</li>
</ul>


<p>If you want to have a customizable product, the second approach is definitely very powerful.  Otherwise, the first is probably
safer and simpler.  An example of the benefits to server-side (and ultimately hybrid or 'isomorphic') is described well here:</p>

<ul>
<li> <a href="https://www.youtube.com/watch?v=pgvlHGi9VXM">https://www.youtube.com/watch?v=pgvlHGi9VXM</a></li>
<li> <a href="http://isomorphic.net">http://isomorphic.net</a></li>
</ul>


<h3>What scripting language?</h3>

<p>The obvious modern scripting language to use is JavaScript.  Because of its' pervasiveness in the browser, it is among
the better understood languages out there.  It also has a ridiculously simple and powerful language model (JS is a
(maybe accidental?) descendant of Self, which was an amazingly simple and powerful language too).  And although it does
not have a lot of libraries, running JavaScript via Nashorn enables you to call into the Java world.  A tutorial on
Nashorn is here:</p>

<ul>
<li><a href="http://winterbe.com/posts/2014/04/05/java8-nashorn-tutorial/">http://winterbe.com/posts/2014/04/05/java8-nashorn-tutorial/</a></li>
</ul>


<h2>Summary</h2>

<p>This article described augmenting both the server and the client by putting in three stack
'ingredients' that enable a lot of power (either broadly or in limited situations):</p>

<ul>
<li>Flexible/Semi-structured Data – JSON – On both the client and the server (and the database)</li>
<li>Templating – Dust – On both the client and the server (by the next one)</li>
<li>Scripting: Dual and Isomorphic – JavaScript / Nashorn – Both client and server can then have leverage the same scripting technologies, and potentially chose whether to run something on the server or on the client (or both to enhance SEO)</li>
</ul>


<p>These ingredients make for a much more powerful and flexible application.  These may be overkill for some projects, but
 they are definitely <em>generally useful</em> and whether 'utilized' they should be considered 'available' when needed.</p>
]]></content>
  </entry>
  
</feed>
