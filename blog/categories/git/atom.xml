<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Git | Polyglot]]></title>
  <link href="http://markfussell.emenar.com/blog/categories/git/atom.xml" rel="self"/>
  <link href="http://markfussell.emenar.com/"/>
  <updated>2015-10-11T13:47:17-07:00</updated>
  <id>http://markfussell.emenar.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-10]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-10/"/>
    <updated>2015-10-10T02:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-10</id>
    <content type="html"><![CDATA[<p>This is the tenth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, HipChat integration, presence, EC2, configuring nodes, and inter-machine presence.</p>

<h2>A good, opinionated, framework</h2>

<p>Back in 1972, Smalltalk became the first Object-Oriented Programming Language (Simula was Object-Based but there is a difference).
For decades this kind of language was 'esoteric'.  It was like LISP or Prolog or APL: somehow exotic and inaccessible.
I was lucky: I had access to Smalltalk at Caltech.  I had access to lots of crazy expensive things at Caltech and that
made the exotic (e.g. making your own chips) into the mundane (e.g. made lots of chips, they were commonly broken,
had to be re-fabricated, and I eventually got bored with all that and moved a level up).</p>

<!-- more -->


<p>But back to the language of Smalltalk.  The problem with Smalltalk is that it appears to be a language when it is
actually a computer. 'C' was a language.  It made programs. 'Pascal', 'Lisp' (sans Machine), 'Fortan', and so on...
they were all languages.  Smalltalk <em>contains</em> a language.  It is named Smalltalk (darn).  But Smalltalk-80 was not
<em>just</em> a language, it was an <em>entire running operating system with applications and full source</em>  It could boot on
most any machine that you made the 'bootstrap' code work on.  To make a new Smalltalk-80 machine, you cloned either
the primordial Smalltalk-80 'image' from PARC, or you cloned your own modified 'image'.  And by 'image' this is
basically the same concept as cloning a disk... bit by bit identical copy that happens to be on a different disk / computer.</p>

<p>Eventually OOP became mainstream with Java, C++, Objective-C, Ruby, Python, and the like.  So people thought they
were getting the "Smalltalk" (or LISP Machine) benefits.  But they left out the 'computer' that went with the language.</p>

<h3>Why opinionated?</h3>

<p>The Smalltalk computer was quite functional and thoroughly opinionated.  It <em>already did</em> a bunch of things and showed
you how it did them.  It wasn't opinionated like a human usually uses the term: "You should build that house out of bricks, not straw".
It was opinionated like the planet is: "I have already created lots of flora and fauna... please use them wisely".  Even
how humans on the planet are: "We have already created plenty of roads... please use them instead of driving through yards"</p>

<p>Opinionated is basically a synonym for "Working".  Smalltalk computers "worked" so don't break it.  They work, so you
should probably copy them for anything similar.  And they work, so you might want to study how they work even if you
are going to be creative later.</p>

<h3>Modern 'working' frameworks</h3>

<p>Early frameworks (say for Java) 'kind-of-worked'.  They didn't fully work, but you could 'configure' them to work.
That is like getting all 'IKEA' furniture for your house.  You could easily build it wrong.  It could not work
together.  Yes, you get to 'tweak' it, but if someone simply offered "a furnished house" you would save a lot of
time and leverage their full sense of design.  Or you could go to a different furnished house that more closely matched your tastes.</p>

<p>The later fully-working / opinionated frameworks (like Ruby/Rails) truly worked out of the box.  They would come up with a UI, Business/Domain
layer, and a Database layer.  You could add things to the UI and it would go down the whole stack.  Add things to the database
or Domain, and it would bubble up/down.  For the framework to do these things it had to have a model for what software (in its full form)
looks like.  These frameworks had patterns/templates/rules for building things at command.  This isn't quite as good as Smalltalk ("it already exists")
but it is getting close, especially with sample applications available.
It also gets rid of the one problem / hurdle with Smalltalk full-computers: you had to strip them
of things you didn't want customers to see / use / clone.</p>

<h3>Languages</h3>

<p>There are many modern languages.  They are mostly quite similar and boring in the language themselves.  The community around the
language makes much more of a difference, and the libraries / frameworks that exist based on that community's interest.</p>

<p>I mentioned that I switched to Java pretty early on, which cost me productivity.  But I wanted the community and their
libraries.  Java was popular enough that it had multiple communities associated with it.  Some were crazy stupid and
created things (even tried to mandate use of things) that were completely stupid.  But other communities continued
to plug along and evolve libraries and frameworks that are better than you can get in other languages.  On the whole,
I believe the Java ecosystem is by far the best 'hub' to build most custom development and to pair
with other tools/components in other languages.  And by Java, I mean Java, Groovy, and potentially other JVM-targeting
languages.  The less Java-like the language, the less likely I would consider it acceptably an 'other'.</p>

<h3>Framework</h3>

<p>I believe the best (general) application framework in Java is Grails, which lives on top of the Spring stack.  It is
very mature and has good minds in the drivers seat.  It gets simpler and more powerful every generation.  If Spring
does something right, Grails simply uses it.  If not, Grails augments it.  Very rational.  Very powerful.</p>

<h2>The first application</h2>

<p>The first application will simply be the default applications with a grails 'create-app'.  To get the application we
need to get grails on the 'app1' nodes, create the application, and then run it.</p>

<p>Grails needs Java, but ec2 instances automatically have that.  In other environments we would use something like:</p>

<h3>installJava.sh</h3>

<p>```bash</p>

<h1>!/bin/bash</h1>

<h1>================================================</h1>

<h1>=== Java</h1>

<h1>================================================</h1>

<p>export JAVA_VERSION=7u79
export JAVA_FULL_VERSION=jdk-${JAVA_VERSION}-linux-x64</p>

<p>mkdir -p .temp
cp it/resource/${JAVA_FULL_VERSION}.rpm .temp/</p>

<p>./bin/inflatePaths.sh .temp/${JAVA_FULL_VERSION}.rpm</p>

<p>rpm -i .temp/${JAVA_FULL_VERSION}.rpm</p>

<p>```</p>

<p>The advantage of storing the RPM within our own system is speed of access and reliability.  EC2 to S3 communication
is very fast.  And S3 has never been down (AFAIK) at all, let alone when EC2 is running.  We also lock down on the
version we want vs. using 'yum' without an explicit version.</p>

<h3>installGrails3_x.sh</h3>

<p>For grails we will get the latest version</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<h1>==========================================================</h1>

<h1>=== Install Grails 3.x</h1>

<h1>==========================================================</h1>

<p>curl -s get.sdkman.io | bash
source "$HOME/.sdkman/bin/sdkman-init.sh"
yes | sdk install grails</p>

<p>source ~/.bashrc
grails -version</p>

<p>```</p>

<p>We need to source '~/.bashrc' so we get the additions to our path.</p>

<h3>Create 'test' application</h3>

<p>At this point we have grails on the machine and can simply
```bash
mkdir -p /root/app/
cd /root/app</p>

<p>grails create-app test
cd test
grails run-app
```</p>

<p>The application will come up at 'localhost:8080' and if you wget/curl it, it returns the generated 'index.html' file:</p>

<p>```html
&lt;!doctype html>
<html lang="en" class="no-js"></p>

<pre><code>&lt;head&gt;
    &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;
    &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt;
    &lt;title&gt;Welcome to Grails&lt;/title&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;
</code></pre>

<p>...</p>

<pre><code>    &lt;div id="page-body" role="main"&gt;
        &lt;h1&gt;Welcome to Grails&lt;/h1&gt;
        &lt;p&gt;Congratulations, you have successfully started your first Grails application! At the moment
           this is the default page, feel free to modify it to either redirect to a controller or display whatever
           content you may choose. Below is a list of controllers that are currently deployed in this application,
           click on each to execute its default action:&lt;/p&gt;

        &lt;div id="controller-list" role="navigation"&gt;
            &lt;h2&gt;Available Controllers:&lt;/h2&gt;
            &lt;ul&gt;

            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class="footer" role="contentinfo"&gt;&lt;/div&gt;
    &lt;div id="spinner" class="spinner" style="display:none;"&gt;Loading&amp;hellip;&lt;/div&gt;
&lt;/body&gt;
</code></pre>

<p></html>
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-9]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-9/"/>
    <updated>2015-10-08T02:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-9</id>
    <content type="html"><![CDATA[<p>This is the ninth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, HipChat integration, presence, EC2, and configuring nodes.</p>

<h2>Using Presence for configuration</h2>

<p>So far, presence has been just information that 'humans' consume.  It shows up on dashboards, in chat rooms, and so on,
but nothing has acted upon it.  Until now!</p>

<p>We have 'app' and 'db' nodes.  Clearly the 'app' nodes need to find the 'db' nodes or the app is not going to be
able to persist much.  The 'db' here happens to be 'Maria' but it could be anything from a single DB node to a
cluster of Riak nodes.  At the moment, I just want to get the information that a 'db' node knows ("I exist!", "My IP is this!")
over to the 'app' nodes so they can process it.</p>

<h3>It is already there?</h3>

<p>But wait?  All nodes have 'repo4' for writing?  Don't they already have everything in 'repo4' for reading as well?</p>

<p>And so they do.  The presence information is already there waiting patiently for somebody or someboty to read it.</p>

<!-- more -->


<p>As of this writing, repo4 looks like this:</p>

<p><img src="http://markfussell.emenar.com/images/add-9/add9_all.png" /></p>

<p>And the live hipchat still looks like this:</p>

<p><img src="http://markfussell.emenar.com/images/add-8/add8_demo1.png" /></p>

<p>So the DB server is definitely there:</p>

<p><code>
i-4e7cb59a:fed1/db1: Launched!
</code></p>

<p>And the information is there:
```json
{</p>

<pre><code>"filetype": "nodepresence",
"value": {
    "a": "a",
    "deployment": "fed1",
    "initgitrepo": "repo2_petulant-cyril",
    "instance-id": "i-4e7cb59a",
    "nodepart": "db1",
    "stacktype": "lad1",
    "state": "done",
    "statelog": "setup:20151008-174646;initdone:20151008-174830;",
    "statetss": "20151008-174830"
}
</code></pre>

<p>}
```</p>

<p>So the only issue is for nodes to 'find their partners'</p>

<h3>Finding the partners</h3>

<p>By the HipChat there are only three nodes alive, so problem one is finding live nodes vs. dead nodes.  There are
two levels to that:</p>

<ul>
<li> Finding plausibly live nodes</li>
<li> Finding truly awake nodes</li>
</ul>


<p>The simplest approach to the first is to make sure there is some kind of heartbeat within 'statetss'.  Every-minute
is clearly possible, but a bit noisy if done in the main part of repo4.  It would be nice to not to see the heartbeat
block out the actual state change information that is already there. An interesting alternative is to 'flatten time'
and have an alternative branch that stores information as 'it/presence/flattime/timestamp'.  Or given we are storing
the information differently, we could use the main branch and just change the comment to mention 'flattime'.
Yes, the information in the files would not change very often.  But Git stores files separate from paths,
so there is very little overhead to adding new paths to identical files.</p>

<h4>Time flattened</h4>

<p>repo4 has folder under 'presence' called 'flattime' which contains the presence information where every checkin is a new path.
To keep things manageable the timestamp is complete 'YYYYMMDDHHMM', but year/month/day/hour/ is used to organize it.
Seconds are not used because we want everything to be together and there is no guarantee the seconds would match
between machines.</p>

<p>Looking at a few minutes of time, we get something like this:</p>

<p><img src="http://markfussell.emenar.com/images/add-9/add9_flattime1.png" /></p>

<p>The files change a bit because the machines are switching states and at the 'capture' moment could be in almost any state
of their 'state machine'.</p>

<h4>How precise?</h4>

<p>So this is quite precise in time and you could certainly slow it down.  Sometimes providers get annoyed if you use
git this way, but the software itself is thoroughly comfortable with it.  You can get some impressive merge graphs
as the machine count goes up.</p>

<p><img src="http://markfussell.emenar.com/images/add-9/add9_merge1.png" /></p>

<p>So making things less often and more jittered will help alleviate some stress.  Since
this is only the first stage of presence (what exists and is plausibly alive), we will deal with stale data in the
second stage.</p>

<h3>Who is what?</h3>

<p>So we have a directory of JSON files and we want to find certain kinds of partners.  It is simplest to just
run through all the files and see what is inside them.  The files can be loaded one-by-one or concatenated together
into a working temporary file.</p>

<p>A basic python script could look like this:</p>

<h4>buildLiveServerJson.py</h4>

<p>```python</p>

<h1>!/usr/bin/env python</h1>

<h1>========================================================</h1>

<h1>=== buildLiveServerJson.py</h1>

<h1>=== This builds a JSON structure of server presence data</h1>

<h1>=== from a directory of presence data</h1>

<h1>=========================================================</h1>

<p>import json
import string
import os
import sys
from optparse import OptionParser
from datetime import datetime,timedelta</p>

<p>now = datetime.utcnow()
tss = now.strftime("%Y%m%d%H%M%S")</p>

<p>backminute = timedelta(minutes=-1)
before = now + backminute</p>

<p>tsm = before.strftime("%Y%m%d%H%M")
datepath = before.strftime("%Y/%m/%d/%H")</p>

<p>USAGE_STRING = "usage: %prog [options]"</p>

<p>parser = OptionParser(usage=USAGE_STRING)
parser.set_defaults(verbose=True)
parser.add_option("--source", action="store", type="string", dest="source", help="The source directories of the presence files.  Use a comma to separate multiple source directories.")
parser.add_option("--adddatepath", action="store_true", default=False, dest="adddatepath", help="Whether to add the current datetime path to the source")
parser.add_option("--suffix", action="store", type="string", dest="suffix", help="A suffix to add at the end of the source")
(options, args) = parser.parse_args()</p>

<p>source = options.source.strip()
adddatepath = options.adddatepath
suffix = options.suffix</p>

<p>if not source:</p>

<pre><code>parser.print_help()
exit()
</code></pre>

<p>full_source = source</p>

<p>if adddatepath:
   full_source = full_source + datepath + '/' + tsm</p>

<p>if suffix:
   full_source = full_source + suffix</p>

<h1>=========================================================</h1>

<h1>=========================================================</h1>

<h1>=========================================================</h1>

<p>sys.stdout.write('{"source":"'+source+'","suffix":"'+suffix+'","full_source":"'+full_source+'","tss":"'+tss+'","tsm":"'+tsm+'","datepath":"'+datepath+'","nodes":[')</p>

<p>isfirst = True
for f in os.listdir(full_source):
  f_json = json.load(open(full_source+f))</p>

<p>  if isfirst:</p>

<pre><code> isfirst = False
</code></pre>

<p>  else:</p>

<pre><code> sys.stdout.write(",")
</code></pre>

<p>  sys.stdout.write(json.dumps(f_json))
sys.stdout.write("]}")</p>

<p>sys.stdout.flush()</p>

<p>```</p>

<p>Our first stage is to get a list of plausible nodes and store that:</p>

<p><code>bash
python buildLiveServerJson.py --source=/root/gitrepo/repo4_sagacious-adventure/it/presence/flattime/ --adddatepath --suffix /all/ | python -mjson.tool &gt; /root/nodeinfo/liveserver.json
</code></p>

<p><img src="http://markfussell.emenar.com/images/add-9/add9_json1.png" /></p>

<p>Next we can filter out the ones that don't respond to our 'awake' check.  That leaves
us with one or more remaining.  Depending on the kind of system you may actually want to know a bunch of nodes vs.
just one (e.g. ZooKeeper).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-8]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-8/"/>
    <updated>2015-10-08T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-8</id>
    <content type="html"><![CDATA[<p>This is the eighth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, HipChat integration, presence, and EC2 integration.</p>

<h2>Configuring Node Parts and even fuller Presence and visibility</h2>

<p>So far our node was a generic 'ControlNode'.  A ControlNode is a node that is in your data center
(to be near the other nodes), similar to your actual nodes, and configured to be able to do interesting tasks.
It is not a critical part of anything, so you can fiddle with it and just throw it away.  Say you want to
start configuring a database node.  You launch and login to a ControlNode and then try to install a database
(for example Maria).</p>

<!-- more -->


<p>```bash
cat > /etc/yum.repos.d/mariadb10.repo &lt;&lt;EOS</p>

<h1>MariaDB 10.0 CentOS repository list - created 2015-10-08 15:16 UTC</h1>

<h1>http://mariadb.org/mariadb/repositories/</h1>

<p>[mariadb]
name = MariaDB
baseurl = http://yum.mariadb.org/10.0/centos7-amd64
gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB
gpgcheck=1
EOS</p>

<p>yum install MariaDB-server MariaDB-client
```</p>

<p>Assuming you changed to root for the instance:</p>

<p><code>bash
sudo bash
</code></p>

<p>This works!  After confirming some things along the way...</p>

<p>OK, so now we want to have our database servers install MariaDB.  We first need an 'installMaria' script with the above
in it.  Say</p>

<h3>installMaria10.sh</h3>

<p>```bash</p>

<h1>!/bin/bash</h1>

<h1>================================================</h1>

<h1>=== Java</h1>

<h1>================================================</h1>

<p>cat > /etc/yum.repos.d/mariadb10.repo &lt;&lt;EOS</p>

<h1>MariaDB 10.0 CentOS repository list - created 2015-10-08 15:16 UTC</h1>

<h1>http://mariadb.org/mariadb/repositories/</h1>

<p>[mariadb]
name = MariaDB
baseurl = http://yum.mariadb.org/10.0/centos7-amd64
gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB
gpgcheck=1
EOS</p>

<p>yum install MariaDB-server MariaDB-client
```</p>

<h3>adding init</h3>

<p>And unless you want every node to install Maria, you need to add an 'init' for the type of node we are dealing with.
In our case, the StackType is 'lad1' (Load,App,Db,1) and the node type / part is 'db1'.</p>

<p>So we get this hierarchy:</p>

<p><img src="http://markfussell.emenar.com/images/add-8/add8_hierarchy1.png" /></p>

<p>And the content of the 'init.sh' file is simply:
```bash</p>

<h1>!/bin/bash</h1>

<h1>====================================================</h1>

<h1>=== fed1/db1</h1>

<h1>====================================================</h1>

<p>bash ${COMMON}/installMaria10.sh</p>

<p>```</p>

<h3>CloudFormation</h3>

<p>We have a new CloudFormation named 'awscf4_Fed1Db1' with the simple change of the nodepart being 'db1'</p>

<p>```json</p>

<pre><code>"TemplateConstant" : {
  "stacktype" : { "value" : "lad1" },
  "initgitrepo" : { "value" : "repo2_petulant-cyril" },
  "nodepart" : { "value" : "db1" },
  "state" : { "value" : "presetup" },
  "statetss" : { "value" : "" },
  "statelog" : { "value" : "" },
  "deployment" : { "value" : "fed1" }
},
</code></pre>

<p>```</p>

<h3>Demo or Die!</h3>

<p>Since the previous presence description, the presence system has upped itself and now nodes check-in with
more information than before.  After launching two 'app' stack and one 'db' stack we get this:</p>

<p><img src="http://markfussell.emenar.com/images/add-8/add8_demo1.png" /></p>

<p>So clearly our nodes know who they are, what deployment they are in, what the 'part' in that deployment is, and how to
"do work". But are they actually what they say they are?</p>

<h2>Being the 'user', fixing the 'user'</h2>

<p>If you use the installMaria script above, it will not work.  Because I said: "This works!  After confirming some things along the way..."
During 'boot' there is no user to confirm anything.  So the 'yum' part fails although the yum repository is there
(the user is 'root' so it has permission).  It ran the script but it didn't work under 'automation'.
The three annoying issues in automation:</p>

<ul>
<li> The user could be different from the user you think it is (say 'ec2' vs. 'root')</li>
<li> The user is not interactive</li>
<li> The user did not "launch a login shell" and so some launch things that happen for you did not happen for them.</li>
</ul>


<p>There are trivial and super-effective solutions to all of these, but until you get them right, you can bang your head
quite a bit.</p>

<h3>Who is the user?  'root'</h3>

<p>The user provisioning a machine should always be 'root'.  Yes, 'root' is dangerous.  Because 'root' is powerful.  And
given (a) if you mess up you simply kill the machine, and (b) everything is from version-controlled source files...
you can handle that power.  So don't add silly hoops to jump through.  On a ControlNode, immediately 'sudo bash'.
And if for some reason the default user isn't 'root' in a launch or cron script, 'su root' or 'sudo bash' to fix that.</p>

<h3>Is the user interactive? 'no'</h3>

<p>We are doing production automation that is designed to scale into thousands of machines.  No one is going to answer
questions for thousands of machines.  That is not 'scalable' or at all valuable.  You should always know all the
answers when a machine launches.  So script any UI that really requires some value put in, or use the variant of
a command that has default answers.</p>

<p>The true script for 'installMaria' has this line.</p>

<p><code>bash
yes | yum -y install MariaDB-server MariaDB-client
</code></p>

<p>The 'yum -y' <em>should</em> never ask any questions.  But just in case it does, I give it a 'y' for every answer.  If you
are testing something and get a question, check if it has a flag like '-y'</p>

<p><img src="http://markfussell.emenar.com/images/add-8/add8_yes.png" /></p>

<h3>Has the user launch as a login shel? 'yes'</h3>

<p>Since getting on a machine without 'logging in' is quite a bit more painful than 'ssh' into the machine, just make sure
any 'init' and 'work' script has read the files a login shell would automatically read.</p>

<p>A simple 'source /root/.bashrc' fixes the problem immediately</p>

<p>```bash</p>

<h1>========================================</h1>

<h1>=== Do the work for this repository</h1>

<h1>========================================</h1>

<p>source /root/.bashrc
...
```</p>

<h2>Node Work</h2>

<p>Just like the 'init' hierarchy, the 'db1' nodes can have their own work items to do regularly by simply adding the 'work.sh'
into the hierarchy:</p>

<p><img src="http://markfussell.emenar.com/images/add-8/add8_hierarchy2.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-7]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-7/"/>
    <updated>2015-10-04T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-7</id>
    <content type="html"><![CDATA[<p>This is the seventh installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, HipChat integration, and presence.</p>

<h2>Fuller Presence and EC2 Integration</h2>

<p>In the previous part, I went through a very simple but powerful model of 'presence' using simply GitHub repositories.
The content of those presence statements was enough to figure out what nodes exist, but not much more about them.
The second level of presence is to update the state of the node as it changes.  For example, a node goes through
a few bootstrap steps:</p>

<ul>
<li> presetup – The node before any updates are possible (no ability to change status)</li>
<li> setup – The beginning of the 'setup' phase where the node is alive enough to change it's status</li>
<li> initdone – The time a node is done are initialization and can start doing 'work' as the 'nodepart' it is</li>
</ul>


<p>A node getting to 'setup' is pretty important: before that it may be a zombie!  And we don't want zombie's in
our federation!</p>

<!-- more -->


<p>So far for the ADD we now have four resources within which track node states:</p>

<ul>
<li> On the node (say '/root/log' or '/root/nodeinfo/state.txt)</li>
<li> Within the presence system</li>
<li> Within HipChat</li>
<li> On EC2 itself</li>
</ul>


<p>I recommend using <em>all</em> of them.</p>

<h3>On node</h3>

<p> On the node is very helpful in that it is isolated from any other failures.  You
 can 'tail' the logs or 'cat' the state file.  This tangibility helps understand things and debug if there is failure.</p>

<h3>Within Presence</h3>

<p> Within the presence system is the most powerful and flexible.  It is easy to see history and all the activity of your
 nodegrid.  And the nodegrid can use the presence system to figure out what nodes are present and in full 'working'
 mode.</p>

<h3>HipChat</h3>

<p> Within HipChat lets everyone see and talk about the changes.  It can get noisy though, so you need
 to separate the 'chatty' state changes from the 'critical' ones.  An example of 'critical' is when a machine realizes
 it is broken.  It is running the cron job, but something is wrong and it can tell that the 'work' is not completable.
 I call this being 'wedged'.  If a machine is 'wedged', it should tell people and then we can work on improving its
 DNA so it can unwedge itself in the future.  And then kill the machine.</p>

<h3>EC2</h3>

<p> By using EC2 tags you can leverage the EC2 dashboard.  I view 'tags' as read-only because the ADD should not get
 attached (be dependent) on EC2, but it is helpful for visibility.</p>

<h3>Examples</h3>

<p>The following show two machines initializing through Presence, HipChat, and EC2.  The only trigger for this was
killing the existing two instances: the AutoScalingGroup automatically replaced them.</p>

<h4>Launching viewed within EC2 Dashboard</h4>

<p>Nicely the 'add:' prefix makes all the properties that are most important appear on the left.  Some of the names
of concepts are intentionally alphabetically 'sorted' so they appear in the correct column.</p>

<p><img src="http://markfussell.emenar.com/images/add-7/add7_ec2_cv1b.png" /></p>

<p>Click here: <a target="add7_ec2_cv1b" href="http://markfussell.emenar.com/images/add-7/add7_ec2_cv1b.png" >add7_ec2_cv1b</a> to expand.</p>

<p>The ‘stacktype’ of ‘lad1’ in the capture is short for a stack of</p>

<ul>
<li>Load Balancer</li>
<li>Application</li>
<li>Database</li>
</ul>


<h4>Working viewed within HipChat</h4>

<p><img src="http://markfussell.emenar.com/images/add-7/add7_hipchat_cv1.png" /></p>

<h4>Working viewed within Presence / SourceTree</h4>

<p><img src="http://markfussell.emenar.com/images/add-7/add7_presence_cv1.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-6]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-6/"/>
    <updated>2015-10-02T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-6</id>
    <content type="html"><![CDATA[<p>This is the sixth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, and HipChat integration.</p>

<h2>'Part' Provisioning</h2>

<p>Each node plays a singular 'Part'.  A 'part' is a unique combination of roles (in the chef sense) that identifies
exactly how the node should be provisioned, usually globally, but at least for each stacktype.  A standard array
of parts would be the LAMP stack:</p>

<ul>
<li> Load Balancer (lb)</li>
<li> Application Server (app)</li>
<li> Database Server  (db)</li>
</ul>


<!-- more -->


<p>The most interesting thing about parts is hooking them together.  Load balancers need to know about application servers.
Application servers need to know where the databases are.  This feature I call 'presence'.  There are a lot
of fancy ways to solve 'presence'.  There could be 'presence' servers that servers register with.  Or 'presence' servers
that poll AWS registries.  Certain products keep their 'CI' (Configuration Item) information in databases: both SQL and
other kinds.</p>

<p>All of this is stupidly complex and treats the nodes as if they are idiots.  Pretty sure these nodes can be made about
as smart as a young student (say elementary school or even younger).  A young person is perfectly capable of putting
their name on a list.  And then listing some other interesting things about them.  A node can do the same.  So all
we need is a list.  The classic list for a computer?  A folder.  A folder containing files.  A file named after a node's
unique name.  And a file containing information about the node.  Voila.  No SPOF (can have two folders stored differently),
and no additional nodes doing something stupidly simple.</p>

<h2>Demo or Die!</h2>

<p>So we already have a 'HeartBeat' server, all we need are for it to write somewhere what it's state is.  That is
quite simple:</p>

<h3>updatePresence.sh</h3>

<p>This simply writes information in ~/nodeinfo into a JSON file.  To make that JSON file a little nicer we python
format it.  What gets written into the JSON file?  Basically anything we want!  When?  Every minute!  Ta Da...
the trick is done.</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<p>...</p>

<h1>====================================================</h1>

<h1>=== Generate file</h1>

<h1>====================================================</h1>

<p>export INSTANCE_ID="<code>cat /root/nodeinfo/instance-id.txt</code>"
echo $INSTANCE_ID</p>

<p>cat &lt;<EOS >>$PRESENCE_TEMP
{
"filetype":"nodepresence",
"value": {</p>

<pre><code>"a":"a"
</code></pre>

<p>EOS</p>

<p>FILES=( "initgitrepo" "instance-id" "nodepart" "stacktype" )</p>

<p>for i in "${FILES[@]}"
do</p>

<pre><code>cat &lt;&lt;EOS &gt;&gt;$PRESENCE_TEMP
,
"$i":"`cat /root/nodeinfo/${i}.txt`"
</code></pre>

<p>EOS
done</p>

<p>cat &lt;<EOS >>$PRESENCE_TEMP
}
}
EOS</p>

<p>cat $PRESENCE_TEMP | python -mjson.tool > $PRESENCE_TEMP2
cat $PRESENCE_TEMP2</p>

<h1>| bash ${COMMON}/send_hipchat.sh -c green</h1>

<h1>====================================================</h1>

<h1>=== Switch to the presence repository and copy file</h1>

<h1>====================================================</h1>

<p>pushd $REPO_ROOT</p>

<p>if [ ! -d "$PRESENCE_REPO" ]; then
  echo "git clone git@github.com:shaklee/${PRESENCE_REPO}.git"
  git clone git@github.com:shaklee/${PRESENCE_REPO}.git
fi</p>

<p>if [ -d "$PRESENCE_REPO" ]; then
  cd $PRESENCE_REPO
  git pull</p>

<p>  #Now splat it out to all the proper places
  TARGETS=( "it/presence/all" )
  for i in "${TARGETS[@]}"
  do</p>

<pre><code>mkdir -p $i
cp -f $PRESENCE_TEMP2 $i/${INSTANCE_ID}.json
</code></pre>

<p>  done</p>

<p>  git add .
  git commit -m "Updated by $INSTANCE_ID"; git push
  #Now need to see if this works... but the following is an easy trick in the small
  git pull; git push; git pull; git push</p>

<p>  #Repeat until push succeeds
else
  echo "Not working!"
fi</p>

<p>popd</p>

<p>```</p>

<p>And with the above script we get this simple and beautiful view:</p>

<p><img src="http://markfussell.emenar.com/images/add-6/add6_sourceTree_cv1.png" /></p>

<h2>Collisions</h2>

<p>OK, updating a GitHub repository every minute is not the smartest thing to do at scale... but: if the file
is the same, Git won't do anything.  And if we want, we can always turn down the noise.</p>

<h2>Death</h2>

<p>A machine can die or be killed, so presence information could be out of date.  The solution is just to
broadcast a 'HeartBeat' in either the presence repository or another repository.  Or to make sure to
check if the machine is actually responsive (e.g. HAProxy will interact with the machine to make sure it
is actually alive) vs. being present.  This final interaction is pretty critical (no Zombies in my data center),
so that is the best way to figure out who is alive and alert vs. just being present.</p>
]]></content>
  </entry>
  
</feed>
