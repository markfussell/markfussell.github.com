<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cloud | Polyglot]]></title>
  <link href="http://markfussell.emenar.com/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://markfussell.emenar.com/"/>
  <updated>2015-10-05T09:47:58-07:00</updated>
  <id>http://markfussell.emenar.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-7]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-7/"/>
    <updated>2015-10-04T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-7</id>
    <content type="html"><![CDATA[<p>This is the seventh installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, HipChat integration, and presence.</p>

<h2>Fuller Presence and EC2 Integration</h2>

<p>In the previous part, I went through a very simple but powerful model of 'presence' using simply GitHub repositories.
The content of those presence statements was enough to figure out what nodes exist, but not much more about them.
The second level of presence is to update the state of the node as it changes.  For example, a node goes through
a few bootstrap steps:</p>

<ul>
<li> presetup – The node before any updates are possible (no ability to change status)</li>
<li> setup – The beginning of the 'setup' phase where the node is alive enough to change it's status</li>
<li> initdone – The time a node is done are initialization and can start doing 'work' as the 'nodepart' it is</li>
</ul>


<p>A node getting to 'setup' is pretty important: before that it may be a zombie!  And we don't want zombie's in
our federation!</p>

<!-- more -->


<p>So far for the ADD we now have four resources within which track node states:</p>

<ul>
<li> On the node (say '/root/log' or '/root/nodeinfo/state.txt)</li>
<li> Within the presence system</li>
<li> Within HipChat</li>
<li> On EC2 itself</li>
</ul>


<p>I recommend using <em>all</em> of them.</p>

<h3>On node</h3>

<p> On the node is very helpful in that it is isolated from any other failures.  You
 can 'tail' the logs or 'cat' the state file.  This tangibility helps understand things and debug if there is failure.</p>

<h3>Within Presence</h3>

<p> Within the presence system is the most powerful and flexible.  It is easy to see history and all the activity of your
 nodegrid.  And the nodegrid can use the presence system to figure out what nodes are present and in full 'working'
 mode.</p>

<h3>HipChat</h3>

<p> Within HipChat lets everyone see and talk about the changes.  It can get noisy though, so you need
 to separate the 'chatty' state changes from the 'critical' ones.  An example of 'critical' is when a machine realizes
 it is broken.  It is running the cron job, but something is wrong and it can tell that the 'work' is not completable.
 I call this being 'wedged'.  If a machine is 'wedged', it should tell people and then we can work on improving its
 DNA so it can unwedge itself in the future.  And then kill the machine.</p>

<h3>EC2</h3>

<p> By using EC2 tags you can leverage the EC2 dashboard.  I view 'tags' as read-only because the ADD should not get
 attached (be dependent) on EC2, but it is helpful for visibility.</p>

<h3>Examples</h3>

<p>The following show two machines initializing through Presence, HipChat, and EC2.  The only trigger for this was
killing the existing two instances: the AutoScalingGroup automatically replaced them.</p>

<h4>Launching viewed within EC2 Dashboard</h4>

<p>Nicely the 'add:' prefix makes all the properties that are most important appear on the left.  Some of the names
of concepts are intentionally alphabetically 'sorted' so they appear in the correct column.</p>

<p><img src="http://markfussell.emenar.com/images/add-7/add7_ec2_cv1b.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-6]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-6/"/>
    <updated>2015-10-02T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-6</id>
    <content type="html"><![CDATA[<p>This is the sixth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, the one minute configuration HeartBeat, and HipChat integration.</p>

<h2>'Part' Provisioning</h2>

<p>Each node plays a singular 'Part'.  A 'part' is a unique combination of roles (in the chef sense) that identifies
exactly how the node should be provisioned, usually globally, but at least for each stacktype.  A standard array
of parts would be the LAMP stack:</p>

<ul>
<li> Load Balancer (lb)</li>
<li> Application Server (app)</li>
<li> Database Server  (db)</li>
</ul>


<!-- more -->


<p>The most interesting thing about parts is hooking them together.  Load balancers need to know about application servers.
Application servers need to know where the databases are.  This feature I call 'presence'.  There are a lot
of fancy ways to solve 'presence'.  There could be 'presence' servers that servers register with.  Or 'presence' servers
that poll AWS registries.  Certain products keep their 'CI' (Configuration Item) information in databases: both SQL and
other kinds.</p>

<p>All of this is stupidly complex and treats the nodes as if they are idiots.  Pretty sure these nodes can be made about
as smart as a young student (say elementary school or even younger).  A young person is perfectly capable of putting
their name on a list.  And then listing some other interesting things about them.  A node can do the same.  So all
we need is a list.  The classic list for a computer?  A folder.  A folder containing files.  A file named after a node's
unique name.  And a file containing information about the node.  Voila.  No SPOF (can have two folders stored differently),
and no additional nodes doing something stupidly simple.</p>

<h2>Demo or Die!</h2>

<p>So we already have a 'HeartBeat' server, all we need are for it to write somewhere what it's state is.  That is
quite simple:</p>

<h3>updatePresence.sh</h3>

<p>This simply writes information in ~/nodeinfo into a JSON file.  To make that JSON file a little nicer we python
format it.  What gets written into the JSON file?  Basically anything we want!  When?  Every minute!  Ta Da...
the trick is done.</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<p>...</p>

<h1>====================================================</h1>

<h1>=== Generate file</h1>

<h1>====================================================</h1>

<p>export INSTANCE_ID="<code>cat /root/nodeinfo/instance-id.txt</code>"
echo $INSTANCE_ID</p>

<p>cat &lt;<EOS >>$PRESENCE_TEMP
{
"filetype":"nodepresence",
"value": {</p>

<pre><code>"a":"a"
</code></pre>

<p>EOS</p>

<p>FILES=( "initgitrepo" "instance-id" "nodepart" "stacktype" )</p>

<p>for i in "${FILES[@]}"
do</p>

<pre><code>cat &lt;&lt;EOS &gt;&gt;$PRESENCE_TEMP
,
"$i":"`cat /root/nodeinfo/${i}.txt`"
</code></pre>

<p>EOS
done</p>

<p>cat &lt;<EOS >>$PRESENCE_TEMP
}
}
EOS</p>

<p>cat $PRESENCE_TEMP | python -mjson.tool > $PRESENCE_TEMP2
cat $PRESENCE_TEMP2</p>

<h1>| bash ${COMMON}/send_hipchat.sh -c green</h1>

<h1>====================================================</h1>

<h1>=== Switch to the presence repository and copy file</h1>

<h1>====================================================</h1>

<p>pushd $REPO_ROOT</p>

<p>if [ ! -d "$PRESENCE_REPO" ]; then
  echo "git clone git@github.com:shaklee/${PRESENCE_REPO}.git"
  git clone git@github.com:shaklee/${PRESENCE_REPO}.git
fi</p>

<p>if [ -d "$PRESENCE_REPO" ]; then
  cd $PRESENCE_REPO
  git pull</p>

<p>  #Now splat it out to all the proper places
  TARGETS=( "it/presence/all" )
  for i in "${TARGETS[@]}"
  do</p>

<pre><code>mkdir -p $i
cp -f $PRESENCE_TEMP2 $i/${INSTANCE_ID}.json
</code></pre>

<p>  done</p>

<p>  git add .
  git commit -m "Updated by $INSTANCE_ID"; git push
  #Now need to see if this works... but the following is an easy trick in the small
  git pull; git push; git pull; git push</p>

<p>  #Repeat until push succeeds
else
  echo "Not working!"
fi</p>

<p>popd</p>

<p>```</p>

<p>And with the above script we get this simple and beautiful view:</p>

<p><img src="http://markfussell.emenar.com/images/add-6/add6_sourceTree_cv1.png" /></p>

<h2>Collisions</h2>

<p>OK, updating a GitHub repository every minute is not the smartest thing to do at scale... but: if the file
is the same, Git won't do anything.  And if we want, we can always turn down the noise.</p>

<h2>Death</h2>

<p>A machine can die or be killed, so presence information could be out of date.  The solution is just to
broadcast a 'HeartBeat' in either the presence repository or another repository.  Or to make sure to
check if the machine is actually responsive (e.g. HAProxy will interact with the machine to make sure it
is actually alive) vs. being present.  This final interaction is pretty critical (no Zombies in my data center),
so that is the best way to figure out who is alive and alert vs. just being present.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-5]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-5/"/>
    <updated>2015-10-02T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-5</id>
    <content type="html"><![CDATA[<p>This is the fifth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture, Vagrant and EC2,
node initialization, and the one minute configuration HeartBeat.</p>

<h2>HipChat</h2>

<p>The fourth ingredient to the ADD is HipChat.  HipChat is meant to help people communicate and see the state of the world.
It is an excellent communication program with a plethora of integrations.  But for ADD the critical capability is
to mix notifications of machines with communication between people.  You can also have it be used to drive the ADD
system (kind of like a command line) but that isn't very important since it would just make changes in GitHub
which can be made in lots of different ways.</p>

<p>The demo of this is very simple:</p>

<p><img src="http://markfussell.emenar.com/images/add-5/add5_hipchat_cv1.png" /></p>

<!-- more -->


<p>The GitHub part is an integration that works out of the box, and the AddBot1 notification is a minor addition
to the working script:</p>

<p><code>bash
echo "Doing the work for ${GIT_VERSION}"
echo "Doing the work for ${GIT_VERSION}" | bash ${COMMON}/send_hipchat.sh
sleep 121
echo "Done the work for ${GIT_VERSION}"
echo "Done the work for ${GIT_VERSION}" | bash ${COMMON}/send_hipchat.sh -c green
</code></p>

<p>So now we have 'Action in GitHub' and visibility to all the activities of the machines that reacted to
that action.  Finally we can have human augmentation like "@Team New version is up on the development server"
to transform something technical to something more meaningful.  With proper use of colors, the state
of the world is fairly well communicated at a glance (e.g. Reds, Yellows, Greens, and Blues).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-4]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-4/"/>
    <updated>2015-10-01T03:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-4</id>
    <content type="html"><![CDATA[<p>This is the fourth installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture and the Vagrant and EC2 bootstrap.</p>

<h2>Node initialization</h2>

<p>The previous parts described getting Vagrant and EC2 to have an operational node.  For Vagrant it leverages 'host' virtual
disk access to configure and bootstrap itself.  For EC2, it leverages CloudFormation to configure and bootstrap itself.
In both cases the very last thing the node does in the bootstrap is:</p>

<p><code>bash
cd /root/gitrepo/`cat /root/nodeinfo/initgitrepo.txt`
include () { if [[ -f \"$1\" ]]; then source \"$1\"; else echo \"Skipped missing: $1\"; fi }
include it/nodeinit/common/init.sh
</code></p>

<!-- more -->


<p>It is an 'include/source' to make sure it is at the same level as the initial bootstrap script.  For EC2 this affects
logging, so continual sourcing is preferred.  In other cases, the 'source' enables sub-scripts to set values for subsequent
scripts where subshells are more isolated.</p>

<h3>init.sh</h3>

<p>The init script first figures out where it is and sets up some important paths.</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<h1>===================================================</h1>

<h1>=== Want DIR to be root of the 'nodeinit' directory</h1>

<h1>===================================================</h1>

<p>export DIR="$( cd -P "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )/../"
export RESOURCE=${DIR}/resource
export COMMON=${DIR}/common
```</p>

<h3>cron_1m.sh</h3>

<p>It then gets some AWS resources, sets up a shared 'cron', and so on.  I like a single 'cron' job running every minute
so it is easy to understand what is going on.  This is the 'heartbeat' of the server configuration infrastructure: a
server can want to change any 'minute'.  They look every minute for something that makes them want to change and
then they launch an activity.  The look need to be fast: take about a second or two per 'look' and not cause much load.
But the 'change' does not have to be fast: it could take minutes to reconfigure based on the change.  So while
changing, the 'looking' is disabled.  For example, deploying a new WAR can take a while.  The server stops looking
for new WARs when deploying a WAR.  Then starts looking again when it is back online.</p>

<p>At scale (say 100 servers) with servers all on NTP this one-minute rhythm can cause resource rushing.  To
counter that we need to 'jitter' the servers so they work on a different
second of the minute, or even as much as minutes later at super-scale (1000 servers).
That is done within the cron_1m.sh script after the look has established something needs to be done.</p>

<p>```bash
mkdir -p /root/bin
cp ${RESOURCE}/cron_1m.sh /root/bin/cron_1m.sh
chmod +x /root/bin/cron_1m.sh</p>

<p>cat &lt;<EOS > /var/spool/cron/root
MAILTO=""</p>

<ul>
<li><ul>
<li><ul>
<li><ul>
<li><ul>
<li>/root/bin/cron_1m.sh
EOS
```</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>More specific initialization</h3>

<p>The above activities are done for any node.  They all need to have heartbeats and some other common resources.
But beyond that, it depends on the type of node and the type of stack what should be put on a particular node.
This is done by simple 'includes' with the 'nodeinfo' that came from the configuration.</p>

<p>```bash</p>

<p>include ${DIR}part/<code>cat /root/nodeinfo/nodepart.txt</code>/init.sh
include ${DIR}stacktype/<code>cat /root/nodeinfo/stacktype.txt</code>/init.sh
include ${DIR}stacktype/<code>cat /root/nodeinfo/stacktype.txt</code>/part/<code>cat /root/nodeinfo/nodepart.txt</code>/init.sh</p>

<p>```</p>

<p>You can see the layout in the directory picture.</p>

<p><img src="http://markfussell.emenar.com/images/add-2/vag1_20151001b.png" /></p>

<p>As of that picture, no 'part' or 'stacktype' exists.  So a machine that is brought up is simply a heart-beating server,
but a heart-beating server that can mutate on command every minute.</p>

<h2>What are nodes doing every minute?</h2>

<p>The next cool feature of ADD is that nodes do work based on the state of git repositories.  For any given repository, they
look for a 'work.sh' file within a 'nodework' directory for either all types of nodes (i.e. common again), or the specific
type of node they are.  So just like the other 'include' we get:</p>

<p>```bash</p>

<pre><code>        bash_ifexist bin/nodework/common/work.sh
        bash_ifexist bin/nodework/part/`cat /root/nodeinfo/nodepart.txt`/work.sh
        bash_ifexist bin/nodework/stacktype/`cat /root/nodeinfo/stacktype.txt`/work.sh
        bash_ifexist bin/nodework/stacktype/`cat /root/nodeinfo/stacktype.txt`/part/`cat /root/nodeinfo/nodepart.txt`/work.sh
</code></pre>

<p>```</p>

<p>where the only change is these are not 'sourced' but executed within a sub-shell since they could do weird things to each other, and
also this enables them not to block each other (if desired).</p>

<p>All of these 'work' scripts should quickly determine if anything has changed and then release themselves.  While 'work' is going on,
 the main cron script is locked out.</p>

<p>```bash</p>

<pre><code>     if [[ -e ${CURRENT_ACTION_FILE} ]]; then
         : #Don't do anything until the current action completes
</code></pre>

<p>```</p>

<h3>work.sh</h3>

<p>The main purpose of 'work.sh' is to detect changes.  Any actual work will be in 'work_ActualWork.sh'.  In reverse, the ActualWork is
simply:</p>

<p><code>bash
echo "Doing the work for ${GIT_VERSION}"
</code></p>

<p>So a one-liner appears in the log for the cron job just to prove the 'ActualWork' was done.</p>

<p>But 'work.sh' has to do a few things (very quickly) to detect if there are changes of relevance.  It stores files in the 'repo/.temp/add'
directory that keeps track of state.  The example 'work.sh' will detect changes to the repository based on a watched 'path'.  This
allows multiple things to use the same git repository but be looking at different parts.  By default they look at the root, but it
can be changed.  No matter what 'path' is watched, the version of the 'work' is always the version of the git repository... not the path itself.
In total, there are four 'outer' states possible:</p>

<ul>
<li>The version of the work previously done is identical to the version of git now</li>
<li>The version of the work previously done is different from the version of git now, but the version of the watched path is the same</li>
<li>The version of the work previously done is different from the version of git now, and the watched path has changed</li>
<li>There is no work previously done (the first run of the work)</li>
</ul>


<p>Of the above, only the last two should trigger work.  You can branch differently based on the first run or subsequent runs, but
generally it is best to be 'idempotent' with the work: you change the state of the server to a new state without caring
what the previous state is/was.</p>

<p>The 'inner' state issue is the server could already be doing 'ActualWork', so you have to wait until that is done.</p>

<p>The core of the work.sh script is</p>

<p>```bash
export WORK_VERSION=$ADD_TEMP/work.sh_VERSION
export WORK_DOING_VERSION=$ADD_TEMP/work.sh_DOING_VERSION
export WORK_WATCH_PATH=$ADD_TEMP/work.sh_WATCH_PATH.txt</p>

<p>export WORK_WATCH_VALUE=<code>cat $WORK_WATCH_PATH</code>
export PREV_WORK_VERSION=<code>cat $WORK_VERSION</code></p>

<h1>====================================================</h1>

<h1>=== Now do comparison</h1>

<h1>====================================================</h1>

<p>export GIT_VERSION=<code>git rev-parse HEAD</code></p>

<p>export DETECT_GIT_CHANGE=<code>git log --pretty=oneline ${PREV_WORK_VERSION}..  -- ${WORK_WATCH_VALUE} | awk '{print $1}'</code></p>

<p>echo "Compared ${PREV_WORK_VERSION} to ${GIT_VERSION} for ${WORK_WATCH_VALUE} and got ${DETECT_GIT_CHANGE}"</p>

<p>mkdir -p ${ADD_TEMP}</p>

<p>if [[ -n "${DETECT_GIT_CHANGE}" ]] ;
then</p>

<pre><code>echo "Detected Change in Git Version!";

if [[ -e ${WORK_DOING_VERSION} ]] ;
then
   echo "Already doing `cat ${WORK_DOING_VERSION}`"
else
   echo $GIT_VERSION &gt; ${WORK_DOING_VERSION}
   source ${COMMON}/work_ActualWork.sh

   #Update the state.  This also does a clean startup on first run

   echo $GIT_VERSION &gt; ${WORK_VERSION}
   echo $WORK_WATCH_VALUE &gt; ${WORK_WATCH_PATH}

   rm -fr ${WORK_DOING_VERSION}
fi
</code></pre>

<p>else</p>

<pre><code>echo "No change, move along";
</code></pre>

<p>fi</p>

<p>```</p>

<h3>Speed!</h3>

<p>How fast does this detection take? Basically one second for it to figure out which of the variations it is in, plus the time of the 'git pull'.  With a
'small' server and a small change, this a single second and basically no load:</p>

<h4>Difference detected: start the work</h4>

<p>```bash
cron_1m.sh: Start  20151002-013401
~/gitrepo/repo2_petulant-cyril ~</p>

<p>==> /root/log/cron_1m.sh_error.txt &lt;==
From github.com:shaklee/repo2_petulant-cyril
   57f20ff..6f85e76  master     -> origin/master</p>

<p>==> /root/log/cron_1m.sh_log.txt &lt;==
Updating 57f20ff..6f85e76
Fast-forward
 bin/nodework/common/work.sh | 2 ++
 1 file changed, 2 insertions(+)
Compared 57f20ff734c8836fa34f938bcc540a89bad9215c to 6f85e76a507ce599f42762ad7bf4ae639884ae12 for  and got 6f85e76a507ce599f42762ad7bf4ae639884ae12
Detected Change in Git Version!
Starting ActualWork at 20151002-013402
Doing the work for 6f85e76a507ce599f42762ad7bf4ae639884ae12
```</p>

<h4>Difference detected (but already doing something)</h4>

<p><code>bash
cron_1m.sh: Start  20151002-012301
~/gitrepo/repo2_petulant-cyril ~
Already up-to-date.
Compared 7916053bb9f8bc3d952588a87a48da96dda7abe6 to 57f20ff734c8836fa34f938bcc540a89bad9215c for  and got 57f20ff734c8836fa34f938bcc540a89bad9215c
Detected Change in Git Version!
Already doing 57f20ff734c8836fa34f938bcc540a89bad9215c
Skipped missing: bin/nodework/part/controlnode/work.sh
Skipped missing: bin/nodework/stacktype/ControlServer1/work.sh
Skipped missing: bin/nodework/stacktype/ControlServer1/part/controlnode/work.sh
~
cron_1m.sh: Finish 20151002-012302
</code></p>

<h4>No Difference</h4>

<p><code>bash
cron_1m.sh: Start  20151002-012801
~/gitrepo/repo2_petulant-cyril ~
Already up-to-date.
Compared 57f20ff734c8836fa34f938bcc540a89bad9215c to 57f20ff734c8836fa34f938bcc540a89bad9215c for  and got
No change, move along
Skipped missing: bin/nodework/part/controlnode/work.sh
Skipped missing: bin/nodework/stacktype/ControlServer1/work.sh
Skipped missing: bin/nodework/stacktype/ControlServer1/part/controlnode/work.sh
~
cron_1m.sh: Finish 20151002-012802
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Development and Delivery (ADD) [Part-3]]]></title>
    <link href="http://markfussell.emenar.com/blog/add-3/"/>
    <updated>2015-10-01T02:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/add-3</id>
    <content type="html"><![CDATA[<p>This is the third installment of describing a radically more productive development and delivery environment.</p>

<p>The first part is here: <a href="/blog/add-1/">Intro</a>.  In the previous parts I described the big picture and the
first part of the Vagrant bootstrap.</p>

<h2>EC2</h2>

<p>The Vagrant bootstrap occurred through 'bash' files that shaped (put shape information into files) and
the 'init' itself to get access to the repo (repo2) that contains the true configuration.  For EC2
the same thing happens within a CloudFormation template.  The code of the 'init' is almost identical, but because
it is in a JSON file there is a lot of noise as the string gets concatenated together.</p>

<!-- more -->


<h3>Shaping</h3>

<p>```json</p>

<pre><code>"TemplateConstant" : {
  "stacktype" : { "value" : "ControlServer1" },
  "initgitrepo" : { "value" : "repo2_petulant-cyril" },
  "nodepart" : { "value" : "controlnode" }
},
</code></pre>

<p>```</p>

<p>```json</p>

<pre><code>        "files" : {
          "/root/nodeinfo/stacktype.txt" : {
            "content" : { "Fn::Join" : ["", [
              { "Fn::FindInMap" : [ "TemplateConstant", "stacktype", "value" ] },
              ""
            ]]},
            "mode"  : "000700",
            "owner" : "root",
            "group" : "root"
          },
          "/root/nodeinfo/initgitrepo.txt" : {
            "content" : { "Fn::Join" : ["", [
              { "Fn::FindInMap" : [ "TemplateConstant", "initgitrepo", "value" ] },
              ""
            ]]},
            "mode"  : "000700",
            "owner" : "root",
            "group" : "root"
          },
</code></pre>

<p>```</p>

<h3>Init</h3>

<p>```json</p>

<pre><code>    "UserData"       : { "Fn::Base64" : { "Fn::Join" : ["", [
      "#!/bin/bash -v\n",
      "yum update -y aws-cfn-bootstrap\n",

      "# Helper function\n",
      "function error_exit\n",
      "{\n",
      "  /opt/aws/bin/cfn-signal -e 1 -r \"$1\" '", { "Ref" : "WaitHandle" }, "'\n",
      "  exit 1\n",
      "}\n",

      "# Install LAMP packages\n",
      "/opt/aws/bin/cfn-init -s ", { "Ref" : "AWS::StackName" }, " -r PrimaryLaunchConfig ",
      "    --access-key ",  { "Ref" : "HostKeys" },
      "    --secret-key ", {"Fn::GetAtt": ["HostKeys", "SecretAccessKey"]},
      "    --region ", { "Ref" : "AWS::Region" }, " || error_exit 'Failed to run cfn-init'\n",

      "yum -y install git \n",

      "echo 'Fetch s3cmd to get credentials' \n",
      "mkdir /root/download/ \n",
      "pushd /root/download/ \n",
      "git clone git://github.com/s3tools/s3cmd.git \n",
</code></pre>

<p>```</p>

<h3>Launching and Clusters</h3>

<p>A CloudFormation can provision a single server, but it is used more for clusters.  Instead of creating a server, we create
a server definition and then say how many servers we want.  The 'PrimaryServerGroup' defines this:</p>

<p>```json</p>

<pre><code>"PrimaryServerGroup" : {
  "Type" : "AWS::AutoScaling::AutoScalingGroup",
  "Properties" : {
    "Tags": [
      { "Key": "add:stacktype", "Value": { "Fn::FindInMap" : [ "TemplateConstant", "stacktype", "value" ] }, "PropagateAtLaunch" : "true" },
      { "Key": "add:nodepart", "Value": { "Fn::FindInMap" : [ "TemplateConstant", "nodepart", "value" ] }, "PropagateAtLaunch" : "true" }
    ],
    "AvailabilityZones" : { "Fn::GetAZs" : "" },
    "LaunchConfigurationName" : { "Ref" : "PrimaryLaunchConfig" },
    "MinSize" : "1",
    "MaxSize" : "1",
    "DesiredCapacity" : "1"
  }
},
</code></pre>

<p>```</p>

<p>Note that it ends with '1', '1', '1' meaning this is just a single server.  But those numbers can be changed at any time.</p>

<p>Given the DesiredCapacity is '1', if you ever kill a server, a new one will be spun up.</p>

<h3>EC2 Keypairs</h3>

<p>Another difference of the EC2 model is that EC2 holds onto the keypair that is used for logging into it.  So that information
doesn't need to be exposed.  And further, the EC2 version creates a special 'IAM' agent for the machine.</p>

<h3>EC2 Dashboard</h3>

<p>The dashboard shows some standard EC2 properties along with the add:stacktype and add:nodepart.  The nodepart shows the
kind of node it is (say a load-balancer vs. a game server) and is used within the bootstrap to put the right software
onto the machine.  The 'nodepart' and the 'stacktype' are the core DNA switches of a server.  Later we will add in
'federation' which primarily configures the size of the node (e.g. no 'small' in production)</p>

<p><img src="http://markfussell.emenar.com/images/add-3/add3_ec2_cv1.png" /></p>
]]></content>
  </entry>
  
</feed>
