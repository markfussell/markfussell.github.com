<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | Polyglot]]></title>
  <link href="http://markfussell.emenar.com/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://markfussell.emenar.com/"/>
  <updated>2015-12-14T18:10:55-08:00</updated>
  <id>http://markfussell.emenar.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Velidom: Two Decades of Systems and Architectures]]></title>
    <link href="http://markfussell.emenar.com/blog/arch-3/"/>
    <updated>2015-12-03T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/arch-3</id>
    <content type="html"><![CDATA[<p>This is a series describing various architectures I have worked with in the last two decades and some of their
benifits and issues.  The table of contents of the series is <a href="/blog/arch-1">here</a>.</p>

<p>Velidom came out of the technologies that helped increase velocity, agility, and scale of the Evant
development team.  This was in the mid 2000 time-frame and Evant had created technology which did
mass regression testing on every checkin, enabled continuous inter-team communication (including to India),
and various other major features.  Velidom was an attempt to productize this whole concept: The Velocity
to Dominate with an Advanced Software Development Factory.</p>

<h2>Major System Aspects</h2>

<p>The Velidom Factory was built primarily out of Java-based technologies and VMWare ESX capabilities.  The goal was
to integrate into common tools at the time (Eclipse / Subversion / etc.), automatically launch testing
and deployment servers on any given checkin, verify whether a commit was clean, and either push it through
to the main development line or roll it out based on that verification.</p>

<p>Another side of the factory was an agile development tool that tracked features, their values, the tasks
needed to complete them, and the status of everything.  This was for planning, agility, and measuring.  The
automation was to increase velocity and 'reality' (if it didn't successfully go in, it wasn't in).</p>

<p>A final side of the factory was a set of communication tools for both real-time and knowledge accumulation,
where both of these were hooked into the other sides of the factory so what everything was visible and memorable.</p>

<p>If you look at the <a href="/blog/add-1">Advanced Development and Delivery Environment</a> you will see pretty much all of this
vision manifested through other companies' solutions.  Ultimately Velidom's vision was too big to succeed with the
runway the startup had and the events that occurred during its' lifetime.</p>

<h2>Architecture-1 : Virtualization and Virtualized Desktops</h2>

<p>Of all the architectural aspects that Velidom got right, virtualizing the infrastructure was almost certainly
the biggest 'Yes!'.  VMWare ESX was expensive, but having that infrastructure in place made it possible to
think about computation in a way very different from the raw hardware.  Ultimately from Amazon EC2 through to
Vagrant, this separation has come to pass as a higher-level-language of computational hardware.  Virtualized
computers can be built in minutes and discarded after being used.</p>

<p>Velidom provided virtualized desktops and servers as a service, and we spent the money and time
building out the hardware, the virtualized server side, and creating a custom desktop client.  The results were impressive,
leading edge, unreliable, and expensive.  Things were unreliable due to the client-server desktop communication
paradigm.  This needed good networks and a good protocol for the remote desktop.  And given these were development machines, they needed
to be secure, so each had its own private network.  Again, this was too big a vision to succeed at that time.  Focusing
on just servers may have been viable, but it wasn't clear what the value was without a large base of customers committed
to good automated test suites (which is certainly plausible).</p>

<p>Expensive is relative, and the virtualization Velidom provided may have been viable except for an event that occurred
in 2006.  Amazon announced EC2, and suddenly the price point of virtualized computers dove to a number no one else
could compete with.  Even 10 years later, there are very few viable cloud providers, and no small ones.</p>

<h2>Architecture-2 : Tool Integration and Improvement</h2>

<p>One of the core Velidom concepts was the integration between tools (e.g. Eclipse) and the functionality we provided.
We had Eclipse plugins to do things within the factory, including chat, logging, automation, and other activities.
Integrating directly with a tool is nice, but definitely development expensive.  And the tools you are connecting with
(Eclipse and Subversion) may 'go away'.  In 2005, Eclipse was a good choice, but if we had customers on a Microsoft
development stack, they might have been unsatisfiable.</p>

<p>The core problem wasn't picking the right tool, it was picking any tool before having a Minimal Viable Product.  Tool
integration is not part of Minimal Viable: if your product is good at group chat, people will start using it.  A full
suite of products (the Factory) is also not part of Minimal Viable: whether chat or automated regression testing,
just get a product done and in the hands of customers to get feedback.  If they like your product, they will drive
integration with their favorite tools as an important improvement.</p>

<h2>Architecture-3 : Reactor</h2>

<p>The last architecture from Velidom that I am going to mention is the 'reactor' or 'queue' pattern.  Doing
a mass regression test with servers being created on the fly takes time.  Separating the 'request' from the task
to complete the request is very effective for both scaling and also avoiding needless scaling.  If the automation
is fast enough, you don't need to scale.  If you don't have the extra money to buy the bonus performance,
you also don't need to scale.  You can choose whether to pay for time or not.</p>

<p>The one aspect that for a codebase or similar 'team progessive' activity is whether people wait for things to finish.
Ideally, you are 'unblocked' while you wait: you can go on to something else.  But in a team environment, many people
are trying to get there work in the main codebase of work.  With Subversion, we had to do some annoyingly fancy tricks
to extract a bad build.  With Git and faster testing tools (in memory databases, better functional test declaration
languages), this is far less of a problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Evant: Two Decades of Systems and Architectures]]></title>
    <link href="http://markfussell.emenar.com/blog/arch-2/"/>
    <updated>2015-12-02T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/arch-2</id>
    <content type="html"><![CDATA[<p>This is a series describing various architectures I have worked with in the last two decades and some of their
benifits and issues.  The table of contents of the series is <a href="/blog/arch-1">here</a>.</p>

<p>Evant was originally named Retail Aspect and provided a Retail-as-a-service suite to companies that were
joining the Web retail boom (e.g. Disney Online).</p>

<h2>Major System Aspects</h2>

<p>The technical foundations of the company were from a
Java / Smalltalk background, so the server technologies were pretty mainstream Java enterprise technologies.
The client was the 'leading edge' piece in the implementation technology, using a lot of JavaScript back in a very early time
for the language (early 2000s).  The whole system was notable in the number of automated regression tests
it contained (see below).  The database was initially Oracle but later moved to DB2.</p>

<p>Evant had a suite of products that did not succeed as a suite, potentially due to 9-11 causing a shutdown of online
retail activity.</p>

<h2>AA-1 (Architectural Aspect): Strong Client, Server-UI, and Server-Domain separation</h2>

<p>In terms of making the Evant Advanced Planning product capable, performant, and testable, there was a very strong
separation between "Interface" (UI or Test) and "Domain".  The Domain includes all the business functionality within the planning
engine, exposed by a Java-based API.  It could be driven by either tests or the User Interface.  The API was identical,
so if the tests were successful, the engine was doing the 'right thing'.  And the UI just needed to:</p>

<ul>
<li>Interact with the interface similarly to the tests

<ul>
<li>Or expand interface and tests for new needs</li>
</ul>
</li>
<li>Present the information pleasantly and effectively</li>
</ul>


<p>The UI could do all kinds of amazing things to transform the results or make actions easier for a user.  Since this was
a JavaScript application, lots of things could happen on the client without server interaction or asynchronously with
the server.  The important part was having a single contract that the two clients (one verifying, one using) could
run against.</p>

<h2>AA-2 : Mass Automated Testing</h2>

<p>The original Evant team was very committed to a full XP (Extreme Programming) approach and used TDD, Paired Programming,
and other aspects of XP as part of their development process.  I arrived after this development period, but there
were a fairly extensive collection of automated tests as part of the development artifacts.  However they were
created, they were incredibly useful for regression testing as we transformed the Domain to be far faster,
more scalable, and flexible.</p>

<p>Initially the tests were in XML to allow a very flexible system of automated testing that (in theory) could have tests
written by subject matter experts or general end users.  This flexibility made it a poor Domain-Specific-Language and
users could not write tests themselves.  The tests were also very repetitive (wet) given they had to describe
many states, inputs, and outputs within a matrix-like space.  Ultimately the solution was to move to a matrix-oriented
tool: a Spreadsheet.  And simply organize states, inputs, and outputs within that spreadsheet.  Automation turned
the spreadsheets into automated test specifications.  And the integration server ran this vast collection of tests
pretty much <em>all the time</em> to make sure nothing regressed (or at least it was identified if it did).</p>

<p>The automated testing was a continuous benefit as long as we could keep performance of the testing servers equal to
developer demands.</p>

<h2>AA-3 : Hidden Storage Model</h2>

<p>An important part of the Domain's API was its' separation of 'transactions' from its 'storage'.  The system had
transactional statements ('update' and 'save') but how those things were accomplished was not visible at the
interface.  This separation prevented callers from caring and fiddling with how things were communicated to the
persistent storage.</p>

<p>Not all systems need this kind of separation: What is the chance you will swap out your database?  With a very different
database?  But the Evant storage model was a Hybrid-relational system with the bulk of the data stored in semi-opaque
compressed format.  So the domain acted transactionally, but under the covers it did a lot of data transformations to
organize and compress facts.  Transformations that evolved in time (different versions had better formats) and evolved
based on the size of the data space and performance tuning around it.</p>

<h2>AA-4 : Canned to Generic</h2>

<p>Another common and useful architectural progression is going from 'canned' (fully specified) to 'generic' (very flexible)
capabilities.  You should generally start at 'canned' so you have super-control over what you are doing and what you
expect its results to be.  This is great for both modeling and testing the system.  As the canned capabilities grow,
they can become unwieldy and need to be more parameterized or even genericized (e.g. an Excel formula built out of
operations).</p>

<p>As you go from canned to generic, you will likely encounter both behavioral anomalies and performance anomalies.  But
if you start with generics that do the same as canned, you can focus on performance.  And then switch to generics that
are more broadly capable and focus on whether they behave correctly.  And then return to performance of these more
broadly capable generics.</p>

<h2>Next</h2>

<p><a href="/blog/arch-3">Velidom Factory</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Two Decades of Systems and Architectures]]></title>
    <link href="http://markfussell.emenar.com/blog/arch-1/"/>
    <updated>2015-12-01T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/arch-1</id>
    <content type="html"><![CDATA[<p>It is now the end of 2015 and for decades I have been reading and writing software in both small and large companies, in startups and established enterprises, and in multiple industries.  My background includes several early languages (C, Basic, Pascal, Fortran, and specialty database systems), but I truly became a serious engineer in Smalltalk.  After doing several systems including IRIS-2 / <a href="http://cargosmart.com/">CargoSmart</a>, <a href="http://www.thefreelibrary.com/McKesson+and+SunScript+Sign+$500-Million+Pharmaceutical+Supply...-a020515184">BidLink</a>, and others, I switched to Java as my primary language.  Since then, I have also worked in Objective-C, Ruby/Rails, JavaScript (client and server), Python, and various other languages.</p>

<p>By building so many systems over the years, I have seen many choices and their impacts.  Sometimes the choice was before me, commonly it was mine and my team,  and sometimes people made choices after I 'passed the system on'.  This series is meant to document as many of these systems as possible.  Previously I spoke at conferences and disseminated some of our insights.  I may return to that venue, but wanted to get more than a decade of work visible.</p>

<p>The systems, applications, and architectures documented here will eventually include:</p>

<ul>
<li><a href="/blog/arch-2">Evant Advanced Planning</a>: A multidimensional planning system

<ul>
<li>Java, JavaScript</li>
</ul>
</li>
<li><a href="/blog/arch-3">Velidom Factory</a>: A highly virtualized and automated software development environment / factory

<ul>
<li>Java, VmWare ESX, Subversion (as part of the infrastructure), Flash/Flex, and Eclipse plugins</li>
</ul>
</li>
<li>Winster: A cooperative online gaming and social site

<ul>
<li>Java, Flash/Flex, MySQL</li>
</ul>
</li>
<li>FooPets: A virtual pet entertainment site

<ul>
<li>Ruby, Rails, Maya, iOS, etc.</li>
</ul>
</li>
<li>HeartPark: A 3-D world / game

<ul>
<li>Unity, Ruby, Rails</li>
</ul>
</li>
<li>Vive: A mobile health and wellness application

<ul>
<li>Grails, Java, YUI</li>
</ul>
</li>
<li>Epocrates EMR: An electronic medical records application

<ul>
<li>Ruby, Rails, iOS</li>
</ul>
</li>
<li>PeerCase: A mobile-first medical communication application

<ul>
<li>Grails, Sencha</li>
</ul>
</li>
<li>Rumble: A platform to support free-to-play and hiqh-quality games

<ul>
<li>Grails, Kafka, Redis, eJabberd, and a host of other technologies</li>
</ul>
</li>
<li>ABC: An analytics platform for massive scale machine learning

<ul>
<li>Weka, Python, Grails, Amazon AWS services</li>
</ul>
</li>
<li>ADD: A recommended development &amp; delivery environment and platform for The Gap, Shaklee, and others</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-10]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-10/"/>
    <updated>2015-10-22T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-10</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.  The fifth added some major aspects to the stack: Semi-Structured Data, Templates,
and Dual or Isomorphic scripting. The sixth discussed UI frameworks in a bit more detail and ended with an Angular vs.
Ember as a core choice.  The seventh went into logging, analytics, and monitoring of the running applications and nodes.
The eighth was an overview of Federation Components like caches, queues, payment services, and the like.  The ninth
was on a highly reliable, scalable, flexibly, and ultimately very simple worker model.</p>

<h2>WAR!</h2>

<p>Continuing with the worker model, we currently have a non-production Application Server running Grails:</p>

<ul>
<li><a href="http://fed1-app1.aws.gaps2c.com:8080">http://fed1-app1.aws.gaps2c.com:8080</a></li>
</ul>


<p>It is running grails 'interactively' and 'off-source'.  This is fast for deployment, but it is missing a few
things that people usually want in production:</p>

<ul>
<li>Well-defined artifact that has been tested and can't "just change"</li>
<li>A container environment that can provide certain resources to the application (e.g. monitoring)</li>
<li>Removal of having to understand the 'building' technology from the running technology (JVM)</li>
<li>That production has as few technologies as possible, and is normally missing 'compilers' so people can't tweak behavior</li>
</ul>


<!--more-->


<p>The last item is (IMO) a bit paranoid, and there are better ways to make sure production is stable (tripwires and
logging).  And the third is probably unrealistic for anything but trivial debugging.<br/>
But the first two are certainly reasonable wants.  A lot of people are familiar with deploying wars and deploying
wars on Tomcat and other servers.</p>

<h3>Where's the WAR?</h3>

<p>The first issue with changing from source deployment to war-based deployment is "Where is the WAR?" and
"How do I know it has changed?".  As with the other weird primary ingredient approaches, the WAR is going to
be in an annexed repository.  And you can see that it changed by simply looking at whether the 'git revision' of
the war has changed.  This approach gives incredible power and flexibility:</p>

<ul>
<li>You can have as many different versions of the application as you want.  They just each have to have their own 'folder'</li>
<li>You can easily see which deployments are using which versions</li>
<li>Changing a deployment to use a different version involves copying a 50 byte hash vs. an actual WAR file</li>
<li>Getting the real file is a super-fast call to S3</li>
<li>Bootstrapping the initial version is the same as any other version, which makes it less likely to diverge and break</li>
</ul>


<p>The WARs should be in a different repository from the source for a number of reasons, but the main one being their
rules and rythms are very different.  But the structure of the repositories can be very similar to make it easy to see
the created artifacts.  Something like this:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-10/addstack10_war1.png" /></p>

<p>Note that the contents of the directory could be anything.  And actually a 'trick' to making the upload much faster
is to use an exploded 'war' vs. a normal 'war'.  Why?  Because a WAR contains a bunch of jars that are all almost
 always <em>identical</em> between versions.  So although S3 has basically unlimited space, it is silly to waste it with
 a file that (although different) is 99% the same between each version.  For example, all the identical jars within this
 expanded war:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-10/addstack10_war2.png" /></p>

<p>The trade is that you have a lot more files in the other folders.  Finally, you could do a hybrid where everything but
the lib folder is compressed.  To make the real war, your deployment process would uncompress and then re-WAR the contents.</p>

<p>The performance difference is dramatically different when working outside the EC2 grid, but is less so within that
grid.</p>

<h3>Who deploys what?  The Promotion model</h3>

<p>The deploying server needs to watch something so it can see a change that is relevant to it.  Production does not care
that there is a new QA build.  And QA may not care there is a new development build.  QA never creates its own build,
but it only cares when a development build is "Good enough to QA".  This I call the promotion model.</p>

<p>For any given application:</p>

<ul>
<li>Automated builds occur <em>all the time</em> (whenever something changes) and each gets a unique identifier (e.g. 201)</li>
<li>Each build is then promoted through however many levels of inspection you want

<ul>
<li>If it passes muster</li>
<li>If it has not been superseded by another build</li>
<li>If not, it is ignored</li>
</ul>
</li>
</ul>


<p>With this model, you never <em>go backward</em>, which increases productivity a lot.  And your are continuously trying to
 <em>go forward</em>, which means you have very current information about where you are.  And this also increases productivity.
 Yes, in a pinch, you could see if a build <em>between</em> last success and most current can be promoted.  But that is
 impacting productivity so it should rarely be done.</p>

<p>This also implies there is no branching.  One source.  One set of builds based on that source.  That is not required
by this approach (branch source, new set of builds), but it is strongly encouraged because it again <em>wastes no energy</em>
and it is trivial to flip to a different 'set of builds' when a branch/back-patch is required.  But the process is
very optimistic while also being very realistic (the world is where it is) and appropriately pessimistic
(you can't promote through QA until you pass the automated tests).  Because machines embody the process, you
can't subvert it without doing it <em>very conspicuously</em></p>

<p>To be promoted, you just have to be 'copied' into the right destination.  Promotions are more an 'it' than
a 'development' activity, so they are structured under the 'it' folder.  Each federation (and potentially part)
has it's own versions of things.  If you are in 'fed1' and want the 'grails-petclinic' application on your
machine, you know where to look: 'fed/fed1'.  The use of 'common' vs. 'stacktype' is mirroring the flexibility
 shown elsewhere.  You could have most deployments use 'common' and have some override it.  Or most deployments override 'common'
 but there is a default in case they don't.</p>

<p><img src="http://markfussell.emenar.com/images/addstack-10/addstack10_promo2.png" /></p>

<h3>Who builds and deploys?  Custom Worker vs. Chores</h3>

<p>OK, so we need to build and deploy every time a particular repository changes.  We could do that monolithicly
and have no registry of the war being built (it just magically happens), or we could do that in two parts:</p>

<ol>
<li>Detect change in repository: create chore to build war</li>
<li>Detect chore and worker do chore</li>
</ol>


<p>The advantage of the second version is we can decompose figuring out what needs to be done from doing it, and we
also have better visibility and consistency in the process.  Although I like doing things incrementally, I don't
think the increment (monolith) is notably simpler than the second, and this was meant to build on our Worker topic.</p>

<p>The critical question is actually 'who is going to write the chore'.  We don't want to have a bunch of chores
created by different workers who all recognized a change was done.  Fortunately, we already have a model for this
 with the 'chore' ownership.  We need to describe an 'event' in a way that is related to whatever has changed
 about the world, and then when trying to 'create the chore' a worker first 'creates the event'.  Once an event
 is created and 'pushed', there is no reason to create it again.</p>

<p>In this case, the event is pretty obvious to describe: a git repository went to a new version or specifically:</p>

<ul>
<li>repo3_miniature-ironman</li>
<li>551b86e42d...</li>
</ul>


<p>so if an event for that exists, don't create another one.  Since this is a simple identification, we don't need
the extra directory structure and can simply write a '.json' file into the appropriate time directory.  Note the
time should be the time of the 'event', not of when it was noticed.</p>

<p>A given event could trigger multiple chores, but in our case we just want to have the one 'build the war' chore
created.  Note that the chore could be trivial: it could result in <em>no work</em> being done except seeing if a
new WAR is needed.  Chores are rarely 'you must do this', but more 'do this if necessary'.  This alows us to
be fast in the creation of the 'chore' vs. doing a lot of analysis up front.  Since the worker pool can be
large, we don't want any given worker to block the pipeline too much.</p>

<h4>Event structure</h4>

<p>The structure of the event can be anything.  It is nice to have the JSON be declarative of what it is (an 'event')
and then have enough information to process the information.  Some human readable information is handy for debugging
and logging.</p>

<p>```json
{
  "type" : "event",
  "id" :  "repo3_miniature-ironman_551b86342d"
  "tss" : "20151022120009",
  "kind" : "repochange",
  "repochange": {</p>

<pre><code>"repo" : "repo3_miniature-ironman",
"version" : "551b86342d",
"comment" : "Just set the javaagent for Java",
"committer" : "markfussell"
</code></pre>

<p>  }
}
```</p>

<h4>Chore structure</h4>

<p>```json
{
  "type" : "chore",
  "tss" : "20151022120009",
  "event_id" : "repo3_miniature-ironman_551b86342d"
  "event" : {</p>

<pre><code>  "kind" : "repochange",
  "repochange": {
    "repo" : "repo3_miniature-ironman",
    "version" : "551b86342d",
    "comment" : "Just set the javaagent for Java",
    "committer" : "markfussell"
 }
</code></pre>

<p>  }
}
```</p>

<h3>Making it happen</h3>

<p>Although I mentioned before that there were 'parents', 'workers', and that application servers shouldn't do any of
this kind of work, with this very clean pipeline it is clear our single application server could easily do all of
this itself.  So just to save on IT, that will be the first version.  After that it is easy to see we could separate
the 'parent/worker' from the application server.  And although likely not necessary, we could separate the 'parent'
from the 'worker' node too.  The reason the 'parent' doesn't need to be separated is we should always have two
parents around and a simple CloudFormation can make sure that is true.  And parents don't do that much, so there
is no reason to have them be separate from workers.  With this model, all workers are also potential parents, and
there are always two workers available.</p>

<h4>Detecting the change to 'Repo3'</h4>

<p>This is actually the same script as before where we just do something different in the 'ActualWork' source:</p>

<p>```bash</p>

<pre><code>   echo "Detected Change in Git Version!";

   export START_TSS="`date +%Y%m%d-%H%M%S`"
   echo "Starting ActualWork at ${START_TSS}"
   echo $GIT_VERSION &gt; ${WORK_DOING_VERSION}

   source ${MY_DIR}/work_FindEvent_Repo3_ActualWork.sh
</code></pre>

<p>```</p>

<p>So now we know we have to do the work, but we need to see if it was already done by someone else:</p>

<p><code>``bash
export FIND_EVENT=</code>find work/event -name ${EVENT_NAME} | head -1`</p>

<p>echo $FIND_EVENT</p>

<p>if [[ "" == "$FIND_EVENT" ]] ;
then</p>

<pre><code> #========================================
 #=== We are the first! Rush to add it
 #========================================
</code></pre>

<p>cat &lt;<EOS >>$EVENT_FILE
{
  "type" : "event",
  "id" :  "${EVENT_ID}"
  "tss" : "${EVENT_TSS}",
  "kind" : "repochange",
  "repochange": {</p>

<pre><code>"repo" : "${EVENT_REPO}",
"version" : "${GIT_VERSION}"
</code></pre>

<p>  }
}
EOS</p>

<p>git add $EVENT_FILE
git commit -m "Creating an event for the change ${GIT_VERSION}";
git push
```</p>

<p>If this push succeeds, we are free and clear.  If not, we can try to merge (maybe some other event or chore was written)
and push again with a quick 'git pull; git push'.  We could do that "forever" or until we know we have no hope (study the
actual output of the git pull, push, or other metadata between the two branches).  For the first pass, we can just do
it once.</p>

<h4>Event poster also chore poster</h4>

<p>Since we know we detected the 'event' first, we are the owner of the event and
can now safely write out the 'chores' associated with the event.</p>

<p>```bash</p>

<p>cat &lt;<EOS >>$CHORE_FILE
{
  "type" : "chore",
  "tss" : "${EVENT_TSS}",
  "event_id" : "${EVENT_ID}",
  "kind" : "buildwar",
  "war_repo" : "${WAR_REPO}",
  "war_path" : "${WAR_PATH}",
  "event" : {</p>

<pre><code>  "kind" : "repochange",
  "repochange": {
    "repo" : "${EVENT_REPO}",
    "version" : "${GIT_VERSION}"
 }
</code></pre>

<p>  }
}
EOS</p>

<p>git add $CHORE_FILE
git commit -m "Creating a chore for the event ${EVENT_ID}";
git push
```</p>

<h4>Detecting and doing the chore</h4>

<p>We went through detecting the chore before <a href="/blog/addstack-9/">AddStack-9</a>, but now we want to do something with the chore.</p>

<p>Given the chore is describe in JSON and what we do for the chore could be complex, we should switch to a higher
level language than 'bash'.  In this case we can go into Python as a decent scripting language:</p>

<p><code>bash
python ${COMMON}/doChore.py --source ${RANDOM_DOIT_DIR}/chore.json --gitroot ${GIT_ROOT}
</code></p>

<p>This implies a powerful chore processing script, or one that can modularly call other scripts.
As long as the script leads the creation of 'chore' types, we should be fine whether monolithic or modular.</p>

<p>The core of the routine is just to extract the necessary information from the JSON</p>

<p>```python</p>

<p>source_directory = os.path.dirname(source)
source_json = json.load(open(source))</p>

<p>chore_kind = source_json['kind']</p>

<p>if chore_kind == "buildwar":</p>

<pre><code>build_repo = source_json['event']['repochange']['repo']
build_version = source_json['event']['repochange']['version']
war_repo = source_json['war_repo']
war_path = source_json['war_path']

buildwarfromrepo_version_torepo_path(build_repo, build_version, war_repo, war_path)
</code></pre>

<p>```</p>

<p>With this information we can then go to the build repository, do a simple 'grails package', and copy it to the
appropriate repo and path.</p>

<h3>Other 'chores' for this event?</h3>

<p>The event that caused the 'buildwar' chore could also cause other activities.  Each of the
 application servers could create their own 'chore' to redeploy, which would enable the 'event' and 'chore'
 repository to reflect system activity on a broader sense.  Because they are doing the chore themselves,
 it would just be a way to log the activity vs. being a way to pass it out to a bunch of workers.</p>

<h2>Conclusion</h2>

<p>The event, chore, and worker model is a very flexible, reliable, and scalable way to get stuff done.  It is
especially good at keeping throughput under control even when tasks can get onerous or 'herding' occurs.<br/>
As the backlog grows, more workers appear to keep it in control.  When the backlog shrinks the workers go
to sleep or decommission.</p>

<p>The biggest issue with the worker approach is to make sure you know the ramp rate and reliability.  Even with a
huge cloud like EC2, there can be stutters and you have to more aggressively try to get resources, or accept that
the user experience may be a bit more lagged.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ADD Stack [Part-9]]]></title>
    <link href="http://markfussell.emenar.com/blog/addstack-9/"/>
    <updated>2015-10-21T01:00:00-07:00</updated>
    <id>http://markfussell.emenar.com/blog/addstack-9</id>
    <content type="html"><![CDATA[<p>This is the second series describing the ADD: a radically more productive development and delivery environment.  The
first article is here: <a href="/blog/addstack-1/">Intro</a> and described the truth and lies about developing software.
The second article dealt with 'Testing'.  The third dealt with the application stack (Grails and other technologies).
The fourth discussed UI alternatives.  The fifth added some major aspects to the stack: Semi-Structured Data, Templates,
and Dual or Isomorphic scripting. The sixth discussed UI frameworks in a bit more detail and ended with an Angular vs.
Ember as a core choice.  The seventh went into logging, analytics, and monitoring of the running applications and nodes.
The eighth was an overview of Federation Components like caches, queues, payment services, and the like.</p>

<h2>Workers!</h2>

<p>Among the more interesting federation / deployment component are workers.  Workers are interesting because
they can do almost anything imaginable and they do it very efficiently.  How efficiently?  Well, the perfect
worker is at 100% when doing a task and <em>dead</em> when they have no tasks to do.  That is pretty darn efficient
because it approaches 100% and is only not 100% when we choose to not accept the 'spin up' latency of getting
 a new worker.  As the amount of work increases, our pool of workers increase, and the spin-up-latency decreases
 on a per-chore basis.  That is <em>very cool</em>: as scale goes up, efficiency <em>increases</em>.  There are a lot of places that
 is not true for computers, so it is nice when it is.</p>

<h3>Work?  Chore?</h3>

<p>So we want to have a worker model where we can add a 'chore' (a unit of work, using a term not otherwise used in
IT and CS... job, task, etc. are now ambivalent) to a queue of work-to-be-done, and have
 something do that chore.  There are a lot of ways to do this:</p>

<p> <!--more--></p>

<ol>
<li>Use BeanStalk</li>
<li>Use Kafka with a bunch of consumers</li>
<li>Use a database and launch a worker if none is available</li>
<li>Use Quartz and coordinate amongst the application servers which one is going to do the work</li>
<li>Use GitHub and launch one or more workers as needed</li>
</ol>


<p>And that is just a minor collection of simple solutions.  The first two are probably 'the best' in terms of having
a very clean model.  But they require additional infrastructure and I am trying to keep that at a minimum.  The
second is using a database as a WorkQueue.  Well, it turns out that this is actually commonly done and almost
always <em>regretted</em>.  Most databases are horrible with the characteristics of Chores and their lifecycle.  So it does
work, but not well.</p>

<p>The fourth is quite functional but not scalable.  You don't want your application servers doing <em>a lot</em> of work.
A little housekeeping is fine.  But the whole point of the Worker model is to enable as many or as few workers who each
<em>always</em> do <em>a lot</em> of work.  And then go away if no longer needed.  That isn't the lifecycle and duty of application
servers.</p>

<p>So if you haven't guessed by now, I am going to describe the fifth approach.  Use an annexed Git repository to describe
chores, their media (if any), and to provide the results (if any).  It turns out to be blazingly fast, scalable,
and flexible.  A little weird but sometimes weird really works.</p>

<h3>Chores, Parents, and Workers</h3>

<p>A lot of time, the real world can seriously inspire the computer world.  The Worker model I am about to describe
matches a 'high-speed', 'high-efficiency', parenting model.  I would guess any parent can see the similarities
and even the Nirvana of this Worker model.  It has a few major components:</p>

<ul>
<li>The World creates some Chores in a to-do list</li>
<li>The World doesn't want to do the Chores, because it has other things to do</li>
<li>So The World creates two or more adults (for redundancy) so they can do the Chores

<ul>
<li>And then The World gives responsibility to the adults to do the Chores</li>
</ul>
</li>
<li>The adults don't want to actually do the Chores themselves, so they produce Workers to do the Chores</li>
<li>The Workers are so awesome that they automatically <em>all</em> try to do the Chores, as quickly as possible

<ul>
<li>The adults (Parents) have worked out a system to prevent two Workers from doing the same Chore</li>
</ul>
</li>
<li>If the Chores are not getting done fast enough, the Parents produce more Workers</li>
<li>If there is no more work to do, the Workers go to sleep

<ul>
<li>Waking periodically to see if there is more work</li>
<li>Or if the Chores are not getting done fast enough, the Parents wake one or more Workers</li>
</ul>
</li>
</ul>


<p>With this model:</p>

<ul>
<li>The World is the Application Server or something similar</li>
<li>The Parents are special Nodes (or processes on Application Server nodes) that can see the 'to-do' list</li>
<li>The Workers are special Nodes that are created as the 'to-do' list backlog gets larger</li>
</ul>


<p>You need at least two Parents at all time to make sure the To-Do list is being watched.  You don't need any
Workers until the To-Do list is sufficiently long or latent.</p>

<p>We will put the 'To-Do' chores into a specially structured, annexed, Git repository.  Because of the annexing,
resources are automatically 'deduped' and having each 'chore' be self-contained is both possible and space
efficient.  Imagine all the 'jar's needed for a java build.  Given most of these are stable between builds,
they cost nothing at all to include in a 'chore'.  Where people run fragile artifact servers (fragile because
(a) they exist as something that could fail and (b) they are rarely run redundantly) that have to handle
heavy load, the Annex puts all that load on S3... which is designed from the ground-up for loads well beyond our workers.</p>

<h4>Chore Structure</h4>

<p>The core of a Chore has to include:</p>

<ul>
<li>The identity of the chore

<ul>
<li>And an ability to 'take it on'</li>
</ul>
</li>
<li>What the instructions are for the chore</li>
<li>What resources you need for the chore</li>
<li>Where the results of the chore are supposed to go</li>
</ul>


<p>To make the throughput easier to see, we will organize chores by time.  So basically a queue.  We can have 'priority' within the
metadata of the chore if we want things to jump the queue.  And we can have different chore types (or IT needs) to
make sure a worker can really handle the chore. Using the 'cron_1m' model of things working on the minute, we will
put things into buckets every minute.  But workers have to look for any not-done chore and pick it up if they can.</p>

<p>An advantage of the one-minute cron is we automatically can have a nice 30-second jitter.  That plus some kind of randomization
in chore selection makes it very unlikely that workers will acquire the same chore at the same time.  But if they do, one will win due
to 'git push' timing.</p>

<h5>Identity</h5>

<p>Chores are identified by their 'producer' and a timestamp.  A 'producer' is a node plus a process id, and the timestamp can
have any precision necessary for the process to know it can't collide with itself.  Two of the banes of any identity system
is making sure identity is unique and not having a bottleneck for identity generation.  The identity proposed solves these
two main issues.  A third requirement (sometimes) is keeping identity short / consistent.  A hash of the 'phrase' is
possible if necessary, but collisions could be an issue if the phrase is too short.</p>

<h5>Instructions</h5>

<p>So we have something like "chore_ip-1-2-3-4_ps-349467_20151022-110109-123456" as a chore.  This is simply a directory with
a 'chore.json' within it where that 'chore.json' looks something like this:</p>

<p><code>json
{
  "chore_id" : "ip-1-2-3-4_ps-349467_20151022-110109-123456",
  "chore_tss" : "20151022110109",
  "producer_id" : "ip-1-2-3-4_ps-349467",
  "runner" : "bash",
  "command" : "ps -aux",
  "result" : "output.txt",
  "error" : "error.txt"
}
</code></p>

<p>Another file is in the directory initially called 'do_it.txt' which can be empty.</p>

<h5>Take on the 'chore'</h5>

<p>To take this 'chore' on, a worker adds a 'worker.json' file to the directory:</p>

<p><code>json
{
  "chore_id" :  "ip-1-2-3-4_ps-349467_20151022-110109-123456",
  "work_id" :  "ip-4-5-6-7_ps-1000_20151022-110209-123456",
  "worker_id" : "ip-4-5-6-7_ps-1000",
  "work_start_tss" : "20151022110209",
  "state" : "working",
  "work_finish_tss" : ""
}
</code></p>

<p>and renames the 'do_it.txt' to 'doing_it.txt'</p>

<p>When these changes commit and push successfully, this worker now owns the chore.  The worker can update the 'worker.json'
through the work if desired, or put files into the directory or elsewhere.  When the chore is complete, the worker
should change worker.json to a finished state, and rename the 'doing_it.txt' to 'done.txt'.  With this,
the three states are:</p>

<ul>
<li>do_it.txt</li>
<li>doing_it.txt</li>
<li>done.txt</li>
</ul>


<p>And everyone can quickly tell what the state of a chore is without worrying about the details.  Or dive into the json
and results to figure out those details.</p>

<p>Visually it would look likte this:</p>

<p><img src="http://markfussell.emenar.com/images/addstack-9/addstack9_chore1.png" /></p>

<p><img src="http://markfussell.emenar.com/images/addstack-9/addstack9_chore2.png" /></p>

<p><img src="http://markfussell.emenar.com/images/addstack-9/addstack9_chore3.png" /></p>

<p>The script to acquire a chore is a little involved because of the possibility of failure, but basically it just</p>

<ul>
<li>Finds all the 'doit.txt' files</li>
<li>Picks one at random</li>
<li>Tries to rename it and push that change

<ul>
<li>If successful, then we are in.  If not, roll-back</li>
</ul>
</li>
</ul>


<p><code>``bash
export RANDOM_DO_IT=</code>find work -name 'do_it.txt' | while read x; do echo "`expr $RANDOM % 1000`:$x"; done | sort -n | sed 's/[0-9]*://' | head -1`</p>

<h1>...</h1>

<p>git mv $RANDOM_DO_IT "${RANDOM_DO_IT_DIR}/doing_it.txt"</p>

<h1>...</h1>

<p>git push
PUSH_RETVAL=$?</p>

<p>if [ $PUSH_RETVAL -ne 0 ];
then</p>

<h1>=================================================</h1>

<h1>=== We failed to acquire, so roll-back</h1>

<h1>=================================================</h1>

<p>```</p>

<h4>Doing the work</h4>

<p>A worker should alway be able to acquire:</p>

<ul>
<li>The root of the work repository – Say "${GIT_ROOT}"</li>
<li>The root of the chore itself – Say "${CHORE_ROOT}"</li>
</ul>


<p>Where the "GIT_ROOT" can have shared scripts in its 'work/bin' or 'bin' directories, and the chore can have
individual scripts in it CHORE_ROOT/bin directory.  We also likely have 'repo2' available,
so we have access to a lot of resources (common and work specific) to leverage.</p>

<h4>Saving the work</h4>

<p>When the worker is done, it needs to do a final 'write' of all the results.  This could be nothing more than
logs (a worker is 'anonymous' and ephemeral, so ideally logs go to the chore's directory vs. somewhere
effectively 'random').  This is just a final pull-push:</p>

<p>```bash</p>

<h1>=================================================</h1>

<h1>=== Done, try to write out the results</h1>

<h1>===</h1>

<h1>=== Make sure everything is annexed</h1>

<h1>=================================================</h1>

<p>./bin/deflatePaths.sh "${RANDOM_DO_IT_DIR}"</p>

<p>git pull</p>

<h1>...</h1>

<h1>=================================================</h1>

<h1>=== Pull successful, start writing</h1>

<h1>=================================================</h1>

<p>git mv "${RANDOM_DO_IT_DIR}/doing_it.txt" "${RANDOM_DO_IT_DIR}/done.txt"</p>

<p>git add -A "${RANDOM_DO_IT_DIR}/../"
git commit -m "$ME completed chore ${RANDOM_DOIT_DIR}"</p>

<p>git push
```</p>

<p>and as long as this is successful, the work is done.</p>

<h4>Jitter</h4>

<p>Although the randomization of chore selection helps with a lot of chores, it does not help when there are very few
chores left.  On the 'go' of chore selection, all the workers go after the chore.  So we need to say 'go' at
different times.  This brings back the 'jitter' concept mentioned previously.  To jitter in this case, we just
create a 'random' number and then modulo it by whatever jitter interval we want.</p>

<p>For example, using the process id plus the time stamp, and trying for a 0-29 range, we can have:</p>

<p><code>bash
TSS_SECOND=`date +%s`
PSEUDO_RANDOM="`expr ${TSS_SECOND} + $$`"
SLEEP_LENGTH=$((${PSEUDO_RANDOM} % 30 ))
</code></p>

<h2>Conclusion</h2>

<p>The above is a very generic worker model that enables all kinds of flexibility in setting up 'chores' and scalably
having a 'right-size' for the number of workers doing the work.  The next article will be more specific and
build new 'wars' every time the application changes after passing the built-in tests.</p>
]]></content>
  </entry>
  
</feed>
