<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Architecture | Polyglot]]></title>
  <link href="http://markfussell.emenar.com/blog/categories/architecture/atom.xml" rel="self"/>
  <link href="http://markfussell.emenar.com/"/>
  <updated>2016-01-04T11:57:03-08:00</updated>
  <id>http://markfussell.emenar.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Polyglot DevOps]]></title>
    <link href="http://markfussell.emenar.com/blog/devop-1/"/>
    <updated>2016-01-02T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/devop-1</id>
    <content type="html"><![CDATA[<p>During the last decade, I did quite a bit of launching IT and product operations for products as a 'sidelight' of my main product
development work.  Build the product, launch it operationally, and grow/maintain it going forward.  This pretty well matches
the responsibility of a DevOps role as people are now using the term, so I seem to be among the earlier 'DevOps' people.  At
first I had a Data Center (racks in Hurricane Electric), later VMWare ESX on the Data Center, later servers running in
other people's Data Centers (e.g. RackSpace), and then servers running in true clouds (e.g. AWS, GCE, etc.)</p>

<p>A number of tools have appeared to help automate operations, and each seems to have a fair number of acolytes.  One of the
issues with software is that there is a lot of it, and it takes quite a bit of time to become familiar with all of (a) software
design, (b) software languages and (c) the problem domain itself.</p>

<p>Although it was not really my 'direct intent', over a decade I put in thousands of hours into DevOps.  We needed a running
product and I was more and more concerned that the operations itself was going to be a problem.  Part of this may have
kicked in when I lost all Thanksgiving vacation to fixing some very bad IT.</p>

<h2>Taste-Of Comparison</h2>

<p>You really shouldn't talk about something you don't know, and ideally you know quite a few different things so you can compare
them to each other.  Or you can try to leverage someone else's work and evaluation to help yourself go in the right direction.</p>

<p>The 'Taste Of' series is meant to help people compare different programming languages solving a similar problem.  The 'Architecture'
series is meant to help people see similarities and differences of architectures solving various problems.</p>

<p>This 'Taste-Of' comparison describes a number of plausible ways to provision and deploy software systems.  Depending on your
goals and background, they are all viable.  Some are clearly better for most teams because they deal with critical needs very effectively,
where others handle needs some teams might have and other would never have.</p>

<p>A list of approaches is below.</p>

<ul>
<li>Copy-Paste Provision – Have a script designed to provision a machine, and copy-paste into the console to make it happen</li>
<li>Machine Image – Have a virtual machine image that you can clone and provision</li>
<li>Jenkins (Pipeline) Deploy – Have the automated pipeline automatically deploy</li>
<li>Bash-Up – Have a script that a machine can automatically execute when baseline provisioned</li>
<li>Git-Deploy – Have one or more repositories with changing</li>
<li>Chef</li>
<li>Puppet</li>
<li>Ansible</li>
<li>Salt</li>
<li>BOSH</li>
<li>Docker</li>
<li>RightScale</li>
</ul>


<h3>Goals</h3>

<p>Software operations is software running.  Development operations is within the development team, and production operations
is for the benefit of users outside the development team.  DevOp Goals can be either for development or production.  Some
of them include:</p>

<ul>
<li>DOG-1: Running the software successfully with the intended amount of usage</li>
<li>DOG-2: Handling spikes of usage successfully/gracefully</li>
<li>DOG-3: Being easy to diagnose and repair issues</li>
<li>DOG-4: Knowing what version (of each/all components) is running in a given environment</li>
<li>DOG-5: Easily deploying new versions</li>
<li>DOG-6: Automatedly deploying new versions</li>
<li>DOG-7: Being able to tune system components to behave optimally</li>
<li>DOG-8: Being able to understand what the working environment looks like and how it works</li>
<li>DOG-9: Not having a single-point-of-failure (SPOF)</li>
<li>DOG-10: Having development and production mirror each other as much as possible</li>
<li>DOG-11: Being able to deploy to a new data center easily</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Micro-Services]]></title>
    <link href="http://markfussell.emenar.com/blog/microservice-1/"/>
    <updated>2016-01-01T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/microservice-1</id>
    <content type="html"><![CDATA[<p>In the last few years, a trendy new term has come up: "microservice" and a microservice architecture.
I have been building software for a long time, and have used a service-oriented-architecture (SOA)
and component-oriented-architecture (COA) for many of the applications / systems my teams have built.  Sometimes an industry is missing a shared term for things people have done for decades.  The microservice term
was new to me, so after having some discussions with people from ThoughtWorks and other companies, I wanted to get
a more definitive definition.</p>

<p>So far, this article seems a good intro: <a href="http://martinfowler.com/articles/microservices.html">Microservices by Lewis and Fowler</a></p>

<p>If you read through the core issues that a microservice architecture is trying to address, they seem to distill to this:</p>

<ul>
<li>Have an architecture where you produce working 'product' continuously</li>
<li>Your 'product' will be <em>deployed</em> and you need to be responsible for that being successful</li>
<li>Don't make the architectural components too big for a team to understand and successfully build and maintain</li>
</ul>


<p>These seem very practical and straightforward architectural guidelines.  In both startups and enterprises, you
are delivering products that the company needs or sells, so you should always have your focus be on achieving that.<br/>
I agree that some teams seem to lose this, so keeping them reminded is a good idea.</p>

<h2>Good Idea, Horrible Name</h2>

<p>Given the above reasonableness of the concept, this would be a good thing to have a good name for.  Maybe something
like:</p>

<ul>
<li>Service-Component Architecture</li>
<li>Business-Service Architecture</li>
<li>Right-Sized Service Architecture</li>
<li>Deployed Service Architecture</li>
<li>Composed-Service Architecture</li>
</ul>


<p>All of the above pull at least some interesting aspect of the solution or problem into the term.</p>

<p>Unfortunately using 'micro' with service doesn't do anything other than imply 'small' or 'very-small'.  A 'microscopic'
entity is too small to see.  A 'microprocessor' is a processor that is powerful in abilities but physically small.<br/>
I am not sure what word containing 'micro' that in any way implies what the 'micro' of 'microservice' is trying to imply.</p>

<h2>Bad names lead to bad architecture</h2>

<p>You might think this pedantic, but words are powerful.  And the first uses of microservice in the wild I heard were
for services <em>so tiny in functionality</em> that if you scaled to build a system out of them, you would have a nightmare
of managing components.  It is fine to do something small as a test run, but services need to be cohesive and as comprehensive
as possible to avoid spiralling out of control with dozens of service components wired together haphazardly.</p>

<h2>Trendy/Transitional vs. Foundational</h2>

<p>My guess is microservice is somewhat trendy and will die because it is a poor term.  A more appropriate word is again
'service' or 'service component' or 'right-sized'.  You want an architecture that has a reasonable number of services organized/composed in
a reasonably understandable way.  One way you might organize things is by business function, another is by core
infrastructure capability (e.g. caching), another is by 'rate-of-change', and another is by 'risk-of-change'.</p>

<p>Monoliths are incredibly easy to understand, so they are actually a good starting point.  Your goal is to deliver
a valuable product, so "start with" doing that.</p>

<p>As long as you are good at splitting monoliths (dealing with inter-service calls vs. in-memory calls, providing a facade that hides the change, etc.),
and leverage third-party service-components when suitable, you should have a pretty effective architecture.  You can
split early (before production) or later, but keep you eye on delivering valuable product to your company.</p>

<p>Basically review 'Design Patterns' and think at the service-component level.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FooPets: Two Decades of Systems and Architectures]]></title>
    <link href="http://markfussell.emenar.com/blog/arch-5/"/>
    <updated>2015-12-05T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/arch-5</id>
    <content type="html"><![CDATA[<p>This is a series describing various architectures I have worked with in the last two decades and some of their
benefits and issues.  The table of contents of the series is <a href="/blog/arch-1">here</a>.</p>

<p>FooPets had several different products, but all were related to photorealistic virtual pets.</p>

<h2>Major System Aspects</h2>

<p>The core FooPets site was originally framed by Facebook with a small amount of HTML driving a Flash-based interactive game.
The server behind the Facebook content was a Ruby/Rails application with a few standard extensions initially running on a bare linux box.  No automated testing or other code-quality metrics.</p>

<p>For most kinds of software, the logic and user-interface are the hardest things to build.  But because FooPets was
effectively a 3-D movie / game, the content was actually the hardest thing to build: creating photorealistic 3-D pets
took a lot more people-power than making these photorealistic pets behave.</p>

<p>Later there were to be a couple more architectures:</p>

<ul>
<li>An iPhone version of the pets

<ul>
<li>This was purely client initially and then later semi-integrated with the server until the game was killed</li>
</ul>
</li>
<li>The <a href="https://www.youtube.com/watch?v=C72spt5ZL44">HeartPark</a> truly 3-D interactive game (vs. canned limited videos).

<ul>
<li>The game ran in Unity and only talked to the server for leaderboards</li>
</ul>
</li>
</ul>


<h2>AA-1 : Lack of promotions and regression testing is a very bad thing</h2>

<p>FooPets was a very unstable code base for many reasons, but definitely the lack of 'make sure this works' was a huge
part of it.  Some team members had the ability to modify production directly, and they could do it even before getting
on a plane and disappearing for the holidays.  A promotion model looks like this:</p>

<ul>
<li>Developer tests things on their own machine, and when happy, 'promote' into the development team server</li>
<li>The development team server tests the new code checkin and sees whether it passes the base line rules for the server

<ul>
<li>If not, it rejects it or starts yelling 'foul'!</li>
</ul>
</li>
<li>When the development team is happy the development team server's code base is good, it goes to the next level (QA, Integration, etc.)</li>
<li>Finally the last QA level is basically the same as production, and the final promotion should be trivial</li>
</ul>


<p>Without this kind of staging model, you are basically just praying production will be about the same as whatever machine you last tested on... potentially a developer laptop very different from production.</p>

<h2>AA-2 : Sanity testing and automation are very good things, in all kinds of situations</h2>

<p>When I joined FooMojo, I expected to work on the main code base and the iPhone application as the 'most important' code bases.
These two code bases needed some work, but ultimately the long-pole for the company was <em>content</em>.  And creating content
required a lot of computational power rendering graphics, connecting images into movies, and similar activities that were
only semi-automated.  The biggest productivity improvement was when a few of us focused on making the whole pipeline pretty
much completely automated (with failures identified and easily re-run).</p>

<p>At thirty frames per second, a 10-minute set of clips has 18,000 frames that have to be rendered and composed.  The frames might have different kinds of issues,
but the most likely issue is they didn't get rendered at all, which is pretty easy to identify.</p>

<p>So similar to DevOps where you apply software to computer operations, DevGraphics applies software and development techniques to
the graphics pipelines of movies and high-content games.</p>

<h2>AA-3 : Using advanced technology can make things very easy and impressive</h2>

<p>The concept for <a href="https://www.youtube.com/watch?v=C72spt5ZL44">HeartPark</a> started during the post-Christmas "break", and
within less than two months, a fun game was in all users hands.  By combining the skills of a very small team with a very
advance technology (Unity 3D), we went from idea through prototype to live in a very short time.</p>

<p>Sometimes the technologies used could be considered 'prototypical': you could never support 1MM with them (say maybe hardware
compatibility issues).  But the importance of figuring out whether you have a viable product for a viable market and pivoting
as you do or don't is far higher in value than getting the technology 'perfect' the first time.  And even more fun: sometimes
the nonviable technology becomes mainstream enough to use by the time you have the right product for the right market.</p>

<h2>AA-4 : Make sure clients "always work" or Apple is smart about devices</h2>

<p>A critical rule to getting through the Apple AppStore process was making sure your application obeyed a bunch of rules.
Some of these rules were human-factor rules to make sure the product was pleasant and conformant with iOS.  But one of the
core rules was that applications <em>must work</em> even when the device was not in a suitable environment.  The application
could be thoroughly hobbled by the environment, but it must launch, interact with a user pleasantly, maybe explain
and resolve the situation, and shut down <em>no matter what</em>.  An application / client can't fail without explanation or
really at all, it can only behave very restrictedly but properly.</p>

<p>This "always work" can then lead you to a decision tree around how well does a client in a degraded environment work.  It definitely must work, but how well?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Winster: Two Decades of Systems and Architectures]]></title>
    <link href="http://markfussell.emenar.com/blog/arch-4/"/>
    <updated>2015-12-04T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/arch-4</id>
    <content type="html"><![CDATA[<p>This is a series describing various architectures I have worked with in the last two decades and some of their
benefits and issues.  The table of contents of the series is <a href="/blog/arch-1">here</a>.</p>

<p>Winster was a cooperative social gaming web site that enabled players to win real-world prizes.  It predated
Zynga and Facebook, but both of those companies 'rose' during the time I worked for Winster.</p>

<h2>Major System Aspects</h2>

<p>Winster had a fairly standard Java backend that dealt with managing player information, talking with PayPal,
and keeping track of prizes, advertisements, and promotions.  This is pretty independent of what Winster was:
almost any commercial consumer site might have these capabilities.</p>

<p>What made Winster interesting is that the client was in Adobe Flash/Flex, it was realtime multi-player, and
the rules of the games were all stored on the server.  This created a pretty compelling environment for
players to interact: players could swap pieces and both be in better shape vs. "the house".  And this interaction
supported a real-time chat system.  So very much like a card-game table without any competitiveness between players.</p>

<p>The client-server interaction was a combination of HTTP calls and socket-based bidirectional updates.</p>

<h2>AA-1 : No important logic on the client</h2>

<p>At Winster players could 'win prizes' based on playing the games.  A lot of basic games out there put the actual
functionality into the game client (Flash, JavaScript, and even compiled desktop clients).  This is fine if there
is nothing at stake.  Someone hacks the client and they get to play a 'different' game.  Many games even have
available 'cheat modes' that make a different game easy to enable.</p>

<p>But if the client can actually impact the business, it has to be securely and correctly implementing business rules.
To enable this, you can try to make sure the client is an unhacked/unaltered version of the correct client.  Or more
simply, you can treat the client as untrusted: it makes request, and the server decides whether they are reasonable.</p>

<p>For Winster, we chose to not trust the client and so every action done on the client that affects the state of the
game went through a 'game server' that knew the rules of the game.  There are a lot of wins for this:</p>

<ul>
<li>Servers tend to be easier to verify

<ul>
<li>You control the hardware completely, and at least at that time, there were significantly more testing frameworks</li>
</ul>
</li>
<li>Server failure is 'unlikely' and should be totally visible if you have a problem</li>
<li>You are already writing the server in a particular language, so may more easily be able to augment its capabilities (although some clients have very nice game/event-oriented languages)</li>
</ul>


<p>There are some losses:</p>

<ul>
<li>Latency is guaranteed to be higher, and potentially has to be masked

<ul>
<li>For games like first-person shooters, you need to see the bullet fly even though the server determines the hit</li>
<li>For things like field-validation, you commonly have to repeat yourself on both the client and the server</li>
</ul>
</li>
<li>Clients sometimes have really nice game language</li>
<li>If there are delays in answers, you somehow have to get them to the client asynchronously</li>
<li>As clients scale 'game servers' scale.</li>
</ul>


<p>The last loss can badly affect your operational profits, especially 'pre-cloud' which is the timeframe that Winster
was.  We had to have servers big enough to deal with our peak loads and smart enough not to overload themselves.</p>

<p>The server-side game can be much simpler than the visual appearance on the client side (e.g. think the rules of chess
vs. a pretty chess board), but the server-side game has to protect the business rules of the game so people can't game the game.</p>

<h2>AA-2 : Socket based client-server connection</h2>

<p>Winster existed before Websocket, Comet, and other specifications and approaches.  To communicate what other players
did within your room / table, the server sent updates through a direct socket.  Making sure customers could connect
with a straight socket was painful for customer support (if a customer was behind a very restrictive firewall) and
required augmentations to deal with 'Flash Policies' and other aspects.  The advantage of the Game Server approach
was that the socket notifications were just that: notifications that the world was in a new state.  If clients missed
them, they could get updated on a subsequent notification.  Or catch up if initially stalled for some reason.</p>

<h2>AA-3 : Protocol versioning</h2>

<p>On top of the socket communication was a 'V1' and 'V2' version of a custom communication protocol.  A great rule to any protocol:</p>

<ul>
<li>Version it!</li>
</ul>


<p>You may not think it will change, but by simply versioning the protocol with a 'V1' or '{ "version":"v1", ...' or
similar you have enabled easily migrating forward with backward compatibility.  In many cases you can never be sure when or
if a client will be updated, so you need to enable continued support of old clients until they are commercially
non-viable.</p>

<h2>AA-4 : AJAX or Send-Data vs. rendering</h2>

<p>Because Flash/Flex is a very high-level UI language, the Java server had absolutely no ability to 'render' for the client,
so there was a very strong client/UI vs. Server/Data &amp; Rules separation.  You make a request of the server and you get
data back via HTTP / XML or via the socket connection.  This enables the client to swap out and enables the server to
have easier automated testing.</p>

<h2>AA-5 : Logging and Telemetry</h2>

<p>Logging has a number of different purposes.  Three very different ones include:</p>

<ul>
<li>To see if the software has issues / defects</li>
<li>To have a record if a customer asks for 'proof'</li>
<li>To see what a customer and the systems are doing compared to the business benefit</li>
</ul>


<p>Winster had a lot of logging and telemetry because it (a) needed to work, (b) needed to deal with grouchy customers,
and (c) needed to be very optimized to be profitable.</p>

<p>Logging frameworks and infrastructure improve every year, and it is important to put in the best structure you can
for the purposes you have.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Velidom: Two Decades of Systems and Architectures]]></title>
    <link href="http://markfussell.emenar.com/blog/arch-3/"/>
    <updated>2015-12-03T01:00:00-08:00</updated>
    <id>http://markfussell.emenar.com/blog/arch-3</id>
    <content type="html"><![CDATA[<p>This is a series describing various architectures I have worked with in the last two decades and some of their
benefits and issues.  The table of contents of the series is <a href="/blog/arch-1">here</a>.</p>

<p>Velidom came out of the technologies that helped increase velocity, agility, and scale of the Evant
development team.  This was in the mid 2000 time-frame and Evant had created technology which did
mass regression testing on every checkin, enabled continuous inter-team communication (including to India),
and various other major features.  Velidom was an attempt to productize this whole concept: The Velocity
to Dominate with an Advanced Software Development Factory.</p>

<h2>Major System Aspects</h2>

<p>The Velidom Factory was built primarily out of Java-based technologies and VMWare ESX capabilities.  The goal was
to integrate into common tools at the time (Eclipse / Subversion / etc.), automatically launch testing
and deployment servers on any given checkin, verify whether a commit was clean, and either push it through
to the main development line or roll it out based on that verification.</p>

<p>Another side of the factory was an agile development tool that tracked features, their values, the tasks
needed to complete them, and the status of everything.  This was for planning, agility, and measuring.  The
automation was to increase velocity and 'reality' (if it didn't successfully go in, it wasn't in).</p>

<p>A final side of the factory was a set of communication tools for both real-time and knowledge accumulation,
where both of these were hooked into the other sides of the factory so what everything was visible and memorable.</p>

<p>If you look at the <a href="/blog/add-1">Advanced Development and Delivery Environment</a> you will see pretty much all of this
vision manifested through other companies' solutions.  Ultimately Velidom's vision was too big to succeed with the
runway the startup had and the events that occurred during its' lifetime.</p>

<h2>AA-1 : Virtualization and Virtualized Desktops</h2>

<p>Of all the architectural aspects that Velidom got right, virtualizing the infrastructure was almost certainly
the biggest 'Yes!'.  VMWare ESX was expensive, but having that infrastructure in place made it possible to
think about computation in a way very different from the raw hardware.  Ultimately from Amazon EC2 through to
Vagrant, this separation has come to pass as a higher-level-language of computational hardware.  Virtualized
computers can be built in minutes and discarded after being used.</p>

<p>Velidom provided virtualized desktops and servers as a service, and we spent the money and time
building out the hardware, the virtualized server side, and creating a custom desktop client.  The results were impressive,
leading edge, unreliable, and expensive.  Things were unreliable due to the client-server desktop communication
paradigm.  This needed good networks and a good protocol for the remote desktop.  And given these were development machines, they needed
to be secure, so each had its own private network.  Again, this was too big a vision to succeed at that time.  Focusing
on just servers may have been viable, but it wasn't clear what the value was without a large base of customers committed
to good automated test suites (which is certainly plausible).</p>

<p>Expensive is relative, and the virtualization Velidom provided may have been viable except for an event that occurred
in 2006.  Amazon announced EC2, and suddenly the price point of virtualized computers dove to a number no one else
could compete with.  Even 10 years later, there are very few viable cloud providers, and no small ones.</p>

<h2>AA-2 : Tool Integration and Improvement</h2>

<p>One of the core Velidom concepts was the integration between tools (e.g. Eclipse) and the functionality we provided.
We had Eclipse plugins to do things within the factory, including chat, logging, automation, and other activities.
Integrating directly with a tool is nice, but definitely development expensive.  And the tools you are connecting with
(Eclipse and Subversion) may 'go away'.  In 2005, Eclipse was a good choice, but if we had customers on a Microsoft
development stack, they might have been unsatisfiable.</p>

<p>The core problem wasn't picking the right tool, it was picking any tool before having a Minimal Viable Product.  Tool
integration is not part of Minimal Viable: if your product is good at group chat, people will start using it.  A full
suite of products (the Factory) is also not part of Minimal Viable: whether chat or automated regression testing,
just get a product done and in the hands of customers to get feedback.  If they like your product, they will drive
integration with their favorite tools or your other products as an important improvement.</p>

<h2>AA-3 : Reactor</h2>

<p>The last architecture from Velidom that I am going to mention is the 'reactor' or 'queue' pattern.  Doing
a mass regression test with servers being created on the fly takes time.  Separating the 'request' from the 'task'
to complete the request is very effective for both scaling and also avoiding needless scaling.  If the automation
is fast enough, you don't need to scale.  If you don't have the extra money to buy the bonus performance,
you also don't need to scale.  You can choose whether to pay for time or not.</p>

<p>The one aspect that for a codebase or similar 'team progessive' activity is whether people wait for things to finish.
Ideally, you are 'unblocked' while you wait: you can go on to something else.  But in a team environment, many people
are trying to get there work in the main codebase of work.  With Subversion, we had to do some annoyingly fancy tricks
to extract a bad build.  With Git and faster testing tools (in memory databases, better functional test declaration
languages), this is far less of a problem.</p>
]]></content>
  </entry>
  
</feed>
