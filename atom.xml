<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Foo]]></title>
  <link href="http://markfussell.github.com/atom.xml" rel="self"/>
  <link href="http://markfussell.github.com/"/>
  <updated>2013-02-02T18:16:56-08:00</updated>
  <id>http://markfussell.github.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Being a git about everything (Annexing)]]></title>
    <link href="http://markfussell.github.com/blog/2013/01/13/git-about-everything-annex/"/>
    <updated>2013-01-13T18:16:00-08:00</updated>
    <id>http://markfussell.github.com/blog/2013/01/13/git-about-everything-annex</id>
    <content type="html"><![CDATA[<p>This is the second in a series of using git as part of interesting solutions to problems.</p>

<p>The first is here: <a href="http://markfussell.github.com/blog/2013/01/11/git-about-everything-intro/">Intro</a></p>

<h2>Dealing with Binary Files</h2>

<p>As mentioned in the first posting, git and similar DVCS have issues with binary files.  Adding 100s of 10MB files, or 100s of
versions of 10MB files will produce gigabytes worth of data that must be cloned by everyone using the repository.  How do we avoid this?</p>

<p>There are a number of solutions in this space out there with differing characteristics, but the core approach is usually similar:
&#8220;Don&#8217;t store it in git&#8221;.  Instead we want to record enough information to retrieve the binary files from somewhere else.</p>

<!-- more -->


<h2>Record Enough of the Binary File</h2>

<p>What is
enough information?  How about 160 bits!  Using SHA1 or any similar hash, we can identify the contents of any file.  To add
a bit of consistency and readability, we will make this hex-based, so we get 40 characters.  And to make it a little clearer what
hash was used and what this string is, we add &#8216;sha1_&#8217; to the front and &#8216;.blob&#8217; to the end.  Now our 10MB file has become 50 to 52 bytes depending on
human-entered white spaces.  For example:</p>

<ul>
<li> sha1_8ac02ee34b94461fed19320d789f251e6a2a6796.blob</li>
<li> SHA1-Hash = 8ac02ee34b94461fed19320d789f251e6a2a6796</li>
<li> Google test: <a href="http://www.google.com/search?q=8ac02ee34b94461fed19320d789f251e6a2a6796">http://www.google.com/search?q=8ac02ee34b94461fed19320d789f251e6a2a6796</a></li>
</ul>


<p>And we have confirmed that the hash is enough to identify that file&#8217;s content (and the file itself if it has a unique name).</p>

<p>Storing tens of thousands of 50Byte files is still under a few megabytes, so that part is good.</p>

<h2>Put the content into the Cloud (or similar)</h2>

<p>Where should we store the actual content?  Pretty much anywhere we want if things are simple (only a few files at a time to store and retrieve, need
only local access), but
if we want to store and retrieve thousands of files from anywhere rapidly things get nastier.  For example, there are projects that try to
hide the process of file-contents being moved elsewhere using git smudge/clean filters.  Unfortunately this make the process all of: sequential, heavy, and
perpetual.  We would have similar major issues if we moved the content via some other sequential approach that was not super-fast.  And
git is meant to be highly distributed, so our approach needs to work for all the &#8216;clones&#8217; of a repository.  And finally, we don&#8217;t
want to break our bank over this.</p>

<p>The solution?  Amazon S3 or similar.  Amazon S3 is:</p>

<ul>
<li> Relatively inexpensive for what it does (about a dime a month for 1GB)</li>
<li> Highly distributed</li>
<li> Reasonably fast in network transfers</li>
<li> Incredibly fast as you throw more workers at the network transfers</li>
<li> Blazingly fast if you throw many workers from EC2 at it</li>
</ul>


<p>So if we want to move files from our Git repository into S3, how do we do that?  This isn&#8217;t really a git issue at all if we do
it before &#8216;add&#8217; and after &#8216;pull&#8217;.  It becomes
a simple filesystem-to-S3 issue and s3cmd <a href="http://s3tools.org/s3cmd">http://s3tools.org/s3cmd</a> is a very well trusted tool for this.
Add in the parallel patch <a href="https://github.com/pcorliss/s3cmd-modification">https://github.com/pcorliss/s3cmd-modification</a> and
you can have any numbers of workers running.  We want to be a &#8216;git&#8217; about everything, but we can solve this issue independently
of git and combine the two.  The only large remaining issues are the actual processes of:</p>

<ul>
<li> &#8216;deflating&#8217;: moving the content of a file somewhere and leaving a content-hash in its place.</li>
<li> &#8216;inflating&#8217;: replacing a content-hash with the actual content</li>
</ul>


<p>A highly annex-augmented version of s3cmd is here <a href="https://github.com/markfussell/s3cmd-modification">https://github.com/markfussell/s3cmd-modification</a>
and was done while working at <a href="http://www.rumblegames.com">Rumble</a> where we needed to move gigabytes of high-quality art assets around
as part of the build-deploy pipeline.</p>

<h2>Working with S3 Annexed Git Repositories</h2>

<p>The three things you need for an S3-Annexed repository are:</p>

<ul>
<li> A git repository</li>
<li> An S3 bucket to put content into</li>
<li> The augmented s3cmd from here <a href="https://github.com/markfussell/s3cmd-modification">https://github.com/markfussell/s3cmd-modification</a></li>
</ul>


<p>A repository that is paired with an S3 bucket is located here:</p>

<ul>
<li> https://github.com/markfussell/giteveryrepo1</li>
</ul>


<p>You can clone that repository and get a working annexed-repository and some example content (without write permission).  The repository is tiny but
grants access to several megabytes worth of images.</p>

<h3>Configuration</h3>

<p>The configuration of the Annex is located in &#8216;s3info&#8217;:</p>

<ul>
<li> blob_includes.txt &mdash; The file extensions you want annexed</li>
<li> s3annex_config.txt &mdash; The location of the annex</li>
<li> s3cmd_config.txt &mdash; Some s3cmd configuration, but most importantly the access/secret</li>
<li> s3worker_config.txt &mdash; The number of workers used for annexing</li>
</ul>


<h4>blob_includes</h4>

<p>The blob_includes should be updated with any new file types you want annexed.  To make things fast and simple, annexing is
based on file extensions not size or other properties.  It would be nice if this was more automatic, but being explicit
was simple and very visible.</p>

<h4>s3annex_config</h4>

<p>This is simply the location of the annex.  This can change over time as a quick way to do &#8216;garbage collection&#8217;
but normally it stays the same.  Because of the content-based approach, you can share annexes across many
repositories.</p>

<h4>s3cmd_config</h4>

<p>The s3cmd configuration including access credentials.  If you don&#8217;t want access credentials in the repository itself, you could take out the s3cmd_config file and it should use your defaults (you may need to tweak a couple scripts).</p>

<h4>s3worker_config</h4>

<p>The number of s3workers to run at a time.  More workers will make the S3 combined throughput faster: this should be 100 or more on an EC2 instance.</p>

<h3>Working commands</h3>

<p>All the commands expect to be run from the root of the git repository.  The main working commands are:</p>

<ul>
<li> bin/deflatePaths.sh &mdash; Move the contents of files into the Annex and replace them with a hash stub/reference</li>
<li> bin/inflatePaths.sh &mdash; Put the proper contents of the files into the filesystem based on their hash stub/reference</li>
</ul>


<p>Because annexed repositories should always be fully deflated before committing, there is a command in the root of the directory to
remind people of this:</p>

<ul>
<li> deflateAll.sh &mdash; Visible reminder and simple equivalent to &#8216;bin/deflatePaths.sh .&#8217;</li>
</ul>


<p>These commands are all you need for annexing proper.  To make it easier to see the Annex itself, there is also an &#8216;lsAnnex.sh&#8217;
script which is used below.</p>

<h3>Annex (S3) Layout</h3>

<p>The layout of the Annex within the S3 bucket is either:</p>

<ul>
<li> Flat in a single bucket plus path prefix</li>
<li> Hierarchical based on some amount of leading hash digits</li>
</ul>


<p>The completely flat version is the simpler and truer representation.
The hierarchy simply allows multiple threads to get listings of the annex files in parallel, which
matters for performance when you have thousands of files within the annex.</p>

<h4>Annex listing</h4>

<p>You can see the contents of the annex with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/lsAnnex.sh
</span></code></pre></td></tr></table></div></figure>


<p>For the example repository, this gives:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>2013-01-22 00:04   4742594   s3://emenar.com/gitevery/giteveryrepo1/sha1_02bf4b647b623dac68e1913b8d3494856041047c.blob
</span><span class='line'>2013-01-22 00:11   4742594   s3://emenar.com/gitevery/giteveryrepo1/sha1_02bf4b647b623dac68e1913b8d3494856041047c.blob__.jpg
</span><span class='line'>2013-01-22 00:10   2679517   s3://emenar.com/gitevery/giteveryrepo1/sha1_2abd18dfa4510e1dfc72f643bff3639b42f2aa32.blob
</span><span class='line'>2013-01-22 00:15   2679517   s3://emenar.com/gitevery/giteveryrepo1/sha1_2abd18dfa4510e1dfc72f643bff3639b42f2aa32.blob__.jpg
</span></code></pre></td></tr></table></div></figure>


<p>As you can see, in the annex are files that start with &#8216;sha1_&#8217; and end in &#8216;.blob&#8217; or &#8216;.blob__.xxx&#8217; where &#8216;.xxx&#8217; is a proper MIME extension.
The reason for the MIME extension is just that it can be useful to see or directly retrieve the content
with proper interpretation.  The normal Annex behavior only uses the &#8216;.blob&#8217; version.</p>

<p>The names of the files in the Annex match the &#8216;sha1&#8217; hash of the contents of the file.  So &#8216;sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob__.jpg&#8217;
has a sha1 hash of &#8216;55b15eb3ac72351249125a3de7a81aee2bda6a2a&#8217;.  It is impossible for files to collide unless they are exactly the same
content, so a completely flat representation is correct and simple.</p>

<h3>Example Walk-through</h3>

<p>If you cloned the example repository:</p>

<ul>
<li> https://github.com/markfussell/giteveryrepo1</li>
</ul>


<p>you should have something less than a megabyte, but it represents more than 100MB of image files (30 images of 3MB each).  But all the image
files are stubbed out with just the content hash inside.</p>

<p>To see example details of these stubbed/annexed files, look inside any of the jpg files in <code>image/album</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">echo</span> -n <span class="s2">&quot;content: &quot;</span>; cat image/album/GitEverythingAlbum_01.jpg ; <span class="nb">echo</span>
</span></code></pre></td></tr></table></div></figure>


<p>This returns the blob identifier:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>content: sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span></code></pre></td></tr></table></div></figure>


<h4>Inflating a file</h4>

<p>To inflate a file, run <code>./bin/inflatePaths.sh</code> with the specific file path:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/inflatePaths.sh image/album/GitEverythingAlbum_01.jpg
</span></code></pre></td></tr></table></div></figure>


<p>And you will get some feedback:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Compiling list of <span class="nb">local </span>files <span class="k">for</span> <span class="s1">&#39;file://image/album/GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;image/album/GitEverythingAlbum_01.jpg&#39;</span>
</span><span class='line'>INFO: Applying --exclude/--include
</span><span class='line'>INFO: Retrieving list of remote files <span class="k">for </span>s3://emenar.com/gitevery/giteveryrepo1/ ...
</span><span class='line'>INFO: Summary: 1 <span class="nb">local </span>files to fetch, 60 remote files present
</span><span class='line'>INFO: Inflating<span class="o">[</span>1<span class="o">]</span> from S3 <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg &lt;- s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob -&gt; image/album/GitEverythingAlbum_01.jpg  <span class="o">[</span>1 of 1<span class="o">]</span>
</span><span class='line'> 4960530 of 4960530   100% in    7s   633.43 kB/s  <span class="k">done</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now you should have a normal file and can view a picture of Nob Hill.</p>

<p>Note that <code>git status</code> will now show a change.  The approach here is not to hide or conflate annexing within git (e.g. being part of smudge),
but to create something that when combined with normal git makes git even more useful.</p>

<h4>Deflating a file</h4>

<p>Since we are in a git repository, we could simply do a reset to get the file back to it&#8217;s original content
(it is already annexed) but it is much safer to always
&#8216;deflate&#8217; in case the contents changed vs. being the same as the original commit.</p>

<p>To deflate a single file you run <code>./bin/deflatePaths.shs</code> with the specific file path:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/deflatePaths.sh image/album/GitEverythingAlbum_01.jpg
</span></code></pre></td></tr></table></div></figure>


<p>Because the contents are the same, you should see this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Compiling list of <span class="nb">local </span>files <span class="k">for</span> <span class="s1">&#39;file://image/album/GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;image/album/GitEverythingAlbum_01.jpg&#39;</span>
</span><span class='line'>INFO: Applying --exclude/--include
</span><span class='line'>INFO: Retrieving list of remote files <span class="k">for </span>s3://emenar.com/gitevery/giteveryrepo1/ ...
</span><span class='line'>INFO: Summary: 1 <span class="nb">local </span>files to upload, 60 remote files already present
</span><span class='line'>INFO: Skipped    <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg -&gt; s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>INFO: Skipped    <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob__.jpg<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg -&gt; s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob__.jpg
</span></code></pre></td></tr></table></div></figure>


<p>The original annexing of the file did upload two files, and looked like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Upload     <span class="o">(</span>1<span class="o">)</span>: ./image/album/GitEverythingAlbum_01.jpg -&gt; s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>File <span class="s1">&#39;./image/album/GitEverythingAlbum_01.jpg&#39;</span> started <span class="o">[</span>1 of 30<span class="o">]</span>
</span><span class='line'>...
</span><span class='line'>File <span class="s1">&#39;./image/album/GitEverythingAlbum_01.jpg&#39;</span> stored as <span class="s1">&#39;s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob&#39;</span> <span class="o">(</span>4960530 bytes ...<span class="o">)</span> <span class="o">[</span>1 of 30<span class="o">]</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Inflating Many Files</h4>

<p>The <code>inflate</code> and <code>deflate</code> scripts accept paths so you can inflate the whole album with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/inflatePaths.sh image/album
</span></code></pre></td></tr></table></div></figure>


<p>or even inflate the whole repository:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/inflatePaths.sh .
</span></code></pre></td></tr></table></div></figure>


<p>With the default settings, this will launch 10 workers doing 10 files at a time in total.  How long
the whole 100MB download takes will almost likely depend on your maximum bandwidth, but if not,
just change the number of workers to a larger number.  S3 is very supportive of many requests by
different workers.</p>

<h3>EC2 Walkthrough</h3>

<p>On EC2 the performance numbers are pretty amazing, so I created a simple CloudFormation so people
can test it out.  The CloudFormation is here:</p>

<ul>
<li> https://s3.amazonaws.com/emenar.com/gitevery/aws/cloudformation/GitEverythingServer1.template</li>
</ul>


<p>and it can be run by going to AWS CloudFormation and just giving it one of your keypairs:</p>

<ul>
<li> https://console.aws.amazon.com/cloudformation/</li>
</ul>


<h4>EC2 Performance</h4>

<p>After the instance launches, SSH in, &#8216;sudo su -&#8216;, and change to the repository:</p>

<ul>
<li> /root/gitrepo/giteveryrepo1</li>
</ul>


<p>run <code>inflatePaths</code> with the standard 10 workers</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">time</span> ./bin/inflatePaths.sh image
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Compiling list of <span class="nb">local </span>files <span class="k">for</span> <span class="s1">&#39;file://image&#39;</span>, <span class="s1">&#39;image&#39;</span>, <span class="s1">&#39;image&#39;</span>
</span><span class='line'>INFO: Applying --exclude/--include
</span><span class='line'>INFO: Retrieving list of remote files <span class="k">for </span>s3://emenar.com/gitevery/giteveryrepo1/ ...
</span><span class='line'>INFO: Summary: 30 <span class="nb">local </span>files to fetch, 60 remote files present
</span><span class='line'>INFO: Inflating<span class="o">[</span>1<span class="o">]</span> from S3 <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg &lt;- s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob started <span class="o">[</span>1 of 30<span class="o">]</span>
</span><span class='line'>INFO: Receiving file <span class="s1">&#39;image/album/GitEverythingAlbum_01.jpg&#39;</span>, please
</span><span class='line'>...
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_801a329248a9cbe48b512f2a75179437382dba02.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_21.jpg&#39;</span> <span class="o">(</span>4194668 bytes in 3.1 seconds, 1330.45 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_7d5d055068a9b7e268e21279770f03a5e8c6c9d3.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_22.jpg&#39;</span> <span class="o">(</span>4576223 bytes in 3.0 seconds, 1477.96 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_02bf4b647b623dac68e1913b8d3494856041047c.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_25.jpg&#39;</span> <span class="o">(</span>4742594 bytes in 2.6 seconds, 1777.42 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_856984959467b2427c2a4e9ade642a3d3c26b0fd.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_20.jpg&#39;</span> <span class="o">(</span>4208680 bytes in 4.2 seconds, 971.63 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_7cb2e0318459e276dc4b65987bbe8bd6021357df.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_28.jpg&#39;</span> <span class="o">(</span>3559585 bytes in 2.2 seconds, 1559.41 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_b855966214caa10638f76a3aba6b6df7b0caffca.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_29.jpg&#39;</span> <span class="o">(</span>3820335 bytes in 2.2 seconds, 1718.09 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_2abd18dfa4510e1dfc72f643bff3639b42f2aa32.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_30.jpg&#39;</span> <span class="o">(</span>2679517 bytes in 2.1 seconds, 1229.88 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_fc322e938362e0c40ccf5e09789a1cb6b6995882.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_26.jpg&#39;</span> <span class="o">(</span>3909187 bytes in 3.0 seconds, 1285.67 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_fd63032739c810743521ad1de0546d67b13b4357.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_27.jpg&#39;</span> <span class="o">(</span>3465440 bytes in 2.9 seconds, 1157.55 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_798788e370f243a2a38f91bf8979fd46070a4ae2.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_24.jpg&#39;</span> <span class="o">(</span>3461363 bytes in 5.3 seconds, 634.12 kB/s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>real  0m10.372s
</span><span class='line'>user  0m4.311s
</span><span class='line'>sys   0m2.948s
</span></code></pre></td></tr></table></div></figure>


<p>So it took 10 seconds to download 100MB.  That is 80Mb/s on an &#8216;m1.small&#8217; which is a pretty nice number to work with.  Changing to 100 workers doesn&#8217;t make much difference (about 9 seconds),
so this is pretty much the saturation of &#8216;m1.small&#8217; to S3 performance.  Larger instance types can perform even better.</p>

<h2>Summary &#8211; Annexing makes Git good at binary files</h2>

<p>By using S3 as an Annex for binary files, we can make &#8216;git&#8217; be exceptionally good at dealing with large amount of binary content.  Git simply
manages the history of 50-byte annex-stub text files, and git is very fast and efficient at doing that.  The annex-enhanced s3cmd can run many
workers to upload/deflate and download/inflate the binary files to and from S3.  Especially on EC2 the performance numbers can be super-fast:</p>

<ul>
<li> Clone repository &lt; 5 seconds</li>
<li> Inflate 100MB of files &lt; 10 seconds</li>
</ul>


<p>By combining git with a powerful annex solution, working with lots of version-controlled information
of any size has become all of: very simple, very fast, very distributable, and very inexpensive.</p>

<h3>Alternatives</h3>

<p>There are some alternative approaches out there, which I should mention.  Some I tried and they didn&#8217;t perform well
enough.  Others didn&#8217;t match the needs we had at Rumble or my needs outside of Rumble.  But they are interesting
projects:</p>

<ul>
<li> <a href="http://git-annex.branchable.com/">http://git-annex.branchable.com/</a></li>
<li> <a href="https://github.com/schacon/git-media">https://github.com/schacon/git-media</a></li>
</ul>


<h3>Next</h3>

<p>Our next problem will be&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Being a git about everything (Intro)]]></title>
    <link href="http://markfussell.github.com/blog/2013/01/11/git-about-everything-intro/"/>
    <updated>2013-01-11T18:16:00-08:00</updated>
    <id>http://markfussell.github.com/blog/2013/01/11/git-about-everything-intro</id>
    <content type="html"><![CDATA[<p>There are times when a new technology comes along, that at first appears to be pretty similar to
existing technology, but certain characteristics make for radically different or just nicely new solutions.
A recent example of this is &#8216;git&#8217; and similar distributed version control systems (DVCS).  They may
at first appear to be an interesting version of centralized version/content management systems, but
they are really much more&#8230; a core piece of technology useful for many things.</p>

<p>This is a series about how to use git to solve many different problems, some obvious and some more unusual.
I hope a few of them are interesting to readers.</p>

<!-- more -->


<p>There are alternative DVCSs but I am not going to compare or translate examples&#8230; at least not on a first pass.
Git was created by Linus Torvalds in 2005.  It was initially quite &#8216;raw&#8217; and still maintains much of that rawness,
but other tools (e.g. github) and general improvements have made it more accessible.  For source-code control, git has some big wins
in collaboration and offline work compared to SVN, Perforce, and the like.  Whether these are worth some trade-offs depends on your team
and company&#8230; but that is a different topic.</p>

<h2>Git Syntax / Overview</h2>

<p>You can learn more about git somewhere like github:</p>

<ul>
<li> <a href="http://learn.github.com/p/intro.html">http://learn.github.com/p/intro.html</a></li>
</ul>


<p>Git has a lot of commands, but around seven are core to standard git flows:</p>

<ul>
<li> clone &mdash; copy a repository from a remote location</li>
<li> fetch &mdash; get updates from a remote repository</li>
<li> merge &mdash; merge changes from one branch into the current branch</li>
<li> pull &mdash; &#8216;fetch&#8217; and then &#8216;merge&#8217;</li>
<li> add &mdash; add changes to the commit stage of the current branch</li>
<li> commit &mdash; commit the changes into the current branch</li>
<li> push &mdash; try to make a remote branch look like the current branch</li>
</ul>


<p>Actually of those seven &#8216;pull&#8217; basically replaces/combines two of them, so you get
down to about five with a core loop like this:</p>

<ul>
<li> clone

<ul>
<li>pull</li>
<li>make changes (if needed)

<ul>
<li>add</li>
<li>commit</li>
<li>push</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Of these commands only &#8216;push&#8217; can fail due to timing.  &#8216;push&#8217; is transactional
and you can be contending with other people or machines that pushed to the same branch
as you between when you pulled and you pushed.  Merging can fail, but that
represents some actual file-level conflict vs. a timing issue (someone beat you to the &#8216;push&#8217;).
A proper &#8216;commit&#8217; can&#8217;t fail because it is local.</p>

<h3>Repositories and branches</h3>

<p>At least to begin, all these solutions will use a standard centralized repository approach
and generally not use branches.  So you don&#8217;t have to worry about git&#8217;s ability to
deal with many remotes and which branch a given git repository is using.  By default
at any current moment there is only</p>

<ul>
<li> local: &#8216;master&#8217; <-> remote: origin/master</li>
</ul>


<p>where things get interesting because there could be 100 different machines each with their own &#8216;local&#8217;.</p>

<h3>Problems with git / DVCS</h3>

<p>The biggest issue with git and similar DVCSs is that their model doesn&#8217;t work well for large amounts of
binary assets.  Large amounts of binary assets could occur either because there are a large number of
assets available at any time but only a subset are needed (so with Perforce or SVN many people would not
check out those directories) or more commonly, a modest number of binary assets are frequently
changing.  Because a git repository contains all assets throughout time and to work with a git repository
you clone the whole thing, having a large amount of binary assets punishes everyone.</p>

<p>What is a large amount?  That depends on the circumstances, but generally passing 100MB can start to
become painful depending on the purpose git is being used for.  Having 1GB of textual files in
a single git repository (even over time) is an unusual thing.  GBs of images is common.</p>

<p>So our first problems and solution is going to have to deal with this critical issue.</p>

<p>Enter the annex: <a href="http://markfussell.github.com/blog/2013/01/13/git-about-everything-annex/">Annex</a></p>
]]></content>
  </entry>
  
</feed>
