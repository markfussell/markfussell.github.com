<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Foo]]></title>
  <link href="http://markfussell.github.com/atom.xml" rel="self"/>
  <link href="http://markfussell.github.com/"/>
  <updated>2013-02-04T19:52:41-08:00</updated>
  <id>http://markfussell.github.com/</id>
  <author>
    <name><![CDATA[Mark Fussell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Being a git about everything (Annexing)]]></title>
    <link href="http://markfussell.github.com/blog/2013/01/13/git-about-everything-annex/"/>
    <updated>2013-01-13T18:16:00-08:00</updated>
    <id>http://markfussell.github.com/blog/2013/01/13/git-about-everything-annex</id>
    <content type="html"><![CDATA[<p>This is the second in a series of using git as part of interesting solutions to problems.</p>

<p>The first is here: <a href="http://markfussell.github.com/blog/2013/01/11/git-about-everything-intro/">Intro</a></p>

<h2>Dealing with Binary Files</h2>

<p>As mentioned in the first posting, git and similar DVCS have issues with binary files.  Adding 100s of 10MB files, or 100s of
versions of 10MB files will produce gigabytes worth of data that must be cloned by everyone using the repository.  How do we avoid this?</p>

<p>There are a number of solutions in this space out there with differing characteristics, but the core approach is usually similar:
&#8220;Don&#8217;t store it in git&#8221;.  Instead we want to record enough information to retrieve the binary files from somewhere else.</p>

<!-- more -->


<h2>Record Enough of the Binary File</h2>

<p>What is
enough information?  How about 160 bits!  Using SHA1 or any similar hash, we can identify the contents of any file.  To add
a bit of consistency and readability, we will make this hex-based, so we get 40 characters.  And to make it a little clearer what
hash was used and what this string is, we add &#8216;sha1_&#8217; to the front and &#8216;.blob&#8217; to the end.  Now our 10MB file has become 50 to 52 bytes depending on
human-entered white spaces.  For example:</p>

<ul>
<li> sha1_8ac02ee34b94461fed19320d789f251e6a2a6796.blob</li>
<li> SHA1-Hash = 8ac02ee34b94461fed19320d789f251e6a2a6796</li>
<li> Google test: <a href="http://www.google.com/search?q=8ac02ee34b94461fed19320d789f251e6a2a6796">http://www.google.com/search?q=8ac02ee34b94461fed19320d789f251e6a2a6796</a></li>
</ul>


<p>And we have confirmed that the hash is enough to identify that file&#8217;s content (and the file itself if it has a unique name).</p>

<p>Storing tens of thousands of 50Byte files is still under a few megabytes, so that part is good.</p>

<h2>Put the content into the Cloud (or similar)</h2>

<p>Where should we store the actual content?  Pretty much anywhere we want if things are simple (only a few files at a time to store and retrieve, need
only local access), but
if we want to store and retrieve thousands of files from anywhere rapidly things get nastier.  For example, there are projects that try to
hide the process of file-contents being moved elsewhere using git smudge/clean filters.  Unfortunately this make the process all of: sequential, heavy, and
perpetual.  We would have similar major issues if we moved the content via some other sequential approach that was not super-fast.  And
git is meant to be highly distributed, so our approach needs to work for all the &#8216;clones&#8217; of a repository.  And finally, we don&#8217;t
want to break our bank over this.</p>

<p>The solution?  Amazon S3 or similar.  Amazon S3 is:</p>

<ul>
<li> Relatively inexpensive for what it does (about a dime a month for 1GB)</li>
<li> Highly distributed</li>
<li> Reasonably fast in network transfers</li>
<li> Incredibly fast as you throw more workers at the network transfers</li>
<li> Blazingly fast if you throw many workers from EC2 at it</li>
</ul>


<p>So if we want to move files from our Git repository into S3, how do we do that?  This isn&#8217;t really a git issue at all if we do
it before &#8216;add&#8217; and after &#8216;pull&#8217;.  It becomes
a simple filesystem-to-S3 issue and s3cmd <a href="http://s3tools.org/s3cmd">http://s3tools.org/s3cmd</a> is a very well trusted tool for this.
Add in the parallel patch <a href="https://github.com/pcorliss/s3cmd-modification">https://github.com/pcorliss/s3cmd-modification</a> and
you can have any numbers of workers running.  We want to be a &#8216;git&#8217; about everything, but we can solve this issue independently
of git and combine the two.  The only large remaining issues are the actual processes of:</p>

<ul>
<li> &#8216;deflating&#8217;: moving the content of a file somewhere and leaving a content-hash in its place.</li>
<li> &#8216;inflating&#8217;: replacing a content-hash with the actual content</li>
</ul>


<p>A highly annex-augmented version of s3cmd is here <a href="https://github.com/markfussell/s3cmd-modification">https://github.com/markfussell/s3cmd-modification</a>
and was done while working at <a href="http://www.rumblegames.com">Rumble</a> where we needed to move gigabytes of high-quality art assets around
as part of the build-deploy pipeline.</p>

<h2>Working with S3 Annexed Git Repositories</h2>

<p>The three things you need for an S3-Annexed repository are:</p>

<ul>
<li> A git repository</li>
<li> An S3 bucket to put content into</li>
<li> The augmented s3cmd from here <a href="https://github.com/markfussell/s3cmd-modification">https://github.com/markfussell/s3cmd-modification</a></li>
</ul>


<p>A repository that is paired with an S3 bucket is located here:</p>

<ul>
<li> https://github.com/markfussell/giteveryrepo1</li>
</ul>


<p>You can clone that repository and get a working annexed-repository and some example content (without write permission).  The repository is tiny but
grants access to several megabytes worth of images.</p>

<h3>Configuration</h3>

<p>The configuration of the Annex is located in &#8216;s3info&#8217;:</p>

<ul>
<li> blob_includes.txt &mdash; The file extensions you want annexed</li>
<li> s3annex_config.txt &mdash; The location of the annex</li>
<li> s3cmd_config.txt &mdash; Some s3cmd configuration, but most importantly the access/secret</li>
<li> s3worker_config.txt &mdash; The number of workers used for annexing</li>
</ul>


<h4>blob_includes</h4>

<p>The blob_includes should be updated with any new file types you want annexed.  To make things fast and simple, annexing is
based on file extensions not size or other properties.  It would be nice if this was more automatic, but being explicit
was simple and very visible.</p>

<h4>s3annex_config</h4>

<p>This is simply the location of the annex.  This can change over time as a quick way to do &#8216;garbage collection&#8217;
but normally it stays the same.  Because of the content-based approach, you can share annexes across many
repositories.</p>

<h4>s3cmd_config</h4>

<p>The s3cmd configuration including access credentials.  If you don&#8217;t want access credentials in the repository itself, you could take out the s3cmd_config file and it should use your defaults (you may need to tweak a couple scripts).</p>

<h4>s3worker_config</h4>

<p>The number of s3workers to run at a time.  More workers will make the S3 combined throughput faster: this should be 100 or more on an EC2 instance.</p>

<h3>Working commands</h3>

<p>All the commands expect to be run from the root of the git repository.  The main working commands are:</p>

<ul>
<li> bin/deflatePaths.sh &mdash; Move the contents of files into the Annex and replace them with a hash stub/reference</li>
<li> bin/inflatePaths.sh &mdash; Put the proper contents of the files into the filesystem based on their hash stub/reference</li>
</ul>


<p>Because annexed repositories should always be fully deflated before committing, there is a command in the root of the directory to
remind people of this:</p>

<ul>
<li> deflateAll.sh &mdash; Visible reminder and simple equivalent to &#8216;bin/deflatePaths.sh .&#8217;</li>
</ul>


<p>These commands are all you need for annexing proper.  To make it easier to see the Annex itself, there is also an &#8216;lsAnnex.sh&#8217;
script which is used below.</p>

<h3>Annex (S3) Layout</h3>

<p>The layout of the Annex within the S3 bucket is either:</p>

<ul>
<li> Flat in a single bucket plus path prefix</li>
<li> Hierarchical based on some amount of leading hash digits</li>
</ul>


<p>The completely flat version is the simpler and truer representation.
The hierarchy simply allows multiple threads to get listings of the annex files in parallel, which
matters for performance when you have thousands of files within the annex.</p>

<h4>Annex listing</h4>

<p>You can see the contents of the annex with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/lsAnnex.sh
</span></code></pre></td></tr></table></div></figure>


<p>For the example repository, this gives:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>2013-01-22 00:04   4742594   s3://emenar.com/gitevery/giteveryrepo1/sha1_02bf4b647b623dac68e1913b8d3494856041047c.blob
</span><span class='line'>2013-01-22 00:11   4742594   s3://emenar.com/gitevery/giteveryrepo1/sha1_02bf4b647b623dac68e1913b8d3494856041047c.blob__.jpg
</span><span class='line'>2013-01-22 00:10   2679517   s3://emenar.com/gitevery/giteveryrepo1/sha1_2abd18dfa4510e1dfc72f643bff3639b42f2aa32.blob
</span><span class='line'>2013-01-22 00:15   2679517   s3://emenar.com/gitevery/giteveryrepo1/sha1_2abd18dfa4510e1dfc72f643bff3639b42f2aa32.blob__.jpg
</span></code></pre></td></tr></table></div></figure>


<p>As you can see, in the annex are files that start with &#8216;sha1_&#8217; and end in &#8216;.blob&#8217; or &#8216;.blob__.xxx&#8217; where &#8216;.xxx&#8217; is a proper MIME extension.
The reason for the MIME extension is just that it can be useful to see or directly retrieve the content
with proper interpretation.  The normal Annex behavior only uses the &#8216;.blob&#8217; version.</p>

<p>The names of the files in the Annex match the &#8216;sha1&#8217; hash of the contents of the file.  So &#8216;sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob__.jpg&#8217;
has a sha1 hash of &#8216;55b15eb3ac72351249125a3de7a81aee2bda6a2a&#8217;.  It is impossible for files to collide unless they are exactly the same
content, so a completely flat representation is correct and simple.</p>

<h3>Example Walk-through</h3>

<p>If you cloned the example repository:</p>

<ul>
<li> https://github.com/markfussell/giteveryrepo1</li>
</ul>


<p>you should have something less than a megabyte, but it represents more than 100MB of image files (30 images of 3MB each).  But all the image
files are stubbed out with just the content hash inside.</p>

<p>To see example details of these stubbed/annexed files, look inside any of the jpg files in <code>image/album</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">echo</span> -n <span class="s2">&quot;content: &quot;</span>; cat image/album/GitEverythingAlbum_01.jpg ; <span class="nb">echo</span>
</span></code></pre></td></tr></table></div></figure>


<p>This returns the blob identifier:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>content: sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span></code></pre></td></tr></table></div></figure>


<h4>Inflating a file</h4>

<p>To inflate a file, run <code>./bin/inflatePaths.sh</code> with the specific file path:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/inflatePaths.sh image/album/GitEverythingAlbum_01.jpg
</span></code></pre></td></tr></table></div></figure>


<p>And you will get some feedback:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Compiling list of <span class="nb">local </span>files <span class="k">for</span> <span class="s1">&#39;file://image/album/GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;image/album/GitEverythingAlbum_01.jpg&#39;</span>
</span><span class='line'>INFO: Applying --exclude/--include
</span><span class='line'>INFO: Retrieving list of remote files <span class="k">for </span>s3://emenar.com/gitevery/giteveryrepo1/ ...
</span><span class='line'>INFO: Summary: 1 <span class="nb">local </span>files to fetch, 60 remote files present
</span><span class='line'>INFO: Inflating<span class="o">[</span>1<span class="o">]</span> from S3 <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg &lt;- s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob -&gt; image/album/GitEverythingAlbum_01.jpg  <span class="o">[</span>1 of 1<span class="o">]</span>
</span><span class='line'> 4960530 of 4960530   100% in    7s   633.43 kB/s  <span class="k">done</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now you should have a normal file and can view a picture of Nob Hill.</p>

<p>Note that <code>git status</code> will now show a change.  The approach here is not to hide or conflate annexing within git (e.g. being part of smudge),
but to create something that when combined with normal git makes git even more useful.</p>

<h4>Deflating a file</h4>

<p>Since we are in a git repository, we could simply do a reset to get the file back to it&#8217;s original content
(it is already annexed) but it is much safer to always
&#8216;deflate&#8217; in case the contents changed vs. being the same as the original commit.</p>

<p>To deflate a single file you run <code>./bin/deflatePaths.shs</code> with the specific file path:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/deflatePaths.sh image/album/GitEverythingAlbum_01.jpg
</span></code></pre></td></tr></table></div></figure>


<p>Because the contents are the same, you should see this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Compiling list of <span class="nb">local </span>files <span class="k">for</span> <span class="s1">&#39;file://image/album/GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;GitEverythingAlbum_01.jpg&#39;</span>, <span class="s1">&#39;image/album/GitEverythingAlbum_01.jpg&#39;</span>
</span><span class='line'>INFO: Applying --exclude/--include
</span><span class='line'>INFO: Retrieving list of remote files <span class="k">for </span>s3://emenar.com/gitevery/giteveryrepo1/ ...
</span><span class='line'>INFO: Summary: 1 <span class="nb">local </span>files to upload, 60 remote files already present
</span><span class='line'>INFO: Skipped    <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg -&gt; s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>INFO: Skipped    <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob__.jpg<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg -&gt; s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob__.jpg
</span></code></pre></td></tr></table></div></figure>


<p>The original annexing of the file did upload two files, and looked like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Upload     <span class="o">(</span>1<span class="o">)</span>: ./image/album/GitEverythingAlbum_01.jpg -&gt; s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>File <span class="s1">&#39;./image/album/GitEverythingAlbum_01.jpg&#39;</span> started <span class="o">[</span>1 of 30<span class="o">]</span>
</span><span class='line'>...
</span><span class='line'>File <span class="s1">&#39;./image/album/GitEverythingAlbum_01.jpg&#39;</span> stored as <span class="s1">&#39;s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob&#39;</span> <span class="o">(</span>4960530 bytes ...<span class="o">)</span> <span class="o">[</span>1 of 30<span class="o">]</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Inflating Many Files</h4>

<p>The <code>inflate</code> and <code>deflate</code> scripts accept paths so you can inflate the whole album with:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/inflatePaths.sh image/album
</span></code></pre></td></tr></table></div></figure>


<p>or even inflate the whole repository:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/inflatePaths.sh .
</span></code></pre></td></tr></table></div></figure>


<p>With the default settings, this will launch 10 workers doing 10 files at a time in total.  How long
the whole 100MB download takes will almost likely depend on your maximum bandwidth, but if not,
just change the number of workers to a larger number.  S3 is very supportive of many requests by
different workers.</p>

<h3>EC2 Walkthrough</h3>

<p>On EC2 the performance numbers are pretty amazing, so I created a simple CloudFormation so people
can test it out.  The CloudFormation is here:</p>

<ul>
<li> https://s3.amazonaws.com/emenar.com/gitevery/aws/cloudformation/GitEverythingServer1.template</li>
</ul>


<p>and it can be run by going to AWS CloudFormation and just giving it one of your keypairs:</p>

<ul>
<li> https://console.aws.amazon.com/cloudformation/</li>
</ul>


<h4>EC2 Performance</h4>

<p>After the instance launches, SSH in, &#8216;sudo su -&#8216;, and change to the repository:</p>

<ul>
<li> /root/gitrepo/giteveryrepo1</li>
</ul>


<p>run <code>inflatePaths</code> with the standard 10 workers</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">time</span> ./bin/inflatePaths.sh image
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>INFO: Compiling list of <span class="nb">local </span>files <span class="k">for</span> <span class="s1">&#39;file://image&#39;</span>, <span class="s1">&#39;image&#39;</span>, <span class="s1">&#39;image&#39;</span>
</span><span class='line'>INFO: Applying --exclude/--include
</span><span class='line'>INFO: Retrieving list of remote files <span class="k">for </span>s3://emenar.com/gitevery/giteveryrepo1/ ...
</span><span class='line'>INFO: Summary: 30 <span class="nb">local </span>files to fetch, 60 remote files present
</span><span class='line'>INFO: Inflating<span class="o">[</span>1<span class="o">]</span> from S3 <span class="o">(</span>1<span class="o">)</span> <span class="o">(</span>sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob<span class="o">)</span>: image/album/GitEverythingAlbum_01.jpg &lt;- s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_55b15eb3ac72351249125a3de7a81aee2bda6a2a.blob started <span class="o">[</span>1 of 30<span class="o">]</span>
</span><span class='line'>INFO: Receiving file <span class="s1">&#39;image/album/GitEverythingAlbum_01.jpg&#39;</span>, please
</span><span class='line'>...
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_801a329248a9cbe48b512f2a75179437382dba02.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_21.jpg&#39;</span> <span class="o">(</span>4194668 bytes in 3.1 seconds, 1330.45 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_7d5d055068a9b7e268e21279770f03a5e8c6c9d3.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_22.jpg&#39;</span> <span class="o">(</span>4576223 bytes in 3.0 seconds, 1477.96 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_02bf4b647b623dac68e1913b8d3494856041047c.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_25.jpg&#39;</span> <span class="o">(</span>4742594 bytes in 2.6 seconds, 1777.42 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_856984959467b2427c2a4e9ade642a3d3c26b0fd.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_20.jpg&#39;</span> <span class="o">(</span>4208680 bytes in 4.2 seconds, 971.63 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_7cb2e0318459e276dc4b65987bbe8bd6021357df.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_28.jpg&#39;</span> <span class="o">(</span>3559585 bytes in 2.2 seconds, 1559.41 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_b855966214caa10638f76a3aba6b6df7b0caffca.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_29.jpg&#39;</span> <span class="o">(</span>3820335 bytes in 2.2 seconds, 1718.09 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_2abd18dfa4510e1dfc72f643bff3639b42f2aa32.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_30.jpg&#39;</span> <span class="o">(</span>2679517 bytes in 2.1 seconds, 1229.88 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_fc322e938362e0c40ccf5e09789a1cb6b6995882.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_26.jpg&#39;</span> <span class="o">(</span>3909187 bytes in 3.0 seconds, 1285.67 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_fd63032739c810743521ad1de0546d67b13b4357.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_27.jpg&#39;</span> <span class="o">(</span>3465440 bytes in 2.9 seconds, 1157.55 kB/s<span class="o">)</span>
</span><span class='line'>File s3://emenar.com/gitevery/giteveryrepo1/sha1_798788e370f243a2a38f91bf8979fd46070a4ae2.blob saved as <span class="s1">&#39;image/album/GitEverythingAlbum_24.jpg&#39;</span> <span class="o">(</span>3461363 bytes in 5.3 seconds, 634.12 kB/s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>real  0m10.372s
</span><span class='line'>user  0m4.311s
</span><span class='line'>sys   0m2.948s
</span></code></pre></td></tr></table></div></figure>


<p>So it took 10 seconds to download 100MB.  That is 80Mb/s on an &#8216;m1.small&#8217; which is a pretty nice number to work with.  Changing to 100 workers doesn&#8217;t make much difference (about 9 seconds),
so this is pretty much the saturation of &#8216;m1.small&#8217; to S3 performance.  Larger instance types can perform even better.</p>

<h2>Summary &#8211; Annexing makes Git good at binary files</h2>

<p>By using S3 as an Annex for binary files, we can make &#8216;git&#8217; be exceptionally good at dealing with large amount of binary content.  Git simply
manages the history of 50-byte annex-stub text files, and git is very fast and efficient at doing that.  The annex-enhanced s3cmd can run many
workers to upload/deflate and download/inflate the binary files to and from S3.  Especially on EC2 the performance numbers can be super-fast:</p>

<ul>
<li> Clone repository &lt; 5 seconds</li>
<li> Inflate 100MB of files &lt; 10 seconds</li>
</ul>


<p>By combining git with a powerful annex solution, working with lots of version-controlled information
of any size has become all of: very simple, very fast, very distributable, and very inexpensive.</p>

<h3>Alternatives</h3>

<p>There are some alternative approaches out there, which I should mention.  Some I tried and they didn&#8217;t perform well
enough.  Others didn&#8217;t match the needs we had at Rumble or my needs outside of Rumble.  But they are interesting
projects:</p>

<ul>
<li> <a href="http://git-annex.branchable.com/">http://git-annex.branchable.com/</a></li>
<li> <a href="https://github.com/schacon/git-media">https://github.com/schacon/git-media</a></li>
</ul>


<h3>Next</h3>

<p>Our next problem will be&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Being a git about everything (Intro)]]></title>
    <link href="http://markfussell.github.com/blog/2013/01/11/git-about-everything-intro/"/>
    <updated>2013-01-11T18:16:00-08:00</updated>
    <id>http://markfussell.github.com/blog/2013/01/11/git-about-everything-intro</id>
    <content type="html"><![CDATA[<p>There are times when a new technology comes along, that at first appears to be pretty similar to
existing technology, but certain characteristics make for radically different or just nicely new solutions.
A recent example of this is &#8216;git&#8217; and similar distributed version control systems (DVCS).  They may
at first appear to be an interesting version of centralized version/content management systems, but
they are really much more&#8230; a core piece of technology useful for many things.</p>

<p>This is a series about how to use git to solve many different problems, some obvious and some more unusual.
I hope a few of them are interesting to readers.</p>

<!-- more -->


<p>There are alternative DVCSs but I am not going to compare or translate examples&#8230; at least not on a first pass.
Git was created by Linus Torvalds in 2005.  It was initially quite &#8216;raw&#8217; and still maintains much of that rawness,
but other tools (e.g. github) and general improvements have made it more accessible.  For source-code control, git has some big wins
in collaboration and offline work compared to SVN, Perforce, and the like.  Whether these are worth some trade-offs depends on your team
and company&#8230; but that is a different topic.</p>

<h2>Git Syntax / Overview</h2>

<p>You can learn more about git somewhere like github:</p>

<ul>
<li> <a href="http://learn.github.com/p/intro.html">http://learn.github.com/p/intro.html</a></li>
</ul>


<p>Git has a lot of commands, but around seven are core to standard git flows:</p>

<ul>
<li> clone &mdash; copy a repository from a remote location</li>
<li> fetch &mdash; get updates from a remote repository</li>
<li> merge &mdash; merge changes from one branch into the current branch</li>
<li> pull &mdash; &#8216;fetch&#8217; and then &#8216;merge&#8217;</li>
<li> add &mdash; add changes to the commit stage of the current branch</li>
<li> commit &mdash; commit the changes into the current branch</li>
<li> push &mdash; try to make a remote branch look like the current branch</li>
</ul>


<p>Actually of those seven &#8216;pull&#8217; basically replaces/combines two of them, so you get
down to about five with a core loop like this:</p>

<ul>
<li> clone

<ul>
<li>pull</li>
<li>make changes (if needed)

<ul>
<li>add</li>
<li>commit</li>
<li>push</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Of these commands only &#8216;push&#8217; can fail due to timing.  &#8216;push&#8217; is transactional
and you can be contending with other people or machines that pushed to the same branch
as you between when you pulled and you pushed.  Merging can fail, but that
represents some actual file-level conflict vs. a timing issue (someone beat you to the &#8216;push&#8217;).
A proper &#8216;commit&#8217; can&#8217;t fail because it is local.</p>

<h3>Repositories and branches</h3>

<p>At least to begin, all these solutions will use a standard centralized repository approach
and generally not use branches.  So you don&#8217;t have to worry about git&#8217;s ability to
deal with many remotes and which branch a given git repository is using.  By default
at any current moment there is only</p>

<ul>
<li> local: &#8216;master&#8217; <-> remote: origin/master</li>
</ul>


<p>where things get interesting because there could be 100 different machines each with their own &#8216;local&#8217;.</p>

<h3>Problems with git / DVCS</h3>

<p>The biggest issue with git and similar DVCSs is that their model doesn&#8217;t work well for large amounts of
binary assets.  Large amounts of binary assets could occur either because there are a large number of
assets available at any time but only a subset are needed (so with Perforce or SVN many people would not
check out those directories) or more commonly, a modest number of binary assets are frequently
changing.  Because a git repository contains all assets throughout time and to work with a git repository
you clone the whole thing, having a large amount of binary assets punishes everyone.</p>

<p>What is a large amount?  That depends on the circumstances, but generally passing 100MB can start to
become painful depending on the purpose git is being used for.  Having 1GB of textual files in
a single git repository (even over time) is an unusual thing.  GBs of images is common.</p>

<p>So our first problems and solution is going to have to deal with this critical issue.</p>

<p>Enter the annex: <a href="http://markfussell.github.com/blog/2013/01/13/git-about-everything-annex/">Annex</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why dynamic typing?]]></title>
    <link href="http://markfussell.github.com/blog/1997/08/27/why-dynamic-typing/"/>
    <updated>1997-08-27T18:00:00-07:00</updated>
    <id>http://markfussell.github.com/blog/1997/08/27/why-dynamic-typing</id>
    <content type="html"><![CDATA[<p>This is a discussion of the benefits and drawbacks of dynamic typing
based on specific questions by Anatol Fomenko.</p>

<p>The following is a reference to the main thread-point that this short paper is on:</p>

<ul>
<li> <a href="https://groups.google.com/forum/?fromgroups=#!topic/comp.lang.java.programmer/hIJfUz2kVIM%5B1-25-false%5D">Re: Why dynamic typing (was: Compiler as mediator)</a></li>
</ul>


<h2>Original Posting: Re: Why dynamic typing (was: Compiler as mediator)</h2>

<pre class="quote1">
Anatol Fomenko wrote:
> ...Why Smalltalk is dynamically typed, and why it
> does not affect negatively the stability of the large Smalltalk
> applications?
</pre>


<p>Rephrasing slightly gives the two following questions:</p>

<OL class="arab">
  <LI>Why is Smalltalk dynamically typed?</LI>
  <LI>Why does dynamic typing (as done with Smalltalk) not negatively
      affect the stability of large applications?</LI>
</OL>


<p>The first question would be better answered by Alan Kay and the
Smalltalk team more than anyone else relaying their reasons.  Alan Kay
has described some of his reasoning in the book &#8220;History of Programming
Languages II&#8221;, various OOPSLA &amp; Smalltalk talks, and other sources.</p>

<!-- more -->


<p>   In my own words, the main reason is that Smalltalk has a simple &amp;
powerful concept of building software out of Objects that send Messages
to other Objects.  This is more powerful in both the small and the large
than a language that adds the additional concept (and constraints) of
&#8220;Types&#8221;.  Note that biology has Objects (e.g. Cells) but no Types,
Humans are Objects but there is no compile-time type-checking between
humans, and even electronics do not have compile-time Types: you can
plug the GROUND pin into +5V if you want although some physical
constructs will discourage (but not prevent) it.  These highly scalable
areas (life, civilization, electronics) have done fantastically without
the support of Types, growing in orders of magnitude of functionality.
Alan Kay (who has a biology background) leveraged insights on how cells
and other highly-scalable areas could scale, and applied them to
Smalltalk.  The main concept was membranes/encapsulation and little else
was needed.</p>

<p>The second question may partially support the first.  The short answer
is dynamic typing can scale well because one tends to create much less
code as the system grows bigger.  As the system grows, objects will get
reused in many different situations for which they work well, and the
layers of &#8220;membranes&#8221; allow clients to not worry about internal details
very much.  It still requires a good architecture to build a big system,
but the generalizable functionality of the objects is helping a lot with
the design/implementation.</p>

<p>Now someone could argue that static typing should have the same
property: you write less code as you create more functionality.  But the
truth is that static typing does not just avoid/remove bad code, it
REMOVES GOOD CODE too.  And this good code that static typing is
removing is exactly the code that makes Smalltalk so scalable: it is the
code that can be reused in many different situations that were never
planned for by the original authors.  Dynamic typing excels because it
allows this highly reusable, good code that would not pass a static
typecheck.</p>

<h3>Quantifying the benefit of dynamic typing</h3>

<p>To quantify this a bit, consider that ultimately both a correctly
running Smalltalk program and a correctly running Java program will do
the same thing, so lets consider just one aspect:</p>

<UL>
   <LI>How much extra code needs to be written to support static-typing
vs. dynamic-typing?</LI>
</UL>


<p>The following are all rough estimates between Java and Smalltalk, but
they are based on years of experience doing very similar tasks in both
languages [but Your Mileage May Vary].  Smalltalk requires about 1/2 to
1/3 the number of statements within a method to accomplish the same
thing as Java [this is one of the most painful aspects of switching back
and forth between Smalltalk and Java/C++], so the extra code is at least
100% (2x).  The next level is the number of additional methods needed
because of static typing.  From my experience this is probably about
20%: one in six methods in Java would simply not need to exist in
Smalltalk because they are solely solving a static typing problem and
could otherwise be collapsed into the remaining five methods.  The next
level are additional classes, which is at least another 30%.  Finally, I
will end with additional &#8220;packages&#8221; of functionality which have to be
rewritten or somehow significantly copied/changed to use in the desired
context.  Again, I would say this is about 20% or so (where the &#8216;or so&#8217;
can get really large).  All totaled this is a minimum of:</p>

<pre class="code">
   2.0 x 1.2 x 1.3 x 1.2 = 3.75  (275% larger)
</pre>


<p>and could get as large as</p>

<pre class="code">
   3.0 x 1.3 x 1.5 x 1.7 = 9.5   (850% larger)
</pre>


<p>If you take out the method-statement-level multiplier (people don&#8217;t seem
to mind this growth as much and it is well localized) you get an 85% to
230% growth in overall system size (packages of classes of methods).</p>

<p>It would be better to have real experimental numbers (say for TOPLink or
another cross-language product).  But the above gives the general
concept of an advantage of dynamic languages and the penalty of static
typing.</p>

<p>If you need a specific example, consider the [completely randomly
selected] JDK 1.2 Collection code of:</p>

<pre class="code">
    public boolean AbstractCollection::removeAll(Collection c) {
        boolean modified = false;
        Iterator e = iterator();
        while (e.hasNext()) {
            if(c.contains(e.next())) {
                e.remove();
                modified = true;
            }
        }
        return modified;
    }
</pre>


<p>The static-typing problem in this extremely simple code is that &#8216;c&#8217; only
needs to respond to &#8216;contains&#8217;, not be a Collection.  This means I can&#8217;t
just use any containment concept I want to (say, remove all people who
are 6&#8217; tall) by passing in an object that understands &#8216;contains&#8217;.
Because of a static-typing restriction on what would be perfectly good
code, I have to create extra code that reproduces 90% of the above with
the one variation that &#8216;c&#8217; is something other than a Collection (and I
am likely to pick something as silly [i.e. too specific] as &#8216;Collection&#8217;
again).  This is the type of &#8216;package&#8217;-level punishment that static
typing tends to cause.</p>

<h3>Affect on stability</h3>

<p>So returning to the question:</p>

<pre>
  (2) Why does dynamic typing (as done with Smalltalk) not negatively
      affect the stability of large applications?
</pre>


<p>Because large applications written in a dynamic OO language still have
well encapsulated parts that can be verified independently, and the
total implementation can be about 1/2 to 1/3 the size of the
implementation in Java (or another static-typed language)[2].</p>

<p>In the small you may get a type error that static-typing could have
catched, but you also get to build a system such that you never have to
write 40-70% of the code you might otherwise have to.  And a line of
code not written is a 100% guaranteed correct line of code.</p>

<p>A way to really think about the negative impacts of static typing would
be to consider (as you walk around) how many things in the real world
would be extremely difficult to do if static typing was enforced on
them.  For example, could you have a shoe-rack? (no, someone would have
to &#8216;cast&#8217; their shoes when they took them out again).  Could you use a
key to cut open a package?  Could gas-injection cork removers exist?
Heterogeneity, flexibility, extensibility, and reusability are all
punished by static typing.</p>

<p>Not that I think static-typing isn&#8217;t useful&#8230; it just has serious
drawbacks.  Certainly Eiffel does it better than Java.  But
dynamic-typing has conceptual advantages that even the best static-typed
languages (e.g. Cecil) can&#8217;t remove and those advantages are very
helpful in building real, large-scale, applications.</p>

<pre class="signature">
--Mark
</pre>




<p class="footnote">
[1] If you would like a longer example of completely removing static
typing from a Java program and then re-adding it incrementally, see:
<pre>
   <a href="http://www.chimu.com/publications/smallJava/index.html">http://www.chimu.com/publications/smallJava/index.html</a>
</pre>

<p class="footnote">
[2] On the other hand, the value of a programming language is determined
by how well it helps developers solve their problems.  Although the
quality of a language itself can make it a better tool, the real power
comes from high quality libraries and frameworks available to that
language.  Smalltalk has an inherent advantage but if the number of
skilled developers creating for another language (e.g. Java) is high
enough, than that inherent advantage will go away because enough better
frameworks will exist in the other language such that Smalltalk would
not be as close to the solution as the other language is.
</p>

## Subsequent Discussion

<H3 class="discussion">More details and examples</H3>


<pre class="quote1">
Joern Janneck wrote:
> Mark Fussell wrote:
> >    In my own words, the main reason is that Smalltalk has a simple &
> > powerful concept of building software out of Objects that send Messages
> > to other Objects.  This is more powerful in both the small and the large
> > than a language that adds the additional concept (and constraints) of
> > "Types".
>
> actually, you could have both, couldn't you? many oo languages do, i see
> little reason to present them here as alternatives. the question really
> is, why only one of them is better than the two put together, isn't it?
</pre>

Sure, there are lots of variations:
<OL class="arab">
  <LI>Either you have compile-time types or you don&#8217;t</LI>
  <LI>Either those compile-time types are mandatory, they are optional,
or there are loopholes [e.g. allow dynamic typechecks]</LI>
  <LI>Either types are explicitly declared or implicit</LI>
  <LI class="etc">&#8230; [equal or identical type matching, granularity, DBC enhancements,
type/class separation]&#8230;</LI>
</OL>


Some OO languages support multiple variations, but usually even if a
language supports semi-optional compile-time types they will have the
bulk of their code with mandatory compile-time checks and you can&#8217;t just
turn it off.  Most common compile-time typed languages have mandatory
types with loopholes.


But the questions were:
<pre class="quote2">
>   (1) Why is Smalltalk dynamically typed?
>   (2) Why does dynamic typing (as done with Smalltalk) not negatively
>       affect the stability of large applications?
</pre>


The part you quoted was the auxilary answer to (1): the main answer was
read HOPL-II and similar sources.  And to discuss (2) we have to compare
dynamic (optimistic) typing to static (pessimistic) typing.  It would
certainly be quite valid to consider them within a single language.  I
did a bit of that in:
<pre>
   <a href="http://www.chimu.com/publications/smallJava/index.html">http://www.chimu.com/publications/smallJava/index.html</a>
</pre>


And note that I would prefer not to be comparing relatively
weak/immature languages (in terms of static typing) like Java and C++.
I would much rather be talking in terms of Eiffel or Cecil.  But the
reality is that Java is currently a common language to show examples.  I
certainly would not make a point of a failing in Java (e.g. invariant
return type) as a failing in static typing.  I tend to think primarily
in terms of Eiffel but with the additional separation of types from
classes (that Eiffel supports but does not enforce).  This seems to be a
reasonable perspective considering commonly available languages.


So returning to the topic, I will add a little more explanation for a
few of the points.

### Problems with type-checking

Note that there is nothing conceptually wrong with static
type-checking.  It would be wonderful to create software that can be
completely verified before execution.  That is provably impossible, but
getting closer to that goal would be nice.  Static typing is a possible
approach: you at least make sure that all clients and suppliers agree to
a contract ahead of time before even attempting to run the program.
Some of the problems with static typing are that:
<OL class="upperAlpha">
  <LI>Types are sometimes bound to Implementation Classes</LI>
  <LI>Types have poor granularity.  Frequently a Type will be specified
that has too many operations (is too specific) to be useful in multiple
contexts even though subsets of those operations (a more general
concept) is widely useful.  Since it costs effort to name and create
each Type, there is an impetus of reduction that again impedes reuse and
generalization.  Save now, pay later.</LI>
  <LI>Precise type information is lost when objects are fed through more
generic structures.</LI>
  <LI>Types restrict future type-safe expansion to programs.  Some
programs that could have been written type-correctly if done in one
&#8220;lump&#8221; are impossible to write given the actual historical growth of a
program (many people, different companies, over time, with limited
foresight).  Choose now, pay later.</LI>
</OL>


Of these (A) is actually easily fixable, and Java has helped with that.
And maybe people accept the workaround with (C): either massive
conceptual (and usually code) bloat for a myriad of homogeneous
structures or using a dynamic-typecheck loophole.  But (B) and (D) are
pretty much intractable flaws in static typing for the near future (next
10 years of commercial software).  I would love to be wrong, but it
seems unlikely at the current rate of change in programming languages
and research.


Someone could say somehow they avoid (B) and (D) but I would bet big
money that they are being bit by them all the time.  I gave an example
from the Java collections.  Everyone who programs in Java had the
opportunity to comment on the JDK 1.2 collections for maybe a year
before they were frozen.  But the final choice was to have neither a
concept of an &#8216;Iterable&#8217; object or a &#8216;Containing&#8217; object.  This caused
all of the following methods to have poor granularity:
<pre>
    public boolean containsAll(Collection c)
    public boolean addAll(Collection c)
    public boolean removeAll(Collection c)
    public boolean retainAll(Collection c)
</pre>


Each of the above only needed a single operation: &#8216;contains&#8217; or
&#8216;iterator&#8217;.  But Javasoft rejected:
<pre>
    public boolean containsAll(Container c)
    public boolean addAll(Iterable c)
    public boolean removeAll(Container c)
    public boolean retainAll(Container c)
</pre>


Why?  Because it increased the number of interfaces, which would be a
pain (consider their design notes and the analyses of Doug Lea&#8217;s
collection classes).  A perfect example of both (B) and (D): save now,
choose now, pay later.  And the examples are all over the place in Java,
C++, and Eiffel library code.


The arguments presented against this existing problem actually reinforce
the examples of (B) and (D):

### Changing an existing class/interface

<pre class="quote1">
Davorin Mestric wrote:
>  Yes you can:
>     ...
>     public interface IContains{ public boolean contains( Object o);}
>     ...
>     public void AbstractCollection::removeAll( IContains c) {
</pre>


No, *I* can&#8217;t change &#8216;AbstractCollection&#8217;.  And Javasoft chose not to do
it that way.  They may have chosen unwisely, but that actually means a
whole community of Java programmers chose unwisely because of other
forces solely attributable to static typing.  The problem was putting
these forces on their decision in the first place.

<pre class="quote1">
Joern Janneck wrote:
> ... now
> assume that for a given class of collection (hashed collections are a
> good example) it is more efficient to implement removeAll by iterating
> over the argument (when it is smaller, maybe) instead of over the
> original collection:
[...]
</pre>


OK, so the original contract/type should have been &#8216;IterableContainer&#8217;.
How should I know that ahead of time?  Why did Javasoft not choose that
interface instead?  Collection is definitely too big
a requirement because it dramatically limits the usability of the method
&#8216;removeAll&#8217;.  I would argue that &#8216;IterableContainer&#8217; is also too big.
Why can&#8217;t I just support the &#8216;contains&#8217; method?  As I gave an example:

<pre class="code">
   new Container() { public boolean contains(Object o) {
       ... person is &lt; 6ft...
   }}
</pre>


I can&#8217;t iterate over all the people under six feet tall, or it would at
least be very painful.  Why should iterability be a requirement to a
method like &#8216;removeAll&#8217;?  Intuitively this seems extremely limiting and
I know it to be so in actually building systems.  But the bigger problem
isn&#8217;t just the choices in contract for the &#8216;removeAll&#8217; method, but that
out of simplification that that contract was lumped in with a whole
bunch
of other contracts for Collections in general.

<h3>Summary</h3>


Within just this one simple class (AbstractCollection):
<UL>
  <LI>4 are too specific (they only require an &#8216;Iterable&#8217; or &#8216;Container&#8217;)</LI>
  <LI>3 are non-typed (typed to Object)</LI>
  <LI>4 are non-typed (no parameters)</LI>
  <LI>1 &#8216;toArray(Object[])&#8217; is redundant (and is effectively dynamically
    typed)</LI>
</UL>


So 7 out of 12 are identical with the dynamic version (considering only
parameters), 1/3 are &#8220;incorrect&#8221; caused by static typing disincentives,
and 1 is simply redundant.

<pre class="quote1">
Joern Janneck wrote:
> ...let me again point out that i think that code size
> as such is not the issue in big systems. it is design, and code
> complexity. these don't differ in principle between type systems, and
> arguably static type systems might encourage more structure. or not, who
> knows.
</pre>


In principle, with a perfect static type system, there is no
difference.  But that type system does not exist and current languages
are very far away from it.  The problems (A)-(D) are not just affecting
intra-method complexity (semi-harmless code bloat) they are affecting
inter-object and inter-package complexity.  In just the example
presented we will have to increase (potentially many) clients effort to
use a Collection for their goals, or we will have to provide additional
methods somewhere else (a Collection helper) that a client will need to
know of and again increase the clients&#8217; efforts.


And the argument can be more informed than just personal opinion.
We have plenty of examples of the various languages to compare[1]:
The libraries of Smalltalk, C++, Perl, Java, Eiffel, etc.; Design
Patterns in various languages; and so on.  If you review all these
languages in depth you will find that static typing is certainly harming
scalability.  It may be helping in certain ways against mistakes in the
small, but it is interfering with good code (code that will execute
properly at runtime, is easy to understand, is easy to maintain, and is
useful to many clients) that helps grow systems in the large and over
time.


But great software can be written in any language in spite of each&#8217;s
flaws.  It is just important to keep the great ideas in your team&#8217;s
heads &#8230; and the bad ideas too so you can avoid them (or work around
them) when possible.

<pre class="signature">
--Mark
</pre>


<p class="footnote">
[1] A multi-year immersive experience in each language would be the best
approach, but some of the following might be easier to catch up on:
<UL>
   <LI>Design Patterns: Elements of Reusable Object-Oriented Software</LI>
   <LI>The Design Patterns Smalltalk Companion</LI>
   <LI>Reusable Software: The Base Object-Oriented Component Libraries.</LI>
   <LI>Smalltalk-80: The Language and its Implementation</LI>
   <LI>JDK 1.2 & JGL (www.objectspace.com)</LI>
   <LI>The C++ ANSI/ISO Standard Template Library</LI>
   <LI>CPAN</LI>
</UL>
</p>


<H3 class="discussion">Java Collection</H3>

<pre class="quote">
Joern Janneck wrote:
> Mark Fussell wrote:
> > If you need a specific example, consider the [completely randomly
> > selected] JDK 1.2 Collection code of:
> >     public boolean AbstractCollection::removeAll(Collection c) {
[snip]
> >
> > The static-typing problem in this extremely simple code is that 'c' only
> > needs to respond to 'contains', not be a Collection.  This means I can't
> > just use any containment concept I want to (say, remove all people who
> > are 6' tall)
>
> ... which is something that could be defined as a collection, couldn't
> it? at least in a good design, it should be able to.
</pre>

I don&#8217;t think you really mean that.  Of the 13 operations for a
Collection:
<pre class="code">
    public boolean contains(Object o);
    public boolean containsAll(Collection c);
    public Iterator iterator();
    public int size();
    public boolean isEmpty();
    public Object[] toArray();
    public Object[] toArray(Object a[]);
    public boolean add(Object o);
    public boolean remove(Object o);
    public boolean addAll(Collection c);
    public boolean removeAll(Collection c);
    public boolean retainAll(Collection c);
    public void clear();
</pre>

The concept of &#8220;contains a person 6&#8217; tall&#8221; could only reasonably be
considered to have the first operation at its core with the second as a
helper (really an &#8220;augmentation&#8221; from Collection&#8217;s point of view).
_Maybe_ the third through seventh operation if we insist on the set
being preknown and finite.  All of the rest imply serious mutability
which it would be unreasonable to cause all clients of &#8216;removeAll&#8217; to
support for the parameter &#8216;c&#8217;.  I can&#8217;t believe you consider this to be
a good design and good code.  Again, my definition of good code is code
that will execute properly at runtime, is easy to understand, is easy to
maintain, and is useful to many clients.  This problematic restriction
(all 13 operations instead of 1, 2, or maybe 7) makes this code much
less useful, harder too understand (&#8220;why do we need a full heavyweight
Collection for a simple predicate-like test&#8221;), and the system less
maintainable because we have not specified what we really, precisely,
wanted from the parameter &#8216;c&#8217;.

The argument that HashedCollection would like more from the parameter
&#8216;c&#8217; is really a symptom of this imprecision and a weighting towards
implementers over clients.  Clients are the important ones and need to
be considered first.  There will be many more clients of a particular
operation than implementers of it, so the quality/usefulness of the
contract to the client is much more important to the scalability of the
application.  Client-punishing contracts are the hobgoblins of static
typing.


<H3 class="discussion">Augmenting existing Types</H3>

<pre class="quote1">
Mike Anderson wrote:
[snip]
> ...If, when implementing the client
> of a preexisting class, I could create a new interface and declare that (in the
> context of my client) the preexisting class implements that interface, problem D
> would be solved (wouldn't it?).  Is such a feature feasible?  Are there
> compile-time-checked languages that support something like this?
</pre>

You might look into BeCecil as one example:
<pre>
   <a href="http://www.cs.washington.edu/research/projects/cecil/cecil/www/www/Papers/BeCecil.html">http://www.cs.washington.edu/research/projects/cecil/cecil/www/www/Papers/BeCecil.html</a>
</pre>

<H3 class="discussion">Augmenting existing Types</H3>

<pre class="quote1">
Joern Janneck wrote:
> Markus Kohler wrote:
[snip]
> > Here's a new example
>
> i'd still be interested in your answer to my objection to the first
> example. after all, it was originally supposed to show the virtues of st
> for _large_ sw development. i am still waiting to be answered on that
> issue.
</pre>


If I gave the first example you are referring to (as the originator of
this particular title of thread), I am not sure what answer you are
looking for.  I think multiple people have showed the problem that
static typing has with scaling (in both space and time) because of
certain limitations [&#8216;A&#8217;-&#8216;D&#8217;] fairly well.  Nothing that I and others
presented as problems are _unknown_ to static typing research and people
are busily working on solving these types of problems.  Language
families of Cecil, Haskell, ML, and so on are trying to solve these
problems because they *are* problems.  And they affect scalability.

Dynamic OO languages have benefits that cause (well designed
applications) to scale extremely well in size and space because they
allow components to be reused and pieced together in a more optimal way,
and so reduce overall system complexity.  The reason is that dynamic OO
languages simply do not artificially enlarge a contract between two
parties to include irrelevant details from:
<ol class="arab">
  <LI>Other parties (by being lumped together in a single named type).</LI>
  <LI>Other times   (because types were frozen by a compile at one
moment in time)</LI>
  <LI>Implementation </LI>
</ol>
Current static languages unfortunately encourage or require the
inclusion of these artificial restrictions in a system, which impedes
scalability (space and time).

### Specific example

My example was:
<pre class="code">
    public boolean AbstractCollection::removeAll(Collection c)
</pre>

No, this is not large programming yet, but it is headed that way:
Collections are a core library in any programming language.  If there
are serious restrictions and overhead in dealing with them, this is a
strong indicator of what will come in many areas as the system scales
(in size and over time).  Simply consider the quality and lifetime of
the Smalltalk-80 collections.  They are better (more capable, more
useful, and more maintainable) than anything that has come from the C++
and Java languages over their unstable lifetimes &#8211; even though both
languages could have leveraged this existing work and its published
improvements.  The Smalltalk libraries have been amazingly stable over a
20 year period of use and growth: Smalltalk code I have from 1986 is
still CORRECT and is cleaner than (hopefully much more skillfully
written) Java code from 1999.

My other example included looking at the complexity of all the Design
Patterns in dynamic OO vs. static-typed OO languages.  If you seriously
think that the patterns are more elegant, scalable (size and time), and
maintainable in static-typed OO languages &#8211; Java, for example, needed
three *totally different* implementations of the Observer/Listener
pattern to deal with _primarily_ different typing issues &#8211; there is
unfortunately little to talk about.  If you simply think the tradeoff is
worth it, there is also little to talk about because I accept that
perspective.  Note that I was answering a specific question:
<pre class="quote1">
>   (2) Why does dynamic typing (as done with Smalltalk) not negatively
>       affect the stability of large applications?
</pre>

for someone who had never built a large application in Smalltalk or a
similar language.

### Tradeoffs

The one aspect I do consider very useful with static typing for building
systems is that it *forces* developers to think formally about
interfaces between objects or their code breaks quickly.  This is a very
good training experience and should be repeated off and on to make sure
people aren&#8217;t getting sloppy.  But if you are a good designer, the
realities/restrictions of static typing cause you to produce somewhat
less scalable (over size and time) applications[1] than for a dynamic OO
language with similar effort in documentation of protocols and test
suites.  So the idea of switching back and forth between an optional
statically-checked and a dynamic [with documented protocols] OO language
is certainly a good one.  Better than having casting/type-checking
loopholes (a sort of strange intermediate).

Most large dynamic OO projects do have this characteristic
(static-oriented documentation) because UML and most other notations
require a static-type based perspective.  And well-defined
types/contracts exist all throughout good Smalltalk code, but some of
the best contracts (Valuable, Observer, Iterable, etc.) are just too
fine-grained, too pervasive, or too generic to be represented in a
statically-typed program.  Unfortunately, a dynamically simple concept
like &#8220;augmentations&#8221;[1] is also impossible to correctly represent in the
core UML because of its simplistic (C++ ish) static-typing origin.


<pre class="signature">
--Mark
</pre>

<p class="footnote">
[1] Just the one feature of Envy extensions (the ability to &#8220;augment&#8221;
existing classes with new behavior without modifying the original code)
is incredibly powerful for building large applications [especially
dealing with layering] and is only possible if the original compiler did
not statically freeze the types.
</p>


<H3 class="discussion">Amount of static typing</H3>

<pre class="quote1">
patrick@c837917-a.potlnd1.or.home.com wrote:
> : David Jenkins wrote:
> : > One of my problems with Java is that it pretends to be statically
> : > typed, but is not--you can always cast your way out of a type.
> : > Eiffel, I've found, is a very stern taskmaster when it comes to
> : > typing, but I've learned to appreciate the lessons it teaches.
>
> Java is no less statically typed than Eiffel, i.e. you cannot cast a
> Java object to anything that it was not defined to be (as could be
> done with C++, at least in years past).
</pre>

<p>
I think &#8220;more&#8221; or &#8220;less&#8221; statically typed was referring to &#8220;amount of
code that is verifiably type-correct at compile-time&#8221; not whether the
type system is safe.  I don&#8217;t think unsafe type systems are in any way
interesting to those reading these threads.   I agree with David Jenkins
that Java code will be far less compile-time verified than Eiffel
because of weaknesses in the Java type system (especially from the lack
of covariant return types and some form of parametric types).  A Java
typecheck cast (a &#8220;type attempt&#8221;) is just as dynamic as standard
Smalltalk message sends; the Java version just has a larger granularity
and a slightly different timing (before the message as opposed to at
message time).  The amount of &#8220;type attempts&#8221; within Java code is
enormously larger than the amount of &#8220;assignment attempts&#8221; within Eiffel
code.  So the Java code is really &#8220;much less statically typed&#8221; although
we are want for nice short phrases that a precise and accurate: &#8220;much
less compile-time type-verified&#8221;.
</p>

<p>
Interestingly, the Eiffel code will be additionally and more precisely
&#8220;dynamically object-verified&#8221; through the preconditions, postconditions,
and invariants.  So a stronger verification applied to the Objects
themselves is coming from dynamic checks (just like Smalltalk) as
opposed to compile-time checks.  Smalltalk with Eiffel-like DBC
capabilities would definitely muddle the linearity of type safety[1]:
Smalltalk would be more precisely verified at runtime than a Java
program but less precisely verified at compile time.  This would be
without the problems of compile-time typing (problems with granularity,
evolution, genericity, etc.).  Which is safer?&#8230; no I don&#8217;t want to go
down that topic&#8217;s path&#8230;
</p>

<p>
Actually, this Smalltalk augmentation is pretty easy [I previously did a
prototype and I also recall the concept being published in Smalltalk
Report] since we could: (1) allow DBC anotations in methods or
categorize special unit tests into pre, post, and invariant conditions,
(2) augment the compiler to generate the calls on method entry and exit,
(3) provide the same behavior as Eiffel [no check on intra-object
calls], and (4) throw reasonable exceptions depending on who is
responsible.  The main issues are the exact annotation form (although
UML&#8217;s OCL pretty much solves that problem) and
standardization/portability across Smalltalk platforms.
</p>

<pre class="signature">
--Mark
</pre>


<p class="footnote">
[1] Type safety: Amount the program is verified to behave correctly
</p>

]]></content>
  </entry>
  
</feed>
